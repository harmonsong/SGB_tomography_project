{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ccfj\n",
    "import h5py\n",
    "import time\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import mathlib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'output_FJSJ_09-02/'\n",
    "nThreads = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_basic = proj_name+'Basic_info.npy'\n",
    "info_basic = np.load(filename_basic, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define how many subworks to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_subworks = ['01-01']\n",
    "key_subworks = info_basic['key_subworks']\n",
    "#key_subworks.remove('2013_10')\n",
    "key_subworks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_fj(key_subwork):\n",
    "    global proj_name\n",
    "    global c\n",
    "\n",
    "    start0 = time.time()\n",
    "\n",
    "    filename = proj_name+'Basic_info.npy'\n",
    "    info_basic = np.load(filename, allow_pickle='TRUE').item()\n",
    "    \n",
    "    dir_stack = info_basic['dir_stack']\n",
    "    dir_ds = info_basic['dir_ds']\n",
    "    f = info_basic['f']\n",
    "\n",
    "    if os.path.exists(dir_ds+'ds_'+key_subwork+'.h5'):\n",
    "        os.remove(dir_ds+'ds_'+key_subwork+'.h5')\n",
    "    h5file = h5py.File(dir_ds+'ds_'+key_subwork+'.h5','w')\n",
    "\n",
    "    #print(\"F-J scan for \"+filename+\" stack  \"+key_subwork)\n",
    "    \"\"\"\n",
    "    data = np.load(dir_stack+key_subwork+'_summed-'+filename+'.npz')\n",
    "    ncfs = data['ncfs']\n",
    "    r = data['r']*1e3\n",
    "    \"\"\"\n",
    "    # linear stack\n",
    "    outname = key_subwork+'_gather_linear.h5'\n",
    "    ncffile = h5py.File(dir_stack + outname,'r')\n",
    "    ncfs = ncffile['ncfs'][:]\n",
    "    r = ncffile['r'][:]*1e3\n",
    "    ncffile.close()\n",
    "\n",
    "    \"\"\"\n",
    "    # FPS stack\n",
    "    outname = key_subwork+'_gather_FPS.h5'\n",
    "    ncffile = h5py.File(dir_stack + outname,'r')\n",
    "    ncfs_FPS = ncffile['ncfs'][:]\n",
    "    r = ncffile['r'][:]\n",
    "    ncffile.close()\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #ds00 = ccfj.fj_noise(np.real(ncfs),r,c,f,fstride=1,itype=0,func=0)\n",
    "    #ds01 = ccfj.fj_noise(np.real(ncfs),r,c,f,fstride=1,itype=1,func=0)\n",
    "    #ds10 = ccfj.fj_noise(np.real(ncfs),r,c,f,fstride=1,itype=0,func=1)\n",
    "    ds11 = ccfj.fj_noise(np.real(ncfs),r,c,f,fstride=1,itype=1,func=1)\n",
    "    #ds = [ds10,ds11]\n",
    "    #ds = np.array(ds)\n",
    "    ds = np.array(ds11).reshape(1,np.shape(ds11)[0],np.shape(ds11)[1])\n",
    "    h5file.create_dataset('ds_linear',data=ds)\n",
    "\n",
    "    \"\"\"\n",
    "    ds11 = ccfj.fj_noise(np.real(ncfs_FPS),r,c,f,fstride=1,itype=1,func=1)\n",
    "    ds = np.array(ds11).reshape(1,np.shape(ds11)[0],np.shape(ds11)[1])\n",
    "    h5file.create_dataset('ds_FPS',data=ds)\n",
    "    \"\"\"\n",
    "\n",
    "    h5file.create_dataset('f',data=f)\n",
    "    h5file.create_dataset('c',data=c)\n",
    "    h5file.close()\n",
    "    print('Finish '+ key_subwork +   ' time:', time.time()-start0, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.linspace(0.100,2,1000)\n",
    "info_basic['c'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pool = ThreadPoolExecutor(max_workers = nThreads)\n",
    "for key_subwork in key_subworks:\n",
    "    pool.submit(noise_fj,key_subwork)\n",
    "pool.shutdown()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_subwork in key_subworks:\n",
    "    noise_fj(key_subwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(filename_basic,info_basic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e1b1cfcb63b8c4b20fd3d610677682a40199606624b55ac5cc8ef1326af990f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
