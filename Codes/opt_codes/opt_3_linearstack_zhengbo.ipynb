{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from ccfj import CC\n",
    "from ccfj import GetStationPairs\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import time\n",
    "from geopy.distance import great_circle\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'output_test_15Hz_zb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_basic = proj_name+'Basic_info.npy'\n",
    "info_basic = np.load(filename_basic, allow_pickle='TRUE').item()      # setting dictionary\n",
    "dir_stack = info_basic['dir_stack']\n",
    "dir_stack_all = info_basic['dir_stack_all']\n",
    "stalistname = info_basic['stalistname']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define how many subworks to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_subworks = ['2010_3']\n",
    "key_subworks = info_basic['key_subworks']\n",
    "key_subworks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_subworks = proj_name+'sta_info.npy'\n",
    "sta_info = np.load(filename_subworks, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalist_all = []\n",
    "with open(stalistname,'r') as f:\n",
    "    while True:\n",
    "        tmp = f.readline()\n",
    "        if tmp:\n",
    "            stalist_all.append(tmp.split()[0])\n",
    "            lat_all.append(float(tmp.split()[1]))\n",
    "            lon_all.append(float(tmp.split()[2]))\n",
    "        else:\n",
    "            break\n",
    "nsta_all = len(stalist_all)\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(nsta_all*(nsta_all-1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.zeros(nsta_all)\n",
    "for i in range(nPairs_all):\n",
    "    r[i] = great_circle((lat_all[StationPairs_all[i*2]],lon_all[StationPairs_all[i*2]]),(lat_all[StationPairs_all[i*2+1]],lon_all[StationPairs_all[i*2+1]])).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_file = np.load(dir_stack_all+'summed.npz')\n",
    "ncfs = stack_file['ncfs']\n",
    "ncffile = h5py.File('CC_15_zb/ZG_gather.h5','r')\n",
    "ncfs = ncffile['ncfs'][:]\n",
    "f = info_basic['f']\n",
    "\n",
    "stainfo = pd.read_excel('sta.xlsx')\n",
    "key_pd = 'R0101'\n",
    "stalist_all = list(stainfo[key_pd])\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Stack files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key_subwork in key_subworks:\n",
    "    print(\"Collecting \",key_subwork,' ...')\n",
    "    time0 = time.time()\n",
    "\n",
    "    nf = info_basic['nf']\n",
    "    f = info_basic['f']\n",
    "    dir_stack= info_basic['dir_stack']\n",
    "    \n",
    "    nsta = info_basic['nstaS'][key_subwork]\n",
    "    nPairs = int(nsta*(nsta-1)/2)\n",
    "    stalistname = proj_name+info_basic['stalistname'] +'-'+key_subwork\n",
    "\n",
    "    stalist = []\n",
    "    lon = []\n",
    "    lat =[]\n",
    "    with open(stalistname,'r') as f:\n",
    "        while True:\n",
    "            tmp = f.readline()\n",
    "            if tmp:\n",
    "                stalist.append(tmp.split()[0])\n",
    "                lat.append(float(tmp.split()[1]))\n",
    "                lon.append(float(tmp.split()[2]))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    ncfs_sum_linear = np.zeros((nPairs,nf),dtype=np.complex64)\n",
    "    r = np.zeros(nPairs)\n",
    "    count= np.zeros(nPairs)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    names = []\n",
    "    for i in range(nPairs):\n",
    "        sta1 = StationPairs[2*i]\n",
    "        sta2 = StationPairs[2*i+1]\n",
    "        idx1 = int(stalist_all.index(stalist[sta1]))\n",
    "        idx2 = int(stalist_all.index(stalist[sta2]))\n",
    "        #idx1 = int(stainfo[stainfo[key_pd]==stalist[sta1]].index.values[0])\n",
    "        #idx2 = int(stainfo[stainfo[key_pd]==stalist[sta2]].index.values[0])\n",
    "        \n",
    "        m = 0\n",
    "        for j in range(nsta_all-idx1,nsta_all):\n",
    "            m += j\n",
    "        num = m + idx2 - idx1 -1\n",
    "        \n",
    "        ncfs_sum_linear[i,:] = np.nan_to_num(ncfs[num,:])\n",
    "        #if count_all[num] > 0:\n",
    "        #    ncfs_sum_linear[i,:] = ncfs[num,:]/count_all[num]\n",
    "        #    count[i] = count_all[num]\n",
    "\n",
    "        r[i] = great_circle((lat[sta1],lon[sta1]),(lat[sta2],lon[sta2])).km\n",
    "        #names.append([stalist_all[StationPairs_all[2*num]],stalist_all[StationPairs_all[2*num+1]]])\n",
    "    np.savez(dir_stack+key_subwork+\"_summed-linear.npz\",ncfs= ncfs_sum_linear,r = r,count = count,stalist=stalist,StationPairs=StationPairs)\n",
    "    print(\"Done in \",time.time()-time0,\" s.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e1b1cfcb63b8c4b20fd3d610677682a40199606624b55ac5cc8ef1326af990f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
