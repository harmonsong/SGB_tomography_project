{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../toollib_voro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PointinPolygon import inpolygon\n",
    "import os\n",
    "from geopy.distance import great_circle\n",
    "import ccfj\n",
    "import h5py\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'output_FJSJ_06-05/'\n",
    "outdir = proj_name + 'ds_vor/'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VoroTomo Partition times\n",
    "#n = 100\n",
    "n = 50\n",
    "# number of Voro cells  range\n",
    "kmin = 10\n",
    "kmax = 40\n",
    "# cell radius ?\n",
    "Radius = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_basic = proj_name+'Basic_info.npy'\n",
    "info_basic = np.load(filename_basic, allow_pickle='TRUE').item()      # setting dictionary\n",
    "dir_stack_all = info_basic['dir_stack_all']\n",
    "stalistname = info_basic['stalistname']\n",
    "filename = dir_stack_all + 'gather_all.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_basic['dir_ds_vor'] = outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pairs(sta):\n",
    "    p = []\n",
    "    nsta = len(sta)\n",
    "    for ii in range(nsta):\n",
    "        for jj in range(ii+1,nsta):\n",
    "            p.append([sta[ii],sta[jj]])\n",
    "    return p\n",
    "def cal_indx(pair,nsta):\n",
    "    indx = int(pair[0]*(2*nsta-pair[0]-1)/2+pair[1]-pair[0]-1)\n",
    "    return indx\n",
    "\n",
    "def singleVoro(indx0,outname,xvyv):\n",
    "    global ncfs\n",
    "    global f\n",
    "    global c\n",
    "    global nf\n",
    "    global r\n",
    "    global count\n",
    "    global outdir\n",
    "    filename = os.path.join(outdir,outname+'.h5')\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    \n",
    "    subpairs = Pairs(indx0)\n",
    "    indx1 = [cal_indx(pair,nsta) for pair in subpairs]\n",
    "    ncfsi = ncfs[indx1,:]\n",
    "    counti = count[indx1]\n",
    "    ri = r[indx1]\n",
    "    indx = np.argsort(ri)\n",
    "    ri = ri[indx]\n",
    "    ncfsi = ncfsi[indx,:]\n",
    "    counti = counti[indx]\n",
    "    ncfsi = ncfsi[counti!=0]\n",
    "    ri = ri[counti!=0]\n",
    "    counti = counti[counti!=0]\n",
    "\n",
    "    \n",
    "    ds = ccfj.fj_noise(np.real(ncfsi),ri*1e3,c,f,itype=1,func=1)\n",
    "\n",
    "    h5file=h5py.File(filename,'w')\n",
    "    h5file.create_dataset('ds',data=ds)\n",
    "    h5file.create_dataset('c',data=c)\n",
    "    h5file.create_dataset('f',data=f)\n",
    "    h5file.create_dataset('indx',data=indx0)\n",
    "    h5file.create_dataset('xvyv',data=xvyv)\n",
    "    h5file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stainfo = pd.read_excel(stalistname+'.xlsx')\n",
    "staloc =  np.asarray([stainfo.iloc[:,1],stainfo.iloc[:,2]]).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The KDE of the stations' locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = stats.gaussian_kde(staloc.T)\n",
    "nsta = len(stainfo.iloc[:,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read NCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.linspace(200,2000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncffile = h5py.File(dir_stack_all + 'gather_all.h5','r')\n",
    "ncfs = ncffile['ncfs'][:]\n",
    "f = ncffile['f'][:]\n",
    "count = ncffile['count'][:]\n",
    "r = ncffile['r'][:]\n",
    "ncffile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voronoi partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.mean(staloc[:,0])\n",
    "y0 = np.mean(staloc[:,1])\n",
    "minx = min(staloc[:,0]);maxx = max(staloc[:,0])\n",
    "miny = min(staloc[:,1]);maxy = max(staloc[:,1])\n",
    "points0 = []\n",
    "for i in range(36):\n",
    "    points0.append([x0+np.cos(i/18*np.pi),y0+np.sin(i/18*np.pi)])\n",
    "    \n",
    "points0=np.asarray(points0)\n",
    "\n",
    "# Starting Voronoi Partitioning\n",
    "for ii in range(n):\n",
    "    # random the number of Voronoi cells\n",
    "    k = np.random.randint(kmin,kmax)\n",
    "    # Using the KDE PDF to generate Voronoi cells\n",
    "    points = kernel.resample(k).T \n",
    "    # Using the Uniform distribution to generate Voronoi cells\n",
    "    '''\n",
    "    points = np.random.rand(k,2)\n",
    "    points[:,0] = points[:,0]*(maxx-minx) + minx\n",
    "    points[:,1] = points[:,1]*(maxy-miny) + miny\n",
    "    '''\n",
    "\n",
    "    # Voronoi Partition\n",
    "    points = np.concatenate((points,points0))\n",
    "    vor = Voronoi(points)\n",
    "    areas = []\n",
    "    for j in range(k):\n",
    "        xv = vor.vertices[vor.regions[vor.point_region[j]],0]\n",
    "        yv = vor.vertices[vor.regions[vor.point_region[j]],1]\n",
    "        _in,_on = inpolygon(staloc[:,0],staloc[:,1],xv,yv)\n",
    "        indx = np.array([i for i,x in enumerate(_in) if x])\n",
    "        if len(indx)>10:\n",
    "            areas.append([indx,np.array([xv,yv])])\n",
    "    vor.close()\n",
    "    for j in range(len(areas)):\n",
    "\n",
    "        print(ii,j,len(areas[j][0]))\n",
    "        # calculate the F-J spectrum\n",
    "        singleVoro(areas[j][0],'vor'+str(ii)+'_'+str(j),areas[j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(filename_basic,info_basic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e1b1cfcb63b8c4b20fd3d610677682a40199606624b55ac5cc8ef1326af990f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
