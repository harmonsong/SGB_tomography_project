{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ccfj\n",
    "import h5py\n",
    "import time\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import mathlib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nThreads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('a-project.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "proj_name = proj['name']\n",
    "#proj_name = 'project/output_FJSJ_14-05/'\n",
    "proj_name = '/shdisk/rem2/Harmon/F-J/San/project/output_FJSJ_17-01/'\n",
    "proj_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = proj_name+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = proj_name+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define how many subworks to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_subworks = ['14-05','16-05']\n",
    "key_subworks = info_basic['key_subworks']\n",
    "key_subworks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_fj(key_subwork):\n",
    "    global proj_name\n",
    "    global c\n",
    "    global key_subworks\n",
    "\n",
    "    \n",
    "    start0 = time.time()\n",
    "    filename = proj_name+'Basic_info.yml'\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "    filename_bi = proj_name+'Basic_info.npy'\n",
    "    info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary\n",
    "    \n",
    "    dir_stack = info_basic['dir_stack']\n",
    "    dir_ds = info_basic['dir_ds']\n",
    "    f = info_basic_bi['f']\n",
    "\n",
    "    if os.path.exists(dir_ds+'ds_'+key_subwork+'.h5'):\n",
    "        os.remove(dir_ds+'ds_'+key_subwork+'.h5')\n",
    "    h5file = h5py.File(dir_ds+'ds_'+key_subwork+'.h5','w')\n",
    "\n",
    "    #print(\"F-J scan for \"+filename+\" stack  \"+key_subwork)\n",
    "    \"\"\"\n",
    "    data = np.load(dir_stack+key_subwork+'_summed-'+filename+'.npz')\n",
    "    ncfs = data['ncfs']\n",
    "    r = data['r']*1e3\n",
    "    \"\"\"\n",
    "    # linear stack\n",
    "    outname = key_subwork+'_gather_linear.h5'\n",
    "    ncffile = h5py.File(dir_stack + outname,'r')\n",
    "    ncfs = ncffile['ncfs'][:]\n",
    "    r = ncffile['r'][:]\n",
    "    ncffile.close()\n",
    "    \n",
    "    # timewindow filtered stack\n",
    "    outname = key_subwork+'_gather_timewindow.h5'\n",
    "    ncffile = h5py.File(dir_stack + outname,'r')\n",
    "    ncfs_remove = ncffile['ncfs'][:]\n",
    "    ncffile.close()\n",
    "    \n",
    "\n",
    "\n",
    "    #ds00 = ccfj.fj_noise(np.real(ncfs),r,c,f,fstride=1,itype=0,func=0)\n",
    "    #ds01 = ccfj.fj_noise(np.real(ncfs),r,c,f,fstride=1,itype=1,func=0)\n",
    "    #ds10 = ccfj.fj_noise(np.real(ncfs),r,c,f,fstride=1,itype=0,func=1)\n",
    "    \n",
    "    ds11 = ccfj.fj_noise(np.real(ncfs),r,c,f,fstride=1,itype=1,func=1)\n",
    "    #ds = [ds10,ds11]\n",
    "    #ds = np.array(ds)  \n",
    "    ds = np.array(ds11).reshape(1,np.shape(ds11)[0],np.shape(ds11)[1])\n",
    "    h5file.create_dataset('ds_linear',data=ds)\n",
    "\n",
    "    \n",
    "    ds11 = ccfj.fj_noise(np.real(ncfs_remove),r,c,f,fstride=1,itype=1,func=1)\n",
    "    ds = np.array(ds11).reshape(1,np.shape(ds11)[0],np.shape(ds11)[1])\n",
    "    h5file.create_dataset('ds_remove',data=ds)\n",
    "    \n",
    "\n",
    "    h5file.create_dataset('f',data=f)\n",
    "    h5file.create_dataset('c',data=c)\n",
    "    h5file.close()\n",
    "    print('Finish '+ key_subwork +   ' time:', time.time()-start0, ' seconds. Proceeded '+str(key_subworks.index(key_subwork)+1)+'/'+str(len(key_subworks))+' subworks.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_min = 0.200\n",
    "c_max = 2\n",
    "c_num = 800\n",
    "c = np.linspace(c_min,c_max,c_num)\n",
    "info_basic['c_min'] = c_min\n",
    "info_basic['c_max'] = c_max\n",
    "info_basic['c_num'] = c_num\n",
    "with open(proj_name+'Basic_info.yml', 'w', encoding='utf-8') as f:\n",
    "   yaml.dump(data=info_basic, stream=f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pool = ThreadPoolExecutor(max_workers = nThreads)\n",
    "for key_subwork in key_subworks:\n",
    "    pool.submit(noise_fj,key_subwork)\n",
    "pool.shutdown()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_ds = info_basic['dir_ds']\n",
    "flag_plot = 0\n",
    "for key_subwork in key_subworks:\n",
    "    #print(1)\n",
    "    flag_plot += 1\n",
    "    #print(key_subwork)\n",
    "    \"\"\"\n",
    "    if os.path.exists(dir_ds+'ds_'+key_subwork+'.h5'):\n",
    "        print(key_subwork+' exists')\n",
    "        continue\n",
    "    \"\"\"\n",
    "    \n",
    "    #start0 = time.time()\n",
    "    noise_fj(key_subwork)\n",
    "    #print('Finish '+ key_subwork +   ' time:', time.time()-start0, ' seconds. Proceeded '+str(flag_plot)+'/'+str(len(key_subworks))+' subworks.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e1b1cfcb63b8c4b20fd3d610677682a40199606624b55ac5cc8ef1326af990f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
