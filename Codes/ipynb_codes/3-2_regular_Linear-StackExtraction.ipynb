{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from ccfj import CC\n",
    "from ccfj import GetStationPairs\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import time\n",
    "from geopy.distance import great_circle\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('a-project.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "proj_name = proj['name']\n",
    "#proj_name = 'project/output_FJSJ_15-01/'\n",
    "proj_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = proj_name+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = proj_name+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_stack = info_basic['dir_stack']\n",
    "dir_stack_all = info_basic['dir_stack_all']\n",
    "stalistname = info_basic['stalistname']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define how many subworks to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_subworks = ['01-01']\n",
    "key_subworks = info_basic['key_subworks']\n",
    "key_subworks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stainfo = pd.read_excel(stalistname+'.xlsx')\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist()\n",
    "lat_all = stainfo['latitude'].tolist() \n",
    "lon_all = stainfo['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncffile = h5py.File(dir_stack_all + 'gather_all.h5','r')\n",
    "ncfs = ncffile['ncfs'][:]\n",
    "f = ncffile['f'][:]\n",
    "count_all = ncffile['count'][:]\n",
    "ncffile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Stack files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_basic_bi['r_max'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_subwork in key_subworks:\n",
    "    print(\"Collecting \",key_subwork,' ...')\n",
    "    time0 = time.time()\n",
    "\n",
    "    nf = info_basic['nf']\n",
    "    #f = info_basic['f']\n",
    "    dir_stack= info_basic['dir_stack']\n",
    "    \n",
    "    nsta = info_basic['nstaS'][key_subwork]\n",
    "    nPairs = int(nsta*(nsta-1)/2)\n",
    "    stalistname = proj_name+info_basic['stalistname']\n",
    "\n",
    "    stainfo = pd.read_excel(stalistname+'.xlsx',key_subwork)\n",
    "    nsta = len(stainfo.iloc[:,0])\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    nPairs = int(len(StationPairs)/2)\n",
    "    stalist = stainfo['Station'].tolist()\n",
    "    lat = stainfo['latitude'].tolist() \n",
    "    lon = stainfo['longitude'].tolist()\n",
    "\n",
    "    ncfs_sum_linear = np.zeros((nPairs,nf),dtype=np.complex64)\n",
    "    r = np.zeros(nPairs)\n",
    "    count= np.zeros(nPairs)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    names = []\n",
    "    for i in range(nPairs):\n",
    "        sta1 = StationPairs[2*i]\n",
    "        sta2 = StationPairs[2*i+1]\n",
    "        idx1 = np.min( [int(stalist_all.index(stalist[sta1])),int(stalist_all.index(stalist[sta2]))] )\n",
    "        idx2 = np.max( [int(stalist_all.index(stalist[sta1])),int(stalist_all.index(stalist[sta2]))] )\n",
    "        #idx1 = int(stalist_all.index(stalist[sta1]))\n",
    "        #idx2 = int(stalist_all.index(stalist[sta2]))\n",
    "        #idx1 = int(stainfo[stainfo[key_pd]==stalist[sta1]].index.values[0])\n",
    "        #idx2 = int(stainfo[stainfo[key_pd]==stalist[sta2]].index.values[0])\n",
    "        \n",
    "        m = 0\n",
    "        for j in range(nsta_all-idx1,nsta_all):\n",
    "            m += j\n",
    "        num = m +idx2 - idx1 -1\n",
    "        \n",
    "        ncfs_sum_linear[i,:] = np.nan_to_num(ncfs[num,:])\n",
    "        count[i] = count_all[num]\n",
    "        #r[i] = r0[num]\n",
    "        #if count_all[num] > 0:\n",
    "        #    ncfs_sum_linear[i,:] = ncfs[num,:]/count_all[num]\n",
    "        #    count[i] = count_all[num]\n",
    "\n",
    "        r[i] = great_circle((lat[sta1],lon[sta1]),(lat[sta2],lon[sta2])).km\n",
    "        #names.append([stalist_all[StationPairs_all[2*num]],stalist_all[StationPairs_all[2*num+1]]])\n",
    "\n",
    "    outname = key_subwork+'_gather_linear.h5'\n",
    "    if os.path.exists(dir_stack+outname):\n",
    "        os.remove(dir_stack+outname)\n",
    "    ncffile = h5py.File(dir_stack+outname,'w')\n",
    "    \n",
    "    ncffile.create_dataset('ncfs',data=ncfs_sum_linear)\n",
    "    ncffile.create_dataset('r',data=r)\n",
    "    ncffile.create_dataset('count',data=count)\n",
    "    ncffile.create_dataset('f',data=f)\n",
    "    ncffile.create_dataset('StationPairs',data=StationPairs)\n",
    "    #print(ncffile.keys())\n",
    "    ncffile.close()\n",
    "    #np.savez(dir_stack+key_subwork+\"_summed-linear.npz\",ncfs= ncfs_sum_linear,r = r,stalist=stalist,StationPairs=StationPairs)\n",
    "    print(\"Done in \",time.time()-time0,\" s.\")\n",
    "\n",
    "    info_basic_bi['r_max'][key_subwork] = max(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(filename_bi,info_basic_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_basic_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e1b1cfcb63b8c4b20fd3d610677682a40199606624b55ac5cc8ef1326af990f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
