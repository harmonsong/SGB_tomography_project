{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "#from ccfj import GetStationPairs\n",
    "from geopy.distance import great_circle\n",
    "#import shapefile\n",
    "import geopandas as gp\n",
    "import yaml\n",
    "import math\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import griddata\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "from pykrige.ok import OrdinaryKriging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_project = 1 # 0--regular; 1--repartrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_project == 0:\n",
    "    file_project = 'a-project.yml'\n",
    "elif flag_project == 1:\n",
    "    file_project = 'a-project_repar.yml'\n",
    "elif flag_project == 2:\n",
    "    file_project = 'a-project_voro.yml'\n",
    "    \n",
    "with open(file_project, 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "\n",
    "#name_project = 'project/output_FJSJ_16-01/'               \n",
    "#name_project = 'project_repartrition/repartrition_01-03/'               \n",
    "#name_project = 'project_voronoi/voronoi_01-03/'         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_model_fund = dir_project + info_basic['dir_model_fund']\n",
    "dir_model = dir_project + info_basic['dir_model']\n",
    "dir_image = dir_project + info_basic['dir_image']+'Vs_compare/'\n",
    "if not os.path.exists(dir_image):\n",
    "    os.makedirs(dir_image)\n",
    "dir_inv_dispernet = dir_project + info_basic['dir_inv_dispernet']\n",
    "dir_partition = dir_project + info_basic['dir_partition']\n",
    "key_subworks = info_basic['key_subworks']\n",
    "M = len(key_subworks)\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetStationPairs(nsta):\n",
    "    StationPair = []\n",
    "    for ii in range(nsta):\n",
    "        for jj in range(ii+1,nsta):\n",
    "            StationPair.append(ii)\n",
    "            StationPair.append(jj)\n",
    "    StationPair = np.array(StationPair,dtype=np.int32)\n",
    "    return StationPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist() \n",
    "lat_stations_all =  stainfo['latitude'].tolist() \n",
    "lon_stations_all =  stainfo['longitude'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_partition = {}\n",
    "lat_stations_partition = {}\n",
    "lon_stations_partition = {}\n",
    "lat_centroid_partition = []\n",
    "lon_centroid_partition = []\n",
    "num_stations = []\n",
    "for key in key_subworks:\n",
    "    filepath = dir_partition + str(key) + '.txt'\n",
    "    stations_this, lat_stations_this, lon_stations_this = np.loadtxt(filepath, dtype='str' , unpack=True)\n",
    "    stations_partition[key] = stations_this\n",
    "    lat_stations_partition[key] = lat_stations_this.astype(float)\n",
    "    lon_stations_partition[key] = lon_stations_this.astype(float)\n",
    "    num_stations.append(len(stations_this))\n",
    "    lat_centroid_partition.append(np.mean(lat_stations_this.astype(float)))\n",
    "    lon_centroid_partition.append(np.mean(lon_stations_this.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = np.load('clark_faults.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_affine_transform(original_points, target_points):\n",
    "    A_matrix = np.array([[original_points[0][0], original_points[0][1], 1, 0, 0, 0],\n",
    "                         [0, 0, 0, original_points[0][0], original_points[0][1], 1],\n",
    "                         [original_points[1][0], original_points[1][1], 1, 0, 0, 0],\n",
    "                         [0, 0, 0, original_points[1][0], original_points[1][1], 1],\n",
    "                         [original_points[2][0], original_points[2][1], 1, 0, 0, 0],\n",
    "                         [0, 0, 0, original_points[2][0], original_points[2][1], 1]])\n",
    "\n",
    "    A1_B1_C1 = np.array([target_points[0][0], target_points[0][1], target_points[1][0], target_points[1][1], target_points[2][0], target_points[2][1]])\n",
    "\n",
    "    coefficients = np.linalg.solve(A_matrix, A1_B1_C1)\n",
    "\n",
    "    affine_matrix = np.array([[coefficients[0], coefficients[1], coefficients[2]],\n",
    "                               [coefficients[3], coefficients[4], coefficients[5]],\n",
    "                               [0, 0, 1]])\n",
    "\n",
    "    return affine_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transformation\n",
    "lon_stations_all_new = []\n",
    "lat_stations_all_new = []\n",
    "for sta in stalist_all:\n",
    "    if int(sta[1:3]) <= 60:\n",
    "        lon_stations_all_new.append(lon_stations_all[stalist_all.index(sta)])\n",
    "        lat_stations_all_new.append(lat_stations_all[stalist_all.index(sta)])\n",
    "refs = ['R0101','R6001','R6020']\n",
    "lon_refs = [lon_stations_all[stalist_all.index(ref)] for ref in refs]\n",
    "lat_refs = [lat_stations_all[stalist_all.index(ref)] for ref in refs]\n",
    "loc_refs = np.column_stack([lon_refs,lat_refs])\n",
    "loc_refs_new = np.array([[0,0],[600,0],[600,600]])\n",
    "\n",
    "affine_matrix = compute_affine_transform(loc_refs, loc_refs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all stations\n",
    "x_stations_all_new = []\n",
    "y_stations_all_new = []\n",
    "for i in range(len(lon_stations_all_new)):\n",
    "    loc_sta = np.array([lon_stations_all_new[i],lat_stations_all_new[i],1])\n",
    "    loc_sta_new = np.dot(affine_matrix,loc_sta)\n",
    "    x_stations_all_new.append(loc_sta_new[0])\n",
    "    y_stations_all_new.append(loc_sta_new[1])\n",
    "# faults\n",
    "x_faults = {}\n",
    "y_faults = {}\n",
    "for i in range(len(faults)):\n",
    "    x_faults['clark'+str(i+1)] = []\n",
    "    y_faults['clark'+str(i+1)] = []\n",
    "    for j in range(len(faults['clark'+str(i+1)]['lon'])):\n",
    "        loc_fault = np.array([faults['clark'+str(i+1)]['lon'][j],faults['clark'+str(i+1)]['lat'][j],1])\n",
    "        loc_fault_new = np.dot(affine_matrix,loc_fault)\n",
    "        x_faults['clark'+str(i+1)].append(loc_fault_new[0])\n",
    "        y_faults['clark'+str(i+1)].append(loc_fault_new[1])\n",
    "# partitions\n",
    "x_centroid_partition = []\n",
    "y_centroid_partition = []\n",
    "for i in range(len(lon_centroid_partition)):\n",
    "    loc_centroid = np.array([lon_centroid_partition[i],lat_centroid_partition[i],1])\n",
    "    loc_centroid_new = np.dot(affine_matrix,loc_centroid)\n",
    "    x_centroid_partition.append(loc_centroid_new[0])\n",
    "    y_centroid_partition.append(loc_centroid_new[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_file = dir_inv_dispernet + 'vs_inter.npz'\n",
    "inter = np.load(inter_file, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_fund = inter['vs_fund']\n",
    "vs = inter['vs']\n",
    "x_inter_in = inter['x']\n",
    "y_inter_in = inter['y']\n",
    "z = inter['depth']\n",
    "dz = inter['dz']\n",
    "N = inter['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struc = {}\n",
    "struc_fund = {}\n",
    "flag = 0\n",
    "for key_subwork in key_subworks:\n",
    "    file_model = dir_model + 'model_'+key_subwork+'.txt'\n",
    "    file_model_fund = dir_model_fund + 'model_'+key_subwork+'.txt'\n",
    "    model = np.loadtxt(file_model)\n",
    "    model_fund = np.loadtxt(file_model_fund)\n",
    "    struc[key_subwork] = {}\n",
    "    struc[key_subwork]['layer'] = model[:, 0]\n",
    "    struc[key_subwork]['z'] = model[:, 1]\n",
    "    struc[key_subwork]['rho'] = model[:, 2]\n",
    "    struc[key_subwork]['vs'] = model[:, 3]\n",
    "    struc[key_subwork]['vp'] = model[:, 4]\n",
    "    struc[key_subwork]['std'] = model[:, 5]\n",
    "    struc_fund[key_subwork] = {}\n",
    "    struc_fund[key_subwork]['layer'] = model_fund[:, 0]\n",
    "    struc_fund[key_subwork]['z'] = model_fund[:, 1]\n",
    "    struc_fund[key_subwork]['rho'] = model_fund[:, 2]\n",
    "    struc_fund[key_subwork]['vs'] = model_fund[:, 3]\n",
    "    struc_fund[key_subwork]['vp'] = model_fund[:, 4]\n",
    "    struc_fund[key_subwork]['std'] = model_fund[:, 5]\n",
    "    flag += 1\n",
    "    print('Read structure model: %s (%d/%d)' % (key_subwork, flag, M))\n",
    "\n",
    "vs_horizon = {}\n",
    "vs_horizon_fund = {}\n",
    "for i in range(N):\n",
    "    vs_horizon[i] = []\n",
    "    vs_horizon_fund[i] = []\n",
    "    for key_subwork in key_subworks:\n",
    "        vs_horizon[i].append(struc[key_subwork]['vs'][i])\n",
    "        vs_horizon_fund[i].append(struc_fund[key_subwork]['vs'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    print('Plot horizon %d/%d' % (i+1,N))\n",
    "    fig = plt.figure(figsize=(20, 14))\n",
    "    ax = fig.add_subplot(221)\n",
    "    ax.scatter(x_stations_all_new, y_stations_all_new,marker='.',color='k')\n",
    "    #ax.set_xticks([])  #去掉横坐标值\n",
    "    #ax.set_yticks([])  #去掉纵坐标值\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('Vs at depth '+str((i+1)*dz)+' Fundamental')\n",
    "    flag_add = 0.0005\n",
    "    ax.set_xlim(-50,650)\n",
    "    ax.set_ylim(-50,650)\n",
    "    for j in range(len(faults)):\n",
    "        ax.plot(x_faults['clark'+str(j+1)], y_faults['clark'+str(j+1)], 'k')\n",
    "    im = ax.scatter(x_centroid_partition,y_centroid_partition,c=vs_horizon_fund[i],cmap='gist_rainbow',s=100)\n",
    "    plt.colorbar(im)\n",
    "    ax.set_title('Vs at depth '+str((i+1)*dz)+' Fundamental')\n",
    "    ax.set_xticks([])  #去掉横坐标值\n",
    "    ax.set_yticks([])  #去掉纵坐标值\n",
    "\n",
    "    ax = fig.add_subplot(222)\n",
    "    ax.scatter(x_stations_all_new, y_stations_all_new,marker='.',color='k')\n",
    "    for j in range(len(faults)):\n",
    "        ax.plot(x_faults['clark'+str(j+1)], y_faults['clark'+str(j+1)], 'k')\n",
    "    #im = plt.scatter(lon_inter_in, lat_inter_in, s=10, c=vs_inter_horizon_in[i], cmap='gist_rainbow', vmin=v_min, vmax=v_max)\n",
    "    im = plt.scatter(x_inter_in, y_inter_in, s=10, c=vs_fund[i], cmap='gist_rainbow')\n",
    "    plt.colorbar(im)\n",
    "    ax.set_xticks([])  #去掉横坐标值\n",
    "    ax.set_yticks([])  #去掉纵坐标值\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('Vs at depth '+str((i+1)*dz)+' Fundamental')\n",
    "    ax.set_xlim(-50,650)\n",
    "    ax.set_ylim(-50,650)\n",
    "    \n",
    "\n",
    "    ax = fig.add_subplot(223)\n",
    "    ax.scatter(x_stations_all_new, y_stations_all_new,marker='.',color='k')\n",
    "    #ax.set_xticks([])  #去掉横坐标值\n",
    "    #ax.set_yticks([])  #去掉纵坐标值\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('Vs at depth '+str((i+1)*dz)+' Fundamental')\n",
    "    flag_add = 0.0005\n",
    "    ax.set_xlim(-50,650)\n",
    "    ax.set_ylim(-50,650)\n",
    "    for j in range(len(faults)):\n",
    "        ax.plot(x_faults['clark'+str(j+1)], y_faults['clark'+str(j+1)], 'k')\n",
    "    im = ax.scatter(x_centroid_partition,y_centroid_partition,c=vs_horizon[i],cmap='gist_rainbow',s=100)\n",
    "    plt.colorbar(im)\n",
    "    ax.set_title('Vs at depth '+str((i+1)*dz)+' Overtones')\n",
    "    ax.set_xticks([])  #去掉横坐标值\n",
    "    ax.set_yticks([])  #去掉纵坐标值\n",
    "\n",
    "    ax = fig.add_subplot(224)\n",
    "    ax.scatter(x_stations_all_new, y_stations_all_new,marker='.',color='k')\n",
    "    for j in range(len(faults)):\n",
    "        ax.plot(x_faults['clark'+str(j+1)], y_faults['clark'+str(j+1)], 'k')\n",
    "    #im = plt.scatter(lon_inter_in, lat_inter_in, s=10, c=vs_inter_horizon_in[i], cmap='gist_rainbow', vmin=v_min, vmax=v_max)\n",
    "    im = plt.scatter(x_inter_in, y_inter_in, s=10, c=vs[i], cmap='gist_rainbow')\n",
    "    plt.colorbar(im)\n",
    "    ax.set_xticks([])  #去掉横坐标值\n",
    "    ax.set_yticks([])  #去掉纵坐标值\n",
    "    ax.set_xlim(-50,650)\n",
    "    ax.set_ylim(-50,650)\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Vs at depth '+str((i+1)*dz)+' Overtones')\n",
    "    plt.savefig(dir_image+'Vs_hori_'+str((i+1)*dz)+'m.png',dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccfj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
