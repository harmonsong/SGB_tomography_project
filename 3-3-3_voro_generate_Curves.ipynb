{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "#from scipy import interp, arange, exp\n",
    "from ccfj import GetStationPairs\n",
    "import ccfj\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import geopandas as gp\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tools_F-J')\n",
    "from toollib_voro import PointinPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('a-project_voro.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project_repartrition/output_repar_03-01/'               # Harmon server\n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_stack = dir_project+info_basic['rdir_stack']\n",
    "dir_CC = dir_CC_workspace+info_basic['rdira_CC']\n",
    "dir_ds = dir_project + info_basic['rdir_ds']\n",
    "dir_inv_dispernet = dir_project + info_basic['dir_inv_dispernet']\n",
    "stalistname_all = info_basic['stalistname_all']\n",
    "outdir = dir_inv_dispernet + 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Target Points matrix X,Y\n",
    "nx = 40\n",
    "ny = 40\n",
    "x = np.linspace(-116.596436,-116.586189,nx)\n",
    "y = np.linspace(33.535305,33.54248,ny)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "X = X.reshape(-1)\n",
    "Y = Y.reshape(-1)\n",
    "n = len(X)\n",
    "xv = [-116.596436, -116.59211, -116.586189, -116.590622]\n",
    "yv = [33.53941, 33.535305, 33.538368, 33.54248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the minima sample times\n",
    "min_number = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the Voronoi Partitions\n",
    "dsfiles = glob.glob(dir_ds+'/*h5')\n",
    "files = []\n",
    "for i in range(n):\n",
    "\tfiles.append([])\n",
    "for j in range(len(dsfiles)):\n",
    "\th5file = h5py.File(dsfiles[j],'r')\n",
    "\txvyv = h5file['xvyv'][:]\n",
    "\th5file.close()\n",
    "\t_in,_on = PointinPolygon.inpolygon(X, Y, xvyv[0,:], xvyv[1,:])\n",
    "\tindx = np.array([i for i,x in enumerate(_in) if x])\n",
    "\tfor i in indx:\n",
    "\t\tfiles[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the dispersion curves\n",
    "curves = []\n",
    "for fr in dsfiles:\n",
    "\tfr1 = os.path.join(dir_inv_dispernet + 'curves/',fr.split('/')[-1].split('.')[0]+'.txt')\n",
    "\tcurve = np.loadtxt(fr1)\n",
    "\tcurves.append(curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the dispersion curves of each target points\n",
    "for i in range(n):\n",
    "\tprint(i)\n",
    "\t_in,_on = PointinPolygon.inpolygon(X[i],Y[i],xv,yv)\n",
    "\tif not _in:\n",
    "\t\tcontinue\n",
    "\tfid = open(os.path.join(outdir,'curve'+str(i)+'.txt'),'w')\n",
    "\tfor modei in range(1):\n",
    "\t\tcs = []\n",
    "\t\tfor j in files[i]:\n",
    "\t\t\tcurve = curves[j]\n",
    "\t\t\tif len(curve[curve[:,2]==modei,2])>0:\n",
    "\t\t\t\tcs.append(curve[curve[:,2]==modei,:])\n",
    "\t\n",
    "\t\tminf = 10\n",
    "\t\tmaxf = 0\n",
    "\t\tfor csi in cs:\n",
    "\t\t\tif minf>np.min(csi[:,0]):\n",
    "\t\t\t\tminf = np.min(csi[:,0])\n",
    "\n",
    "\t\t\tif maxf <np.max(csi[:,0]):\n",
    "\t\t\t\tmaxf = np.max(csi[:,0])\n",
    "\t\tnf = int((maxf-minf)/0.1) + 1\n",
    "\t\tfor k in range(nf):\n",
    "\t\t\tc = []\n",
    "\t\t\tf = np.round(minf + k*0.1,2)\n",
    "\t\t\tfor csi in cs:\n",
    "\t\t\t\tindx = np.where(np.abs(csi[:,0]-f)<0.01)[0]\n",
    "\t\t\t\tif len(indx) > 0:\n",
    "\t\t\t\t\tc.append(csi[indx,1])\n",
    "\t\t\tc = np.asarray(c)/1e3\n",
    "\t\t\tif len(c) > min_number:\n",
    "\t\t\t\tmean = np.round(np.mean(c),3)\n",
    "\t\t\t\tstd = np.round(np.std(c),3)\n",
    "\t\t\t\tfid.write(str(f)+' '+str(mean)+' '+str(modei)+' '+str(std)+'\\n')\n",
    "\tfid.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
