{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "#from ccfj import GetStationPairs\n",
    "from geopy.distance import great_circle\n",
    "#import shapefile\n",
    "import geopandas as gp\n",
    "import yaml\n",
    "import math\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import griddata\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_project = 1 # 0--regular; 1--repartrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_project == 0:\n",
    "    file_project = 'a-project.yml'\n",
    "elif flag_project == 1:\n",
    "    file_project = 'a-project_repar.yml'\n",
    "elif flag_project == 2:\n",
    "    file_project = 'a-project_voro.yml'\n",
    "    \n",
    "with open(file_project, 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "\n",
    "#name_project = 'project/output_FJSJ_16-01/'               \n",
    "#name_project = 'project_repartrition/repartrition_01-03/'               \n",
    "#name_project = 'project_voronoi/voronoi_01-03/'         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_model_fund = dir_project + info_basic['dir_model_fund']\n",
    "dir_model = dir_project + info_basic['dir_model']\n",
    "dir_image = dir_project + info_basic['dir_image']+'Vs_compare/'\n",
    "if not os.path.exists(dir_image):\n",
    "    os.makedirs(dir_image)\n",
    "dir_inv_dispernet = dir_project + info_basic['dir_inv_dispernet']\n",
    "dir_partition = dir_project + info_basic['dir_partition']\n",
    "key_subworks = info_basic['key_subworks']\n",
    "M = len(key_subworks)\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetStationPairs(nsta):\n",
    "    StationPair = []\n",
    "    for ii in range(nsta):\n",
    "        for jj in range(ii+1,nsta):\n",
    "            StationPair.append(ii)\n",
    "            StationPair.append(jj)\n",
    "    StationPair = np.array(StationPair,dtype=np.int32)\n",
    "    return StationPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist() \n",
    "lat_stations_all =  stainfo['latitude'].tolist() \n",
    "lon_stations_all =  stainfo['longitude'].tolist() \n",
    "elevation_stations_all = stainfo['elevation'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_partition = {}\n",
    "lat_stations_partition = {}\n",
    "lon_stations_partition = {}\n",
    "lat_centroid_partition = []\n",
    "lon_centroid_partition = []\n",
    "num_stations = []\n",
    "for key in key_subworks:\n",
    "    filepath = dir_partition + str(key) + '.txt'\n",
    "    stations_this, lat_stations_this, lon_stations_this = np.loadtxt(filepath, dtype='str' , unpack=True)\n",
    "    stations_partition[key] = stations_this\n",
    "    lat_stations_partition[key] = lat_stations_this.astype(float)\n",
    "    lon_stations_partition[key] = lon_stations_this.astype(float)\n",
    "    num_stations.append(len(stations_this))\n",
    "    lat_centroid_partition.append(np.mean(lat_stations_this.astype(float)))\n",
    "    lon_centroid_partition.append(np.mean(lon_stations_this.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = np.load('clark_faults.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_affine_transform(original_points, target_points):\n",
    "    A_matrix = np.array([[original_points[0][0], original_points[0][1], 1, 0, 0, 0],\n",
    "                         [0, 0, 0, original_points[0][0], original_points[0][1], 1],\n",
    "                         [original_points[1][0], original_points[1][1], 1, 0, 0, 0],\n",
    "                         [0, 0, 0, original_points[1][0], original_points[1][1], 1],\n",
    "                         [original_points[2][0], original_points[2][1], 1, 0, 0, 0],\n",
    "                         [0, 0, 0, original_points[2][0], original_points[2][1], 1]])\n",
    "\n",
    "    A1_B1_C1 = np.array([target_points[0][0], target_points[0][1], target_points[1][0], target_points[1][1], target_points[2][0], target_points[2][1]])\n",
    "\n",
    "    coefficients = np.linalg.solve(A_matrix, A1_B1_C1)\n",
    "\n",
    "    affine_matrix = np.array([[coefficients[0], coefficients[1], coefficients[2]],\n",
    "                               [coefficients[3], coefficients[4], coefficients[5]],\n",
    "                               [0, 0, 1]])\n",
    "\n",
    "    return affine_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transformation\n",
    "lon_stations_all_new = []\n",
    "lat_stations_all_new = []\n",
    "stalist_all_new = []\n",
    "elevation_stations_all_new = []\n",
    "for sta in stalist_all:\n",
    "    if int(sta[1:3]) <= 60:\n",
    "        lon_stations_all_new.append(lon_stations_all[stalist_all.index(sta)])\n",
    "        lat_stations_all_new.append(lat_stations_all[stalist_all.index(sta)])\n",
    "        stalist_all_new.append(sta)\n",
    "        elevation_stations_all_new.append(elevation_stations_all[stalist_all.index(sta)])\n",
    "refs = ['R0101','R6001','R6020']\n",
    "lon_refs = [lon_stations_all[stalist_all.index(ref)] for ref in refs]\n",
    "lat_refs = [lat_stations_all[stalist_all.index(ref)] for ref in refs]\n",
    "loc_refs = np.column_stack([lon_refs,lat_refs])\n",
    "loc_refs_new = np.array([[0,0],[600,0],[600,600]])\n",
    "\n",
    "affine_matrix = compute_affine_transform(loc_refs, loc_refs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points = np.column_stack((lon_stations_all, lat_stations_all))\n",
    "points = np.column_stack((lon_centroid_partition, lat_centroid_partition))\n",
    "hull = ConvexHull(points)\n",
    "polygon = Polygon(points[hull.vertices])\n",
    "index_sta = []\n",
    "lon_stations_in = []\n",
    "lat_stations_in = []\n",
    "elevation_stations_in = []\n",
    "for i in range(len(lon_stations_all)):\n",
    "    if polygon.contains(Point(lon_stations_all[i], lat_stations_all[i])):\n",
    "        index_sta.append(i)\n",
    "        lon_stations_in.append(lon_stations_all[i])\n",
    "        lat_stations_in.append(lat_stations_all[i])\n",
    "        elevation_stations_in.append(elevation_stations_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all stations\n",
    "x_stations_all_new = []\n",
    "y_stations_all_new = []\n",
    "for i in range(len(lon_stations_all_new)):\n",
    "    loc_sta = np.array([lon_stations_all_new[i],lat_stations_all_new[i],1])\n",
    "    loc_sta_new = np.dot(affine_matrix,loc_sta)\n",
    "    x_stations_all_new.append(loc_sta_new[0])\n",
    "    y_stations_all_new.append(loc_sta_new[1])\n",
    "# In station\n",
    "x_stations_in = []\n",
    "y_stations_in = []\n",
    "for i in range(len(lon_stations_in)):\n",
    "    loc_sta = np.array([lon_stations_in[i],lat_stations_in[i],1])\n",
    "    loc_sta_new = np.dot(affine_matrix,loc_sta)\n",
    "    x_stations_in.append(loc_sta_new[0])\n",
    "    y_stations_in.append(loc_sta_new[1])\n",
    "# faults\n",
    "x_faults = {}\n",
    "y_faults = {}\n",
    "for i in range(len(faults)):\n",
    "    x_faults['clark'+str(i+1)] = []\n",
    "    y_faults['clark'+str(i+1)] = []\n",
    "    for j in range(len(faults['clark'+str(i+1)]['lon'])):\n",
    "        loc_fault = np.array([faults['clark'+str(i+1)]['lon'][j],faults['clark'+str(i+1)]['lat'][j],1])\n",
    "        loc_fault_new = np.dot(affine_matrix,loc_fault)\n",
    "        x_faults['clark'+str(i+1)].append(loc_fault_new[0])\n",
    "        y_faults['clark'+str(i+1)].append(loc_fault_new[1])\n",
    "# partitions\n",
    "x_centroid_partition = []\n",
    "y_centroid_partition = []\n",
    "for i in range(len(lon_centroid_partition)):\n",
    "    loc_centroid = np.array([lon_centroid_partition[i],lat_centroid_partition[i],1])\n",
    "    loc_centroid_new = np.dot(affine_matrix,loc_centroid)\n",
    "    x_centroid_partition.append(loc_centroid_new[0])\n",
    "    y_centroid_partition.append(loc_centroid_new[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_file = dir_inv_dispernet + 'vs_inter.npz'\n",
    "inter = np.load(inter_file, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_fund = inter['vs_fund']\n",
    "vs = inter['vs']\n",
    "x_inter_in = inter['x']\n",
    "y_inter_in = inter['y']\n",
    "ele_inter_in = inter['ele']\n",
    "z = inter['depth']\n",
    "dz = inter['dz']\n",
    "N = inter['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "ax  = fig.add_subplot(121)\n",
    "ax.scatter(x_stations_all_new, y_stations_all_new,marker='.',color='k')\n",
    "ax.set_xticks([])  #去掉横坐标值\n",
    "ax.set_yticks([])  #去掉纵坐标值\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('Elevation')\n",
    "ax.set_xlim(-50,650)\n",
    "ax.set_ylim(-50,650)\n",
    "for j in range(len(faults)):\n",
    "    ax.plot(x_faults['clark'+str(j+1)], y_faults['clark'+str(j+1)], 'k')\n",
    "im = ax.scatter(x_stations_all_new,y_stations_all_new,c=elevation_stations_all_new,cmap='gist_rainbow',s=100)\n",
    "plt.colorbar(im)\n",
    "\n",
    "ax  = fig.add_subplot(122)\n",
    "ax.scatter(x_stations_all_new, y_stations_all_new,marker='.',color='k')\n",
    "ax.set_xticks([])  #去掉横坐标值\n",
    "ax.set_yticks([])  #去掉纵坐标值\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('Elevation')\n",
    "ax.set_xlim(-50,650)\n",
    "ax.set_ylim(-50,650)\n",
    "for j in range(len(faults)):\n",
    "    ax.plot(x_faults['clark'+str(j+1)], y_faults['clark'+str(j+1)], 'k')\n",
    "im = ax.scatter(x_stations_in,y_stations_in,c=elevation_stations_in,cmap='gist_rainbow',s=100)\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do clipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define traces\n",
    "traces = {}\n",
    "for i in range(4,18):\n",
    "    y = 30*(i-1)\n",
    "    traces[i] = np.zeros([2,2])\n",
    "    traces[i][0,0] = np.min(x_inter_in)\n",
    "    traces[i][0,1] = y\n",
    "    traces[i][1,0] = np.max(x_inter_in)\n",
    "    traces[i][1,1] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_points(tag_trace,x_inter_in,y_inter_in):\n",
    "    global traces\n",
    "    trace = traces[tag_trace]\n",
    "\n",
    "    x1 = trace[0,0]\n",
    "    y1 = trace[0,1]\n",
    "    x2 = trace[1,0]\n",
    "    y2 = trace[1,1]\n",
    "    A = (y2-y1)/(x2-x1)\n",
    "    B = -1\n",
    "    C = y2 - A*x2\n",
    "\n",
    "    flag_r = np.sqrt(( (y_inter_in[1]-y_inter_in[0])**2 + (x_inter_in[1]-x_inter_in[0])**2 ))/2\n",
    "    index = []\n",
    "    \n",
    "    for i in range(len(x_inter_in)):\n",
    "        x0 = x_inter_in[i]\n",
    "        y0 = y_inter_in[i]\n",
    "        d = abs(A*x0+B*y0+C)/math.sqrt(A**2+B**2)\n",
    "        if d <= flag_r:\n",
    "            index.append(i)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersection_point(point1_line, point2_line, external_point):\n",
    "    # 计算直线的斜率\n",
    "    line_slope = (point2_line[1] - point1_line[1]) / (point2_line[0] - point1_line[0])\n",
    "    \n",
    "    if line_slope == 0:\n",
    "        #print('slope == 0')\n",
    "        #print(external_point[1],point1_line[0])\n",
    "        return  point1_line[0],external_point[1]\n",
    "    # 计算直线的截距\n",
    "    line_intercept = point1_line[1] - line_slope * point1_line[0]\n",
    "\n",
    "    # 计算垂线的斜率\n",
    "    perpendicular_slope = -1 / line_slope\n",
    "\n",
    "    # 计算垂线的截距\n",
    "    perpendicular_intercept = external_point[1] - perpendicular_slope * external_point[0]\n",
    "\n",
    "    # 求解方程组以找到交点\n",
    "    intersection_x = (perpendicular_intercept - line_intercept) / (line_slope - perpendicular_slope)\n",
    "    intersection_y = line_slope * intersection_x + line_intercept\n",
    "\n",
    "    return intersection_x, intersection_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inter_verti = {}\n",
    "y_inter_verti = {}\n",
    "vs_inter_verti = {}\n",
    "vs_inter_fund_verti = {}   \n",
    "ele_verti = {}\n",
    "indexes = {}\n",
    "loc_starts = {}\n",
    "for tag in traces.keys():\n",
    "    print(tag)\n",
    "    #index = extract_points(tag,x_inter_in,y_inter_in)\n",
    "    yy = list(set(y_inter_in))\n",
    "    index_this = np.argmin(np.abs(yy-traces[tag][0][1]))\n",
    "    index = np.where(y_inter_in == yy[index_this])[0]\n",
    "    \n",
    "    indexes[tag] = index\n",
    "    x_inter_verti[tag] = np.array(x_inter_in)[index]\n",
    "    y_inter_verti[tag] = np.array(y_inter_in)[index]\n",
    "    \n",
    "    vs_inter_verti[tag] = []\n",
    "    vs_inter_fund_verti[tag] = []\n",
    "    ele_verti[tag] = []\n",
    "    loc_start = find_intersection_point(traces[tag][0], traces[tag][1], [x_inter_verti[tag][0], y_inter_verti[tag][0]])\n",
    "    loc_starts[tag] = loc_start\n",
    "    for i in range(N):\n",
    "        vs_inter_verti[tag].append(vs[i,index])\n",
    "        vs_inter_fund_verti[tag].append(vs_fund[i,index])\n",
    "    ele_verti[tag].append(np.array(ele_inter_in)[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断两条线段是否相交\n",
    "def cross_product(p1, p2, p3):\n",
    "    \"\"\"计算叉积\"\"\"\n",
    "    return (p2[0] - p1[0]) * (p3[1] - p1[1]) - (p2[1] - p1[1]) * (p3[0] - p1[0])\n",
    "\n",
    "def on_segment(p1, p2, p3):\n",
    "    \"\"\"检查p2是否在以p1和p3为端点的线段上\"\"\"\n",
    "    print('on segement')\n",
    "    return min(p1[0], p3[0]) <= p2[0] <= max(p1[0], p3[0]) and min(p1[1], p3[1]) <= p2[1] <= max(p1[1], p3[1])\n",
    "\n",
    "def segments_intersect(p1, q1, p2, q2):\n",
    "    \"\"\"检查由(p1, q1)和(p2, q2)形成的两条线段是否相交\"\"\"\n",
    "    # 检查线段的方向\n",
    "    o1 = cross_product(p1, q1, p2)\n",
    "    o2 = cross_product(p1, q1, q2)\n",
    "    o3 = cross_product(p2, q2, p1)\n",
    "    o4 = cross_product(p2, q2, q1)\n",
    "\n",
    "    # 如果两条线段的方向相异，则它们相交\n",
    "    if o1 * o2 < 0 and o3 * o4 < 0:\n",
    "        return True\n",
    "    # 特殊情况处理\n",
    "    if o1 == 0 and on_segment(p1, p2, q1):\n",
    "        return True\n",
    "    if o2 == 0 and on_segment(p1, q2, q1):\n",
    "        return True\n",
    "    if o3 == 0 and on_segment(p2, p1, q2):\n",
    "        return True\n",
    "    if o4 == 0 and on_segment(p2, q1, q2):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def plot_segments(p1, q1, p2, q2):\n",
    "    plt.plot([p1[0], q1[0]], [p1[1], q1[1]], color='blue', label='Segment 1')\n",
    "    plt.plot([p2[0], q2[0]], [p2[1], q2[1]], color='red', label='Segment 2')\n",
    "\n",
    "    intersection = segments_intersect(p1, q1, p2, q2)\n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Segments Intersection')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fault_inter(tag_trace):\n",
    "    global traces\n",
    "    global faults\n",
    "    global x_faults\n",
    "    global y_faults\n",
    "    global x_inter_verti\n",
    "    global y_inter_verti\n",
    "\n",
    "    x_fault_inter = []\n",
    "    y_fault_inter = []\n",
    "\n",
    "    for key in faults.keys():\n",
    "        x_fault = x_faults[key]\n",
    "        y_fault = y_faults[key]\n",
    "        index_fault_start = np.argmin(y_fault)\n",
    "        index_fault_end = np.argmax(y_fault)\n",
    "        p1 = [x_fault[index_fault_start], y_fault[index_fault_start]]\n",
    "        q1 = [x_fault[index_fault_end], y_fault[index_fault_end]]\n",
    "        index_trace_start = np.argmin(x_inter_verti[tag_trace])\n",
    "        index_trace_end = np.argmax(x_inter_verti[tag_trace])\n",
    "        p2 = [x_inter_verti[tag_trace][index_trace_start], y_inter_verti[tag_trace][index_trace_start]]\n",
    "        q2 = [x_inter_verti[tag_trace][index_trace_end], y_inter_verti[tag_trace][index_trace_end]]\n",
    "        \n",
    "        if segments_intersect(p1, q1, p2, q2):\n",
    "            # find the nearest fault point\n",
    "            x_trace = x_inter_verti[tag_trace]\n",
    "            y_trace = y_inter_verti[tag_trace]\n",
    "\n",
    "            min_distance = float('inf')\n",
    "\n",
    "            for lon1, lat1 in zip(x_fault, y_fault):\n",
    "                for lon2, lat2 in zip(x_trace, y_trace):\n",
    "                    distance = math.sqrt((lon1 - lon2)**2 + (lat1 - lat2)**2)\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        x_fault_near = lon1\n",
    "                        y_fault_near = lat1\n",
    "                        x_trace_near = lon2\n",
    "                        y_trace_near = lat2\n",
    "                    \n",
    "            x_fault_inter.append( x_trace_near )\n",
    "            y_fault_inter.append( y_trace_near )\n",
    "        \n",
    "        \"\"\"\n",
    "        intersection = find_lines_inter(p1, q1, p2, q2)\n",
    "        if intersection is not None:\n",
    "            lon_fault_inter.append(intersection[0])\n",
    "            lat_fault_inter.append(intersection[1])\n",
    "        \"\"\"\n",
    "    return x_fault_inter, y_fault_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_min = 0.45\n",
    "v_max = 1.15\n",
    "#v_min = 0.3\n",
    "#v_max = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(traces.keys()):\n",
    "    print('Plotting trace %d' % i)\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    ax1 = plt.subplot2grid((18,3),(2,0),colspan=2,rowspan=7)\n",
    "    im = ax1.imshow(vs_inter_fund_verti[i], aspect='auto', cmap='gist_rainbow', extent=[np.min(x_inter_verti[i]),np.max(x_inter_verti[i]),N*dz,0], vmin=v_min, vmax=v_max)\n",
    "    ax1.set_xticks([])  #去掉横坐标值\n",
    "    ax1.set_ylabel('Depth /m Fundamental')\n",
    "    ax1.set_xlim([np.min(x_inter_in),np.max(x_inter_in)])\n",
    "    # 找到断层点\n",
    "    x_fault_inter, y_fault_inter = find_fault_inter(i)\n",
    "    for j in range(len(x_fault_inter)):\n",
    "        ax1.vlines(x_fault_inter[j], 0, N/10*dz, colors = \"k\", linestyles = \"dashed\")\n",
    "    ax1.set_title('Fundamental')\n",
    "    plt.colorbar(im,orientation='horizontal',aspect=100,fraction=0.05,pad=0.05)\n",
    "\n",
    "\n",
    "    ax2 = plt.subplot2grid((18,3),(10,0),colspan=2,rowspan=8)\n",
    "    im = ax2.imshow(vs_inter_verti[i], aspect='auto', cmap='gist_rainbow', extent=[np.min(x_inter_verti[i]),np.max(x_inter_verti[i]),N*dz,0], vmin=v_min, vmax=v_max)\n",
    "    #ax3.set_xticks([])  #去掉横坐标值\n",
    "    ax2.set_xlabel('Offset')\n",
    "    ax2.set_ylabel('Depth /m Overtones')\n",
    "    ax2.set_xlim([np.min(x_inter_in),np.max(x_inter_in)])\n",
    "    # 找到断层点\n",
    "    #lon_fault_inter, lat_fault_inter = find_fault_inter(i)\n",
    "    for j in range(len(x_fault_inter)):\n",
    "        ax2.vlines(x_fault_inter[j], 0, N/10*dz, colors = \"k\", linestyles = \"dashed\")\n",
    "    ax2.set_title('Overtones')\n",
    "    \n",
    "\n",
    "\n",
    "    axele = plt.subplot2grid((18,3),(0,0),colspan=2,rowspan=1)\n",
    "    axele.set_xticks([])  #去掉横坐标值\n",
    "    #axele.set_yticks([])  #去掉纵坐标值\n",
    "    axele.set_ylabel('Elev')\n",
    "    axele.spines['top'].set_visible(False)\n",
    "    \n",
    "\n",
    "    # 画ele的柱状图\n",
    "    #index_r = np.argsort(r_ele[i])\n",
    "    #axele.plot(r_ele[i][index_r], ele_verti[i][0][index_r]-min(ele_verti[i][0]), color='k')\n",
    "    #axele.fill_between(r_ele[i][index_r], 0, ele_verti[i][0][index_r]-min(ele_verti[i][0]), color='k', alpha=0.5)\n",
    "    \n",
    "    axele.plot(x_inter_verti[i],ele_verti[i][0]-min(ele_verti[i][0]),color='k')\n",
    "    axele.fill_between(x_inter_verti[i],0,ele_verti[i][0]-min(ele_verti[i][0]),color='k',alpha = 0.5)\n",
    "    for j in range(len(x_fault_inter)):\n",
    "        axele.vlines(x_fault_inter[j], 0, max(ele_verti[i][0]-min(ele_verti[i][0])), colors = \"k\", linestyles = \"dashed\")\n",
    "    axele.set_xlim([np.min(x_inter_in),np.max(x_inter_in)])\n",
    "\n",
    "    ax3 = plt.subplot2grid((2,3),(0,2),colspan=1,rowspan=1)\n",
    "    ax3.scatter(x_stations_all_new, y_stations_all_new, c='k', s=0.08)\n",
    "    for j in range(len(faults)):\n",
    "        ax3.plot(x_faults['clark'+str(j+1)], y_faults['clark'+str(j+1)], 'k')\n",
    "    ax3.scatter(x_inter_in, y_inter_in, c='b', s=0.1)\n",
    "    ax3.scatter(np.array(x_inter_in)[indexes[i]], np.array(y_inter_in)[indexes[i]], c='r', s=0.3)\n",
    "    ax3.scatter(x_fault_inter, y_fault_inter, c='y', s=50)\n",
    "    ax3.set_xlim(-50,650)\n",
    "    ax3.set_ylim(-50,650)\n",
    "    ax3.set_xticks([])  #去掉横坐标值\n",
    "    ax3.set_yticks([])  #去掉纵坐标值\n",
    "    ax3.set_xlabel('X')\n",
    "    ax3.set_ylabel('Y')\n",
    "\n",
    "\n",
    "    ax4 = plt.subplot2grid((2,3),(1,2),colspan=1,rowspan=1)\n",
    "    ax4.scatter(x_stations_all_new, y_stations_all_new,marker='.',color='k',s=0.08)\n",
    "    ax4.set_xticks([])  #去掉横坐标值\n",
    "    ax4.set_yticks([])  #去掉纵坐标值\n",
    "    ax4.set_xlabel('X')\n",
    "    ax4.set_ylabel('Y')\n",
    "    ax4.set_title('Elevation')\n",
    "    ax4.set_xlim(-50,650)\n",
    "    ax4.set_ylim(-50,650)\n",
    "    for j in range(len(faults)):\n",
    "        ax4.plot(x_faults['clark'+str(j+1)], y_faults['clark'+str(j+1)], 'k')\n",
    "    im = ax4.scatter(x_stations_in,y_stations_in,c=elevation_stations_in,cmap='gist_rainbow',s=20)\n",
    "    ax4.plot(np.array(x_inter_in)[indexes[i]], np.array(y_inter_in)[indexes[i]], c='b')\n",
    "    #plt.colorbar(im, ax=ax4, location='top', shrink=0.6)\n",
    " \n",
    "    cax = inset_axes(ax4,\n",
    "                 width=\"1%\",  # colorbar宽度占主轴宽度的百分比\n",
    "                 height=\"50%\",  # colorbar高度占主轴高度的百分比\n",
    "                 loc='upper right')  # 在右上角放置colorbar\n",
    "    cbar = plt.colorbar(im, cax=cax, orientation='vertical')\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig(dir_image+'Vs_verticle_trace_'+str(i)+'.png')\n",
    "    #plt.savefig(dir_image+'Vs_shallow_verticle_trace_'+str(i)+'.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccfj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
