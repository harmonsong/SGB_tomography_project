{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "#from ccfj import GetStationPairs\n",
    "from geopy.distance import great_circle\n",
    "#import shapefile\n",
    "import geopandas as gp\n",
    "import yaml\n",
    "import math\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import griddata\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_project = 1 # 0--regular; 1--repartrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_project == 0:\n",
    "    file_project = 'a-project.yml'\n",
    "elif flag_project == 1:\n",
    "    file_project = 'a-project_repar.yml'\n",
    "elif flag_project == 2:\n",
    "    file_project = 'a-project_voro.yml'\n",
    "    \n",
    "with open(file_project, 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "\n",
    "#name_project = 'project/output_FJSJ_16-01/'               \n",
    "#name_project = 'project_repartrition/repartrition_01-03/'               \n",
    "#name_project = 'project_voronoi/voronoi_01-03/'         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_model_fund = dir_project + info_basic['dir_model_fund']\n",
    "dir_model = dir_project + info_basic['dir_model']\n",
    "dir_image = dir_project + info_basic['dir_image']+'Vs_compare/'\n",
    "if not os.path.exists(dir_image):\n",
    "    os.makedirs(dir_image)\n",
    "dir_inv_dispernet = dir_project + info_basic['dir_inv_dispernet']\n",
    "dir_partition = dir_project + info_basic['dir_partition']\n",
    "key_subworks = info_basic['key_subworks']\n",
    "M = len(key_subworks)\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetStationPairs(nsta):\n",
    "    StationPair = []\n",
    "    for ii in range(nsta):\n",
    "        for jj in range(ii+1,nsta):\n",
    "            StationPair.append(ii)\n",
    "            StationPair.append(jj)\n",
    "    StationPair = np.array(StationPair,dtype=np.int32)\n",
    "    return StationPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist() \n",
    "lat_stations_all =  stainfo['latitude'].tolist() \n",
    "lon_stations_all =  stainfo['longitude'].tolist() \n",
    "elevation_stations_all = stainfo['elevation'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_partition = {}\n",
    "lat_stations_partition = {}\n",
    "lon_stations_partition = {}\n",
    "lat_centroid_partition = []\n",
    "lon_centroid_partition = []\n",
    "num_stations = []\n",
    "for key in key_subworks:\n",
    "    filepath = dir_partition + str(key) + '.txt'\n",
    "    stations_this, lat_stations_this, lon_stations_this = np.loadtxt(filepath, dtype='str' , unpack=True)\n",
    "    stations_partition[key] = stations_this\n",
    "    lat_stations_partition[key] = lat_stations_this.astype(float)\n",
    "    lon_stations_partition[key] = lon_stations_this.astype(float)\n",
    "    num_stations.append(len(stations_this))\n",
    "    lat_centroid_partition.append(np.mean(lat_stations_this.astype(float)))\n",
    "    lon_centroid_partition.append(np.mean(lon_stations_this.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = np.load('clark_faults.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate 3D structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = 3\n",
    "N = 68\n",
    "#N  = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struc = {}\n",
    "struc_fund = {}\n",
    "flag = 0\n",
    "for key_subwork in key_subworks:\n",
    "    file_model = dir_model + 'model_'+key_subwork+'.txt'\n",
    "    file_model_fund = dir_model_fund + 'model_'+key_subwork+'.txt'\n",
    "    model = np.loadtxt(file_model)\n",
    "    model_fund = np.loadtxt(file_model_fund)\n",
    "    struc[key_subwork] = {}\n",
    "    struc[key_subwork]['layer'] = model[:, 0]\n",
    "    struc[key_subwork]['z'] = model[:, 1]\n",
    "    struc[key_subwork]['rho'] = model[:, 2]\n",
    "    struc[key_subwork]['vs'] = model[:, 3]\n",
    "    struc[key_subwork]['vp'] = model[:, 4]\n",
    "    struc[key_subwork]['std'] = model[:, 5]\n",
    "    struc_fund[key_subwork] = {}\n",
    "    struc_fund[key_subwork]['layer'] = model_fund[:, 0]\n",
    "    struc_fund[key_subwork]['z'] = model_fund[:, 1]\n",
    "    struc_fund[key_subwork]['rho'] = model_fund[:, 2]\n",
    "    struc_fund[key_subwork]['vs'] = model_fund[:, 3]\n",
    "    struc_fund[key_subwork]['vp'] = model_fund[:, 4]\n",
    "    struc_fund[key_subwork]['std'] = model_fund[:, 5]\n",
    "    flag += 1\n",
    "    print('Read structure model: %s (%d/%d)' % (key_subwork, flag, M))\n",
    "\n",
    "vs_horizon = {}\n",
    "vs_horizon_fund = {}\n",
    "for i in range(N):\n",
    "    vs_horizon[i] = []\n",
    "    vs_horizon_fund[i] = []\n",
    "    for key_subwork in key_subworks:\n",
    "        vs_horizon[i].append(struc[key_subwork]['vs'][i])\n",
    "        vs_horizon_fund[i].append(struc_fund[key_subwork]['vs'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lons = 100\n",
    "num_lats = 100\n",
    "type_interp = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points = np.column_stack((lon_stations_all, lat_stations_all))\n",
    "points = np.column_stack((lon_centroid_partition, lat_centroid_partition))\n",
    "hull = ConvexHull(points)\n",
    "polygon = Polygon(points[hull.vertices])\n",
    "index_sta = []\n",
    "lon_stations_in = []\n",
    "lat_stations_in = []\n",
    "elevation_stations_in = []\n",
    "for i in range(len(lon_stations_all)):\n",
    "    if polygon.contains(Point(lon_stations_all[i], lat_stations_all[i])):\n",
    "        index_sta.append(i)\n",
    "        lon_stations_in.append(lon_stations_all[i])\n",
    "        lat_stations_in.append(lat_stations_all[i])\n",
    "        elevation_stations_in.append(elevation_stations_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate grid\n",
    "xx = np.linspace(np.min(lon_centroid_partition), np.max(lon_centroid_partition), num_lons)\n",
    "yy = np.linspace(np.min(lat_centroid_partition), np.max(lat_centroid_partition), num_lats)\n",
    "A,B = np.meshgrid(xx, yy)\n",
    "X_star = np.hstack((A.flatten()[:,None], B.flatten()[:,None]))\n",
    "lon_grid = X_star[:,0]\n",
    "lat_grid = X_star[:,1]\n",
    "# cut\n",
    "points = np.column_stack((lon_centroid_partition, lat_centroid_partition))\n",
    "hull = ConvexHull(points)\n",
    "polygon = Polygon(points[hull.vertices])\n",
    "index = []\n",
    "lon_inter_in = []\n",
    "lat_inter_in = []\n",
    "for i in range(len(lon_grid)):\n",
    "    if polygon.contains(Point(lon_grid[i], lat_grid[i])):\n",
    "        index.append(i)\n",
    "        lon_inter_in.append(lon_grid[i])\n",
    "        lat_inter_in.append(lat_grid[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "ax  = fig.add_subplot(121)\n",
    "ax.scatter(lon_stations_all, lat_stations_all,marker='.',color='k')\n",
    "ax.set_xticks([])  #去掉横坐标值\n",
    "ax.set_yticks([])  #去掉纵坐标值\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Elevation')\n",
    "flag_add = 0.0005\n",
    "ax.set_xlim([min(lon_stations_all)-flag_add, max(lon_stations_all)+flag_add])\n",
    "ax.set_ylim([min(lat_stations_all)-flag_add, max(lat_stations_all)+flag_add])\n",
    "for j in range(len(faults)):\n",
    "    ax.plot(faults['clark'+str(j+1)]['lon'], faults['clark'+str(j+1)]['lat'], 'k')\n",
    "im = ax.scatter(lon_stations_all,lat_stations_all,c=elevation_stations_all,cmap='gist_rainbow',s=100)\n",
    "plt.colorbar(im)\n",
    "\n",
    "ax  = fig.add_subplot(122)\n",
    "ax.scatter(lon_stations_all, lat_stations_all,marker='.',color='k')\n",
    "ax.set_xticks([])  #去掉横坐标值\n",
    "ax.set_yticks([])  #去掉纵坐标值\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Elevation')\n",
    "flag_add = 0.0005\n",
    "ax.set_xlim([min(lon_stations_all)-flag_add, max(lon_stations_all)+flag_add])\n",
    "ax.set_ylim([min(lat_stations_all)-flag_add, max(lat_stations_all)+flag_add])\n",
    "for j in range(len(faults)):\n",
    "    ax.plot(faults['clark'+str(j+1)]['lon'], faults['clark'+str(j+1)]['lat'], 'k')\n",
    "im = ax.scatter(lon_stations_in,lat_stations_in,c=elevation_stations_in,cmap='gist_rainbow',s=100)\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_inter_horizon_all = {}\n",
    "vs_inter_fund_horizon_all = {}\n",
    "vs_inter_fund_horizon_in = {}\n",
    "vs_inter_horizon_in = {}\n",
    "for i in range(N):\n",
    "    print('Interpolating horizon %d/%d' % (i+1,N))\n",
    "    OK = OrdinaryKriging(lon_centroid_partition, lat_centroid_partition, vs_horizon[i], variogram_model=type_interp,nlags=3)\n",
    "    zz,ss = OK.execute('grid', xx, yy)\n",
    "    vs_inter_horizon_all[i] = zz.reshape(len(xx)*len(yy))\n",
    "    vs_inter_horizon_in[i] = zz.reshape(len(xx)*len(yy))[index]\n",
    "    OK = OrdinaryKriging(lon_centroid_partition, lat_centroid_partition, vs_horizon_fund[i], variogram_model=type_interp,nlags=3)\n",
    "    zz,ss = OK.execute('grid', xx, yy)\n",
    "    vs_inter_fund_horizon_all[i] = zz.reshape(len(xx)*len(yy))\n",
    "    vs_inter_fund_horizon_in[i] = zz.reshape(len(xx)*len(yy))[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do clipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define traces\n",
    "traces = {}\n",
    "for i in range(4,18):\n",
    "    traces[i] = np.zeros([2,2])\n",
    "    sta_start = 'R'+'20'+str(i).zfill(2)\n",
    "    sta_end = 'R'+'30'+str(i).zfill(2)\n",
    "    if sta_start not in stalist_all:\n",
    "        print('Warning: start station %s not found' % sta_start)\n",
    "    if sta_end not in stalist_all:\n",
    "        print('Warning: end station %s not found' % sta_end)\n",
    "    traces[i][0,0] = lon_stations_all[stalist_all.index(sta_start)]\n",
    "    traces[i][0,1] = lat_stations_all[stalist_all.index(sta_start)]\n",
    "    traces[i][1,0] = lon_stations_all[stalist_all.index(sta_end)]\n",
    "    traces[i][1,1] = lat_stations_all[stalist_all.index(sta_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_points(tag_trace,lon_inter_in,lat_inter_in):\n",
    "    global traces\n",
    "    trace = traces[tag_trace]\n",
    "\n",
    "    x1 = trace[0,0]\n",
    "    y1 = trace[0,1]\n",
    "    x2 = trace[1,0]\n",
    "    y2 = trace[1,1]\n",
    "    A = (y2-y1)/(x2-x1)\n",
    "    B = -1\n",
    "    C = y2 - A*x2\n",
    "\n",
    "    flag_r = np.sqrt(( (lon_inter_in[1]-lon_inter_in[0])**2 + (lat_inter_in[1]-lat_inter_in[0])**2 ))/2\n",
    "    index = []\n",
    "    \n",
    "    for i in range(len(lon_inter_in)):\n",
    "        x0 = lon_inter_in[i]\n",
    "        y0 = lat_inter_in[i]\n",
    "        d = abs(A*x0+B*y0+C)/math.sqrt(A**2+B**2)\n",
    "        if d <= flag_r:\n",
    "            index.append(i)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersection_point(point1_line, point2_line, external_point):\n",
    "    # 计算直线的斜率\n",
    "    line_slope = (point2_line[1] - point1_line[1]) / (point2_line[0] - point1_line[0])\n",
    "\n",
    "    # 计算直线的截距\n",
    "    line_intercept = point1_line[1] - line_slope * point1_line[0]\n",
    "\n",
    "    # 计算垂线的斜率\n",
    "    perpendicular_slope = -1 / line_slope\n",
    "\n",
    "    # 计算垂线的截距\n",
    "    perpendicular_intercept = external_point[1] - perpendicular_slope * external_point[0]\n",
    "\n",
    "    # 求解方程组以找到交点\n",
    "    intersection_x = (perpendicular_intercept - line_intercept) / (line_slope - perpendicular_slope)\n",
    "    intersection_y = line_slope * intersection_x + line_intercept\n",
    "\n",
    "    return intersection_x, intersection_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_inter_verti = {}\n",
    "lat_inter_verti = {}\n",
    "vs_inter_verti = {}\n",
    "vs_inter_fund_verti = {}   \n",
    "lon_ele_verti = {}\n",
    "lat_ele_verti = {} \n",
    "ele_verti = {}\n",
    "r = {}\n",
    "r_ele = {}\n",
    "indexes = {}\n",
    "indexes_ele = {}\n",
    "loc_starts = {}\n",
    "loc_ele_starts = {}\n",
    "for tag in traces.keys():\n",
    "    index = extract_points(tag,lon_inter_in,lat_inter_in)\n",
    "    indexes[tag] = index\n",
    "    index_ele = extract_points(tag,lon_stations_in,lat_stations_in)\n",
    "    indexes_ele[tag] = index_ele\n",
    "    lon_inter_verti[tag] = np.array(lon_inter_in)[index]\n",
    "    lat_inter_verti[tag] = np.array(lat_inter_in)[index]\n",
    "    lon_ele_verti[tag] = np.array(lon_stations_in)[index_ele]\n",
    "    lat_ele_verti[tag] = np.array(lat_stations_in)[index_ele]\n",
    "    r[tag] = np.zeros(len(index))\n",
    "    r[tag][0] = 0\n",
    "    r_ele[tag] = np.zeros(len(index_ele))\n",
    "    r_ele[tag][0] = 0\n",
    "    vs_inter_verti[tag] = []\n",
    "    vs_inter_fund_verti[tag] = []\n",
    "    ele_verti[tag] = []\n",
    "    loc_start = find_intersection_point(traces[tag][0], traces[tag][1], [lon_inter_verti[tag][0], lat_inter_verti[tag][0]])\n",
    "    loc_ele_start = find_intersection_point(traces[tag][0], traces[tag][1], [lon_inter_verti[tag][0], lat_inter_verti[tag][0]])\n",
    "    loc_starts[tag] = loc_start\n",
    "    loc_ele_starts[tag] = loc_ele_start\n",
    "    for i in range(N):\n",
    "        vs_inter_verti[tag].append(vs_inter_horizon_in[i][index])\n",
    "        vs_inter_fund_verti[tag].append(vs_inter_fund_horizon_in[i][index])\n",
    "    ele_verti[tag].append(np.array(elevation_stations_in)[index_ele])\n",
    "    for i in range(len(index)):\n",
    "        if i > 0:\n",
    "            loc_new = find_intersection_point(traces[tag][0], traces[tag][1], [lon_inter_verti[tag][i], lat_inter_verti[tag][i]])\n",
    "            r[tag][i] = np.sqrt((loc_new[0]-loc_start[0])**2 + (loc_new[1]-loc_start[1])**2)\n",
    "    for i in range(len(index_ele)):\n",
    "        if i > 0:\n",
    "            loc_new = find_intersection_point(traces[tag][0], traces[tag][1], [lon_ele_verti[tag][i], lat_ele_verti[tag][i]])\n",
    "            r_ele[tag][i] = np.sqrt((loc_new[0]-loc_ele_start[0])**2 + (loc_new[1]-loc_ele_start[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断两条线段是否相交\n",
    "def cross_product(p1, p2, p3):\n",
    "    \"\"\"计算叉积\"\"\"\n",
    "    return (p2[0] - p1[0]) * (p3[1] - p1[1]) - (p2[1] - p1[1]) * (p3[0] - p1[0])\n",
    "\n",
    "def on_segment(p1, p2, p3):\n",
    "    \"\"\"检查p2是否在以p1和p3为端点的线段上\"\"\"\n",
    "    return min(p1[0], p3[0]) <= p2[0] <= max(p1[0], p3[0]) and min(p1[1], p3[1]) <= p2[1] <= max(p1[1], p3[1])\n",
    "\n",
    "def segments_intersect(p1, q1, p2, q2):\n",
    "    \"\"\"检查由(p1, q1)和(p2, q2)形成的两条线段是否相交\"\"\"\n",
    "    # 检查线段的方向\n",
    "    o1 = cross_product(p1, q1, p2)\n",
    "    o2 = cross_product(p1, q1, q2)\n",
    "    o3 = cross_product(p2, q2, p1)\n",
    "    o4 = cross_product(p2, q2, q1)\n",
    "\n",
    "    # 如果两条线段的方向相异，则它们相交\n",
    "    if o1 * o2 < 0 and o3 * o4 < 0:\n",
    "        return True\n",
    "    # 特殊情况处理\n",
    "    if o1 == 0 and on_segment(p1, p2, q1):\n",
    "        return True\n",
    "    if o2 == 0 and on_segment(p1, q2, q1):\n",
    "        return True\n",
    "    if o3 == 0 and on_segment(p2, p1, q2):\n",
    "        return True\n",
    "    if o4 == 0 and on_segment(p2, q1, q2):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def plot_segments(p1, q1, p2, q2):\n",
    "    plt.plot([p1[0], q1[0]], [p1[1], q1[1]], color='blue', label='Segment 1')\n",
    "    plt.plot([p2[0], q2[0]], [p2[1], q2[1]], color='red', label='Segment 2')\n",
    "\n",
    "    intersection = segments_intersect(p1, q1, p2, q2)\n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Segments Intersection')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fault_inter(tag_trace):\n",
    "    global traces\n",
    "    global faults\n",
    "    global lon_inter_verti\n",
    "    global lat_inter_verti\n",
    "\n",
    "    lat_fault_inter = []\n",
    "    lon_fault_inter = []\n",
    "\n",
    "    for key in faults.keys():\n",
    "        lon_fault = faults[key]['lon']\n",
    "        lat_fault = faults[key]['lat']  \n",
    "        index_fault_start = np.argmin(lon_fault)\n",
    "        index_fault_end = np.argmax(lon_fault)\n",
    "        p1 = [lon_fault[index_fault_start], lat_fault[index_fault_start]]\n",
    "        q1 = [lon_fault[index_fault_end], lat_fault[index_fault_end]]\n",
    "        index_trace_start = np.argmin(lon_inter_verti[tag_trace])\n",
    "        index_trace_end = np.argmax(lon_inter_verti[tag_trace])\n",
    "        p2 = [lon_inter_verti[tag_trace][index_trace_start], lat_inter_verti[tag_trace][index_trace_start]]\n",
    "        q2 = [lon_inter_verti[tag_trace][index_trace_end], lat_inter_verti[tag_trace][index_trace_end]]\n",
    "        \n",
    "        if segments_intersect(p1, q1, p2, q2):\n",
    "            # find the nearest fault point\n",
    "            lon_trace = lon_inter_verti[tag_trace]\n",
    "            lat_trace = lat_inter_verti[tag_trace]\n",
    "\n",
    "            min_distance = float('inf')\n",
    "\n",
    "            for lon1, lat1 in zip(lon_fault, lat_fault):\n",
    "                for lon2, lat2 in zip(lon_trace, lat_trace):\n",
    "                    distance = math.sqrt((lon1 - lon2)**2 + (lat1 - lat2)**2)\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        lon_fault_near = lon1\n",
    "                        lat_fault_near = lat1\n",
    "                        lon_trace_near = lon2\n",
    "                        lat_trace_near = lat2\n",
    "                    \n",
    "            lon_fault_inter.append( lon_trace_near )\n",
    "            lat_fault_inter.append( lat_trace_near )\n",
    "        \n",
    "        \"\"\"\n",
    "        intersection = find_lines_inter(p1, q1, p2, q2)\n",
    "        if intersection is not None:\n",
    "            lon_fault_inter.append(intersection[0])\n",
    "            lat_fault_inter.append(intersection[1])\n",
    "        \"\"\"\n",
    "    return lon_fault_inter, lat_fault_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fault_inter1(tag_trace):\n",
    "    global traces\n",
    "    global faults\n",
    "    global lon_inter_verti\n",
    "    global lat_inter_verti\n",
    "\n",
    "    lat_fault_inter = []\n",
    "    lon_fault_inter = []\n",
    "    lon_ref_fault = []\n",
    "    lat_ref_fault = []\n",
    "\n",
    "    for key in faults.keys():\n",
    "        lon_fault = faults[key]['lon']\n",
    "        lat_fault = faults[key]['lat']  \n",
    "        index_fault_start = np.argmin(lon_fault)\n",
    "        index_fault_end = np.argmax(lon_fault)\n",
    "        p1 = [lon_fault[index_fault_start], lat_fault[index_fault_start]]\n",
    "        q1 = [lon_fault[index_fault_end], lat_fault[index_fault_end]]\n",
    "        index_trace_start = np.argmin(lon_inter_verti[tag_trace])\n",
    "        index_trace_end = np.argmax(lon_inter_verti[tag_trace])\n",
    "        p2 = [lon_inter_verti[tag_trace][index_trace_start], lat_inter_verti[tag_trace][index_trace_start]]\n",
    "        q2 = [lon_inter_verti[tag_trace][index_trace_end], lat_inter_verti[tag_trace][index_trace_end]]\n",
    "        \n",
    "        if segments_intersect(p1, q1, p2, q2):\n",
    "            # find the nearest fault point\n",
    "            lon_trace = lon_inter_verti[tag_trace]\n",
    "            lat_trace = lat_inter_verti[tag_trace]\n",
    "            r_trace = []\n",
    "            for i in range(len(lon_fault)):\n",
    "                r_trace.append( np.sum(np.sqrt((np.array(lon_trace)-lon_fault[i])**2 + (np.array(lat_trace)-lat_fault[i])**2)) )\n",
    "            lon_ref_fault.append( lon_fault[np.argmin(r_trace)] )\n",
    "            lat_ref_fault.append( lat_fault[np.argmin(r_trace)] )\n",
    "            # find the nearst trace point\n",
    "            r_fault = np.sqrt((np.array(lon_trace)-lon_ref_fault[0])**2 + (np.array(lat_trace)-lat_ref_fault[0])**2)\n",
    "            lon_fault_inter.append( lon_trace[np.argmin(r_fault)] )\n",
    "            lat_fault_inter.append( lat_trace[np.argmin(r_fault)] )\n",
    "        \n",
    "        \"\"\"\n",
    "        intersection = find_lines_inter(p1, q1, p2, q2)\n",
    "        if intersection is not None:\n",
    "            lon_fault_inter.append(intersection[0])\n",
    "            lat_fault_inter.append(intersection[1])\n",
    "        \"\"\"\n",
    "    return lon_fault_inter, lat_fault_inter,lon_ref_fault,lat_ref_fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_min = 0.45\n",
    "#v_max = 1.15\n",
    "v_min = 0.3\n",
    "v_max = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(traces.keys()):\n",
    "    print('Plotting trace %d' % i)\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    ax1 = plt.subplot2grid((18,3),(2,0),colspan=2,rowspan=7)\n",
    "    im = ax1.imshow(vs_inter_fund_verti[i], aspect='auto', cmap='gist_rainbow', extent=[0,max(r[i]),N*dz,0], vmin=v_min, vmax=v_max)\n",
    "    ax1.set_xticks([])  #去掉横坐标值\n",
    "    #ax1.set_xlabel('Offset')\n",
    "    ax1.set_ylabel('Depth /m Fundamental')\n",
    "    #plt.colorbar(im)\n",
    "    # 找到断层点\n",
    "    lon_fault_inter, lat_fault_inter = find_fault_inter(i)\n",
    "    #lon_fault_inter, lat_fault_inter, lon_ref_fault, lat_ref_fault = find_fault_inter(i)\n",
    "    r_fault = []\n",
    "    for j in range(len(lon_fault_inter)):\n",
    "        r_fault.append(np.sqrt((loc_starts[i][0]-lon_fault_inter[j])**2 + (loc_starts[i][1]-lat_fault_inter[j])**2))\n",
    "        #ax3.scatter(r_fault[j],0, c='k', s=50)\n",
    "        ax1.vlines(r_fault[j], 0, N/10*dz, colors = \"k\", linestyles = \"dashed\")\n",
    "    ax1.set_title('Fundamental')\n",
    "    plt.colorbar(im,orientation='horizontal',aspect=100,fraction=0.05,pad=0.05)\n",
    "\n",
    "\n",
    "    ax2 = plt.subplot2grid((18,3),(10,0),colspan=2,rowspan=8)\n",
    "    im = ax2.imshow(vs_inter_verti[i], aspect='auto', cmap='gist_rainbow', extent=[0,max(r[i]),N*dz,0], vmin=v_min, vmax=v_max)\n",
    "    #ax3.set_xticks([])  #去掉横坐标值\n",
    "    ax2.set_xlabel('Offset')\n",
    "    ax2.set_ylabel('Depth /m Overtones')\n",
    "    # 找到断层点\n",
    "    #lon_fault_inter, lat_fault_inter = find_fault_inter(i)\n",
    "    for j in range(len(lon_fault_inter)):\n",
    "        r_fault.append(np.sqrt((loc_starts[i][0]-lon_fault_inter[j])**2 + (loc_starts[i][1]-lat_fault_inter[j])**2))\n",
    "        #ax3.scatter(r_fault[j],0, c='k', s=50)\n",
    "        ax2.vlines(r_fault[j], 0, N/10*dz, colors = \"k\", linestyles = \"dashed\")\n",
    "    ax2.set_title('Overtones')\n",
    "    \n",
    "\n",
    "\n",
    "    axele = plt.subplot2grid((18,3),(0,0),colspan=2,rowspan=1)\n",
    "    axele.set_xticks([])  #去掉横坐标值\n",
    "    #axele.set_yticks([])  #去掉纵坐标值\n",
    "    axele.set_ylabel('Elev')\n",
    "    axele.spines['top'].set_visible(False)\n",
    "    \n",
    "\n",
    "    # 画ele的柱状图\n",
    "    #axele.bar(r_ele[i], ele_verti[i][0]-min(ele_verti[i][0]), width=0.1, color='g')\n",
    "    index_r = np.argsort(r_ele[i])\n",
    "    axele.plot(r_ele[i][index_r], ele_verti[i][0][index_r]-min(ele_verti[i][0]), color='k')\n",
    "    axele.fill_between(r_ele[i][index_r], 0, ele_verti[i][0][index_r]-min(ele_verti[i][0]), color='k', alpha=0.5)\n",
    "    for j in range(len(lon_fault_inter)):\n",
    "        r_fault.append(np.sqrt((loc_starts[i][0]-lon_fault_inter[j])**2 + (loc_starts[i][1]-lat_fault_inter[j])**2))\n",
    "        #ax1.scatter(r_fault[j],0, c='k', s=50)\n",
    "        axele.vlines(r_fault[j], 0, max(ele_verti[i][0][index_r]-min(ele_verti[i][0])), colors = \"k\", linestyles = \"dashed\")\n",
    "    axele.set_xlim([0, max(r[i])])\n",
    "\n",
    "    ax3 = plt.subplot2grid((2,3),(0,2),colspan=1,rowspan=1)\n",
    "    ax3.scatter(lon_stations_all, lat_stations_all, c='k', s=0.08)\n",
    "    for j in range(len(faults)):\n",
    "        ax3.plot(faults['clark'+str(j+1)]['lon'], faults['clark'+str(j+1)]['lat'], 'k')\n",
    "    ax3.scatter(lon_inter_in, lat_inter_in, c='b', s=0.1)\n",
    "    ax3.scatter(np.array(lon_inter_in)[indexes[i]], np.array(lat_inter_in)[indexes[i]], c='r', s=0.3)\n",
    "    ax3.scatter(lon_fault_inter, lat_fault_inter, c='y', s=50)\n",
    "\n",
    "    ax3.set_xticks([])  #去掉横坐标值\n",
    "    ax3.set_yticks([])  #去掉纵坐标值\n",
    "    ax3.set_xlabel('Longitude')\n",
    "    ax3.set_ylabel('Latitude')\n",
    "    #for j in range(len(lon_ref_fault)):\n",
    "    #    ax3.scatter(lon_ref_fault[j],lat_ref_fault[j],s = 50)\n",
    "\n",
    "\n",
    "    ax4 = plt.subplot2grid((2,3),(1,2),colspan=1,rowspan=1)\n",
    "    ax4.scatter(lon_stations_all, lat_stations_all,marker='.',color='k',s=0.08)\n",
    "    ax4.set_xticks([])  #去掉横坐标值\n",
    "    ax4.set_yticks([])  #去掉纵坐标值\n",
    "    ax4.set_xlabel('Longitude')\n",
    "    ax4.set_ylabel('Latitude')\n",
    "    ax4.set_title('Elevation')\n",
    "    flag_add = 0.0005\n",
    "    ax4.set_xlim([min(lon_stations_all)-flag_add, max(lon_stations_all)+flag_add])\n",
    "    ax4.set_ylim([min(lat_stations_all)-flag_add, max(lat_stations_all)+flag_add])\n",
    "    for j in range(len(faults)):\n",
    "        ax4.plot(faults['clark'+str(j+1)]['lon'], faults['clark'+str(j+1)]['lat'], 'k')\n",
    "    im = ax4.scatter(lon_stations_in,lat_stations_in,c=elevation_stations_in,cmap='gist_rainbow',s=20)\n",
    "    ax4.plot(np.array(lon_inter_in)[indexes[i]], np.array(lat_inter_in)[indexes[i]], c='k')\n",
    "    #plt.colorbar(im, ax=ax4, location='top', shrink=0.6)\n",
    " \n",
    "    cax = inset_axes(ax4,\n",
    "                 width=\"1%\",  # colorbar宽度占主轴宽度的百分比\n",
    "                 height=\"50%\",  # colorbar高度占主轴高度的百分比\n",
    "                 loc='upper right')  # 在右上角放置colorbar\n",
    "    cbar = plt.colorbar(im, cax=cax, orientation='vertical')\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig(dir_image+'Vs_verticle_trace_'+str(i)+'.png')\n",
    "    #plt.savefig(dir_image+'Vs_shallow_verticle_trace_'+str(i)+'.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccfj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
