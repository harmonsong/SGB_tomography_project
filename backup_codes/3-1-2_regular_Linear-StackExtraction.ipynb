{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Connected to base (Python 3.11.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from ccfj import CC\n",
    "from ccfj import GetStationPairs\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import time\n",
    "from geopy.distance import great_circle\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project/output_FJSJ_v9.1_test/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('a-project.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project/output_FJSJ_16-01/'               # Harmon server\n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_CC_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project:  /shdisk/rem2/Harmon/F-J/San/project/output_FJSJ_v9.1_test/\n"
     ]
    }
   ],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = dir_project_workspace + name_project\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_stack = dir_project+info_basic['dir_stack']\n",
    "dir_CC = dir_CC_workspace+info_basic['name_CC']\n",
    "dir_partition = dir_project + info_basic['dir_partition']\n",
    "stalistname_all = info_basic['stalistname_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define how many subworks to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['07-03',\n",
       " '17-03',\n",
       " '27-03',\n",
       " '37-03',\n",
       " '47-03',\n",
       " '07-13',\n",
       " '17-13',\n",
       " '27-13',\n",
       " '37-13',\n",
       " '47-13']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_subworks = ['01-01']\n",
    "key_subworks = info_basic['key_subworks']\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Read All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist()\n",
    "lat_all = stainfo['latitude'].tolist() \n",
    "lon_all = stainfo['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncffile = h5py.File(dir_CC + 'gather_all.h5','r')\n",
    "ncfs = ncffile['ncfs'][:]\n",
    "f = ncffile['f'][:]\n",
    "count_all = ncffile['count'][:]\n",
    "ncffile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Collect Stack files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_basic_bi['r_max'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting  07-03  ...\n",
      "Done in  0.19388651847839355  s.\n",
      "Collecting  17-03  ...\n",
      "Done in  0.40508556365966797  s.\n",
      "Collecting  27-03  ...\n",
      "Done in  0.5720064640045166  s.\n",
      "Collecting  37-03  ...\n",
      "Done in  0.5572614669799805  s.\n",
      "Collecting  47-03  ...\n",
      "Done in  0.7436463832855225  s.\n",
      "Collecting  07-13  ...\n",
      "Done in  0.17097759246826172  s.\n",
      "Collecting  17-13  ...\n",
      "Done in  0.3839287757873535  s.\n",
      "Collecting  27-13  ...\n",
      "Done in  0.47527360916137695  s.\n",
      "Collecting  37-13  ...\n",
      "Done in  0.5760388374328613  s.\n",
      "Collecting  47-13  ...\n",
      "Done in  0.6571552753448486  s.\n"
     ]
    }
   ],
   "source": [
    "for key_subwork in key_subworks:\n",
    "    print(\"Collecting \",key_subwork,' ...')\n",
    "    time0 = time.time()\n",
    "\n",
    "    nf = info_basic['nf']\n",
    "    #f = info_basic['f']\n",
    "    dir_stack= dir_project + info_basic['dir_stack']\n",
    "    \n",
    "    nsta = info_basic['nstaS'][key_subwork]\n",
    "    nPairs = int(nsta*(nsta-1)/2)\n",
    "    \n",
    "    filepath = dir_partition + str(key_subwork) + '.txt'\n",
    "    stalist, lat, lon = np.loadtxt(filepath, dtype='str', unpack=True)\n",
    "\n",
    "    nsta = len(stalist)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    nPairs = int(len(StationPairs)/2)\n",
    "\n",
    "    ncfs_sum_linear = np.zeros((nPairs,nf),dtype=np.complex64)\n",
    "    r = np.zeros(nPairs)\n",
    "    count= np.zeros(nPairs)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    names = []\n",
    "    for i in range(nPairs):\n",
    "        sta1 = StationPairs[2*i]\n",
    "        sta2 = StationPairs[2*i+1]\n",
    "        idx1 = np.min( [int(stalist_all.index(stalist[sta1])),int(stalist_all.index(stalist[sta2]))] )\n",
    "        idx2 = np.max( [int(stalist_all.index(stalist[sta1])),int(stalist_all.index(stalist[sta2]))] )\n",
    "        #idx1 = int(stalist_all.index(stalist[sta1]))\n",
    "        #idx2 = int(stalist_all.index(stalist[sta2]))\n",
    "        #idx1 = int(stainfo[stainfo[key_pd]==stalist[sta1]].index.values[0])\n",
    "        #idx2 = int(stainfo[stainfo[key_pd]==stalist[sta2]].index.values[0])\n",
    "        \n",
    "        m = 0\n",
    "        for j in range(nsta_all-idx1,nsta_all):\n",
    "            m += j\n",
    "        num = m +idx2 - idx1 -1\n",
    "        \n",
    "        ncfs_sum_linear[i,:] = np.nan_to_num(ncfs[num,:])\n",
    "        count[i] = count_all[num]\n",
    "        #r[i] = r0[num]\n",
    "        #if count_all[num] > 0:\n",
    "        #    ncfs_sum_linear[i,:] = ncfs[num,:]/count_all[num]\n",
    "        #    count[i] = count_all[num]\n",
    "\n",
    "        r[i] = great_circle((lat[sta1],lon[sta1]),(lat[sta2],lon[sta2])).km\n",
    "        #names.append([stalist_all[StationPairs_all[2*num]],stalist_all[StationPairs_all[2*num+1]]])\n",
    "\n",
    "    outname = key_subwork+'_gather_linear.h5'\n",
    "    if os.path.exists(dir_stack+outname):\n",
    "        os.remove(dir_stack+outname)\n",
    "    ncffile = h5py.File(dir_stack+outname,'w')\n",
    "    \n",
    "    ncffile.create_dataset('ncfs',data=ncfs_sum_linear)\n",
    "    ncffile.create_dataset('r',data=r)\n",
    "    ncffile.create_dataset('count',data=count)\n",
    "    ncffile.create_dataset('f',data=f)\n",
    "    ncffile.create_dataset('StationPairs',data=StationPairs)\n",
    "    #print(ncffile.keys())\n",
    "    ncffile.close()\n",
    "    #np.savez(dir_stack+key_subwork+\"_summed-linear.npz\",ncfs= ncfs_sum_linear,r = r,stalist=stalist,StationPairs=StationPairs)\n",
    "    print(\"Done in \",time.time()-time0,\" s.\")\n",
    "\n",
    "    info_basic_bi['r_max'][key_subwork] = max(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(filename_bi,info_basic_bi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
