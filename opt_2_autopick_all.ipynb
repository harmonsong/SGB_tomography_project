{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "from ccfj import GetStationPairs\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import geopandas as gp\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import scipy.ndimage as sn\n",
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.spatial import ConvexHull\n",
    "from skimage import measure\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_voro_v1.0/output_voro_v9.3_01-01/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#name_project = 'project/output_FJSJ_17-01/'               \n",
    "#name_project = 'project_repartition_v3.0/output_repar_v9.1_02-01/'     \n",
    "#name_project = 'project_repartition_v4.0/output_repar_v9.2_01-01/'\n",
    "name_project = 'project_voro_v1.0/output_voro_v9.3_01-01/'             \n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_CC_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project:  /shdisk/rem2/Harmon/F-J/San/project_voro_v1.0/output_voro_v9.3_01-01/\n"
     ]
    }
   ],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key_subworks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m key_subworks \u001b[38;5;241m=\u001b[39m \u001b[43minfo_basic\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkey_subworks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m key_subworks \u001b[38;5;241m=\u001b[39m info_basic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_subworks_repick\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m key_subworks\n",
      "\u001b[0;31mKeyError\u001b[0m: 'key_subworks'"
     ]
    }
   ],
   "source": [
    "key_subworks = info_basic['key_subworks']\n",
    "key_subworks = info_basic['key_subworks_repick']\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_image = dir_project+info_basic['dir_image'] + 'autopick/'\n",
    "if not os.path.exists(dir_image):\n",
    "    os.makedirs(dir_image)\n",
    "dir_ds = dir_project+info_basic['dir_ds']\n",
    "print('dir_image: ', dir_image)\n",
    "print('dir_ds: ', dir_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_disp =  'autopick'+info_basic['tag']+'/'\n",
    "info_basic['dir_disp'] = dir_disp\n",
    "dir_disp = dir_project+dir_disp\n",
    "if not os.path.exists(dir_disp):\n",
    "    os.makedirs(dir_disp)\n",
    "print('dir_disp: ', dir_disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_project+'Basic_info.yml', 'w', encoding='utf-8') as f:\n",
    "   yaml.dump(data=info_basic, stream=f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_remove_all = {}\n",
    "for key_subwork in key_subworks:\n",
    "    print(key_subwork)\n",
    "    ds = h5py.File(dir_ds+'ds_'+key_subwork+'.h5', 'r')\n",
    "    ds_remove = ds['ds_remove'][0]\n",
    "    ds.close()\n",
    "    ds_remove_all[key_subwork] = ds_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick probes' Phase velocity automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_fundamental(ds):\n",
    "    global f\n",
    "    global c\n",
    "    global f_new\n",
    "    global c_new\n",
    "    global dir_ds\n",
    "    global threshold\n",
    "    # 归一化\n",
    "    #ds = ds / np.max(ds)  \n",
    "    ds = np.nan_to_num(ds)\n",
    "    for i in range(ds.shape[1]):\n",
    "        ds[:,i] = ds[:,i]/np.max(ds[:,i])\n",
    "\n",
    "    binary_ds = ds > threshold\n",
    "    label_ds,num_labels = measure.label(binary_ds, connectivity=2, return_num=True)\n",
    "    region_areas = [np.sum(label_ds==i) for i in range(1,num_labels+1)]\n",
    "    if num_labels == 0:\n",
    "        return np.zeros(0),np.zeros(0)\n",
    "    max_area_label = np.argmax(region_areas) + 1\n",
    "    largest_cluster = label_ds == max_area_label\n",
    "    indices = np.argwhere(largest_cluster)\n",
    "\n",
    "    ff = f_new[indices[:,1]]\n",
    "    cc = c_new[indices[:,0]]\n",
    "\n",
    "    return ff,cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_fundamental(key):\n",
    "    global f\n",
    "    global c\n",
    "    global f_new\n",
    "    global c_new\n",
    "    global flag_f\n",
    "    global flag_c\n",
    "    global dir_ds\n",
    "    global threshold\n",
    "    global dir_disp\n",
    "    global dir_ds\n",
    "    global info_basic\n",
    "    global info_basic_bi\n",
    "    global smooth_cluster\n",
    "    global smooth_pick\n",
    "    global key_subworks\n",
    "    global ds_remove_all\n",
    "\n",
    "    \n",
    "    ds_remove = ds_remove_all[key]\n",
    "    grace = 0.0\n",
    "\n",
    "    f_start = flag_f[0]\n",
    "    f_end = flag_f[1]\n",
    "    c_min = flag_c[0]\n",
    "    c_max = flag_c[1]\n",
    "\n",
    "    ff_all = []\n",
    "    cc_all = []\n",
    "\n",
    "\n",
    "    while f_start != f_end:\n",
    "        #print(f_start,f_end)\n",
    "        f_new = f[np.logical_and(f>f_start,f <= f_end)]\n",
    "        c_new = c[np.logical_and(c>c_min,c < c_max)]\n",
    "        ds_new0 = ds_remove[np.logical_and(c>c_min,c < c_max),:]\n",
    "        ds_new = ds_new0[:,np.logical_and(f>f_start,f <= f_end)]\n",
    "        # 对数组进行横向的平滑\n",
    "        ds_new = pd.DataFrame(ds_new)\n",
    "        #ds_new = ds_new.rolling(100).mean()\n",
    "        ds_new = ds_new.T\n",
    "        ds_new = ds_new.rolling(smooth_cluster).mean()\n",
    "        ds_new = np.array(ds_new)\n",
    "        ds_new = ds_new.T\n",
    "        ff,cc = cluster_fundamental(ds_new)\n",
    "        if len(ff_all) == 0:\n",
    "            ff_all = ff\n",
    "            cc_all = cc\n",
    "        elif len(ff) != 0:\n",
    "            ff_all = np.hstack((ff_all,ff))\n",
    "            cc_all = np.hstack((cc_all,cc))\n",
    "        else:\n",
    "            #print('this')\n",
    "            break\n",
    "        f_start = np.max(ff)\n",
    "        c_max = np.max(cc[ff==f_start]) + grace\n",
    "    \n",
    "    # smooth\n",
    "    # 转置\n",
    "    \"\"\"\n",
    "    ds_smooth = ds_remove.T\n",
    "    ds_smooth = pd.DataFrame(ds_smooth)\n",
    "    ds_smooth = ds_smooth.rolling(smooth_pick).mean()\n",
    "    ds_smooth = np.array(ds_smooth)\n",
    "    ds_smooth = ds_smooth.T\n",
    "    ds_smooth = pd.DataFrame(ds_smooth)\n",
    "    ds_smooth = ds_smooth.rolling(smooth_pick).mean()\n",
    "    ds_smooth = np.array(ds_smooth)\n",
    "    \"\"\"\n",
    "    ds_smooth = plotlib.smooth_ds(ds_remove,level_f = smooth_pick,level_c = smooth_pick)\n",
    "\n",
    "    f_range = set(ff_all)\n",
    "    f_range = np.array(list(f_range))\n",
    "    c_pick = []\n",
    "    for i in range(len(f_range)):\n",
    "        f_this = f_range[i]\n",
    "        c_this = cc_all[ff_all==f_this]\n",
    "        c_range = [np.min(c_this),np.max(c_this)]\n",
    "        c_new = c[np.logical_and(c>=c_range[0],c<=c_range[1])]\n",
    "        c_pick.append(c_new[np.argmax(ds_smooth[np.logical_and(c>=c_range[0],c<=c_range[1]),f==f_this])])\n",
    "    c_pick = np.array(c_pick)\n",
    "    # smooth\n",
    "    index = np.argsort(f_range)\n",
    "    f_range = f_range[index]\n",
    "    c_pick = c_pick[index]\n",
    "    c_pick_smooth = sn.gaussian_filter1d(c_pick,6)\n",
    "    \n",
    "    # save as txt\n",
    "    np.savetxt(dir_disp+'autopick_cluster_'+key+'.txt', np.array([ff_all,cc_all]).T, fmt='%.4f', delimiter=',')\n",
    "    np.savetxt(dir_disp+'autopick_'+key+'.txt', np.array([f_range,c_pick,c_pick_smooth]).T, fmt='%.4f', delimiter=',')\n",
    "    print('finish '+ key + ' '+str(key_subworks.index(key)+1) + '/'+str(len(key_subworks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = info_basic_bi['f']\n",
    "c = np.linspace(info_basic['c_min'],info_basic['c_max'],info_basic['c_num'])\n",
    "flag_c = [0.25,1.2]\n",
    "flag_f = [3,15]\n",
    "#flag_f = [6,25]\n",
    "threshold = 0.9\n",
    "f_new = f[np.logical_and(f>flag_f[0],f < flag_f[1])]\n",
    "c_new = c[np.logical_and(c>flag_c[0],c < flag_c[1])]\n",
    "smooth_cluster = 30\n",
    "smooth_pick = 3\n",
    "flag_pick = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "if flag_pick == 1:\n",
    "    for key_subwork in key_subworks:\n",
    "        pick_fundamental(key_subwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_disp(key_subwork):\n",
    "    global dir_disp\n",
    "    global f\n",
    "    global c\n",
    "    global dir_image\n",
    "    global key_subworks\n",
    "\n",
    "    fig,ax = plt.subplots(1,3,figsize=(18,6))\n",
    "    dir_ds = dir_project + info_basic['dir_ds']\n",
    "    ds = h5py.File(dir_ds+'ds_'+key_subwork+'.h5', 'r')\n",
    "    ds_remove = ds['ds_remove'][0]\n",
    "\n",
    "    title0 = key_subwork\n",
    "    ff_all = np.loadtxt(dir_disp+'autopick_cluster_'+key_subwork+'.txt',delimiter=',')[:,0]\n",
    "    cc_all = np.loadtxt(dir_disp+'autopick_cluster_'+key_subwork+'.txt',delimiter=',')[:,1]\n",
    "    f_pick = np.loadtxt(dir_disp+'autopick_'+key_subwork+'.txt',delimiter=',')[:,0]\n",
    "    c_pick = np.loadtxt(dir_disp+'autopick_'+key_subwork+'.txt',delimiter=',')[:,1]\n",
    "    c_smooth = np.loadtxt(dir_disp+'autopick_'+key_subwork+'.txt',delimiter=',')[:,2]\n",
    "\n",
    "    ax[0] = plotlib.plot_fj(ax[0],ds_remove,title0,f,c,0,c_map='jet')\n",
    "    ax[0].scatter(ff_all,cc_all,marker='o',s=10,color='k')\n",
    "    \n",
    "    ds_smooth = plotlib.smooth_ds(ds_remove,level_f = 10,level_c=6)\n",
    "\n",
    "\n",
    "    ax[1] = plotlib.plot_fj(ax[1],ds_smooth,title0,f,c,0,c_map='jet')\n",
    "    ax[1].scatter(f_pick,c_pick,marker='o',s=10,color='k')\n",
    "\n",
    "    ax[2] = plotlib.plot_fj(ax[2],ds_smooth,title0,f,c,0,c_map='jet')\n",
    "    ax[2].scatter(f_pick,c_smooth,marker='o',s=10,color='k')\n",
    "\n",
    "    plt.savefig(dir_image+'autopick_'+key_subwork+'.png',dpi=60)\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "    print('finish '+key_subwork,' ', str(key_subworks.index(key_subwork)+1),'/',str(len(key_subworks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_plot = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_plot == 1:\n",
    "    for key_subwork in key_subworks:\n",
    "        plot_disp(key_subwork)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccfj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
