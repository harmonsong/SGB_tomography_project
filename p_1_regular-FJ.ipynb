{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import geopandas as gp\n",
    "import time\n",
    "import pandas as pd\n",
    "from ccfj import CC\n",
    "from ccfj import GetStationPairs\n",
    "from geopy.distance import great_circle\n",
    "import folium\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import mathlib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('a-project.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project/output_FJSJ_16-01/'               # Harmon server\n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = dir_project_workspace + name_project\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_CC = dir_CC_workspace + info_basic['name_CC']\n",
    "dir_ds = dir_project + info_basic['dir_ds']\n",
    "dir_partition = dir_project + info_basic['dir_partition']\n",
    "dir_image = dir_project + info_basic['dir_image'] + 'regular_FJ/'\n",
    "if os.path.exists(dir_image) == False:\n",
    "    os.makedirs(dir_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_subworks = info_basic['key_subworks']\n",
    "key_subworks = ['07-03']\n",
    "key_subworks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read all stations coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist()\n",
    "lat_all = stainfo['latitude'].tolist() \n",
    "lon_all = stainfo['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = np.load('clark_faults.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncffile = h5py.File(dir_CC + 'gather_all.h5','r')\n",
    "ncfs = ncffile['ncfs'][:]\n",
    "f = ncffile['f'][:]\n",
    "count_all = ncffile['count'][:]\n",
    "ncffile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = {}\n",
    "lat = {}\n",
    "lon = {}\n",
    "for key in key_subworks:\n",
    "    filepath = dir_partition + str(key) + '.txt'\n",
    "    stations_this, lat_stations_this, lon_stations_this = np.loadtxt(filepath, dtype='str' , unpack=True)\n",
    "    stations[key] = stations_this\n",
    "    lat[key] = lat_stations_this.astype(float)\n",
    "    lon[key] = lon_stations_this.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pairs(sta):\n",
    "    p = []\n",
    "    nsta = len(sta)\n",
    "    for ii in range(nsta):\n",
    "        for jj in range(ii+1,nsta):\n",
    "            p.append([sta[ii],sta[jj]])\n",
    "    return p\n",
    "def cal_indx(pair,nsta):\n",
    "    indx = int(pair[0]*(2*nsta-pair[0]-1)/2+pair[1]-pair[0]-1)\n",
    "    return indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_window_filter(t,ncfst0,r,v_min,t0,a):\n",
    "    ncfst = ncfst0.copy()\n",
    "    for i in range(len(ncfst)):\n",
    "        tag = r[i]/v_min\n",
    "        #print(t0,tag)\n",
    "        t1 = t[t>-tag-t0][t[t>-tag-t0]< tag+t0]\n",
    "        start = np.where(t == t1[0])[0][0]\n",
    "        end = np.where(t == t1[-1])[0][0]\n",
    "        ncfst[i][start:end+1]= ncfst[i][start:end+1]* np.exp(-a*np.abs((tag-np.abs(t1))))\n",
    "    return ncfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stack(key_subwork,ncfs_sum_linear,r,StationPairs):\n",
    "    global dir_project\n",
    "    global key_subworks\n",
    "    global info_basic\n",
    "    global flag_save\n",
    "    global v_tag\n",
    "    global t0\n",
    "    global a\n",
    "\n",
    "    start0 = time.time()\n",
    "    f0 = info_basic_bi['f']\n",
    "    dt = 1/np.max(f0)\n",
    "    t = (np.linspace(-len(f0)-1,len(f0)-1,2*(len(f0)-1))+0.5)*dt/2\n",
    "    ncfst_linear = mathlib.freq_time(ncfs_sum_linear)\n",
    "    ncfst1 = time_window_filter(t,ncfst_linear,r,v_tag,t0,a)\n",
    "    ncfs_sum_remove = mathlib.time_freq(ncfst1)\n",
    "    if flag_save:\n",
    "        tag = name_project[ name_project.rfind('_')+1: -1]\n",
    "        dir_stack = dir_project + 'stack_'+tag+'/'\n",
    "        outname = key_subwork+'_gather_timewindow.h5'\n",
    "        if os.path.exists(dir_stack+outname):\n",
    "            os.remove(dir_stack+outname)\n",
    "        ncffile = h5py.File(dir_stack+outname,'w')\n",
    "        ncffile.create_dataset('ncfs', data=ncfs_sum_remove) \n",
    "        ncffile.create_dataset('r',data=r)\n",
    "        ncffile.create_dataset('StationPairs',data=StationPairs)\n",
    "        ncffile.close()\n",
    "    print('Finish remove stack, time:', time.time()-start0, ' seconds')\n",
    "    return ncfs_sum_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tag = info_basic['v_tag']\n",
    "t0 = info_basic['t0']\n",
    "a = info_basic['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_save = 0\n",
    "\n",
    "start = 0 \n",
    "interval = 10\n",
    "flag_time = 0.02\n",
    "tao = 0\n",
    "\n",
    "c_map = 'jet'\n",
    "v_min = 0.1\n",
    "v_max = None\n",
    "d_len = 31\n",
    "\n",
    "xlim_f = [2,30]\n",
    "xlim_T = [-1,1]\n",
    "\n",
    "info_basic['v_min'] = v_min\n",
    "info_basic['v_max'] = v_max\n",
    "info_basic['c_map'] = c_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_linear_all = {}\n",
    "ds_remove_all = {}\n",
    "index_ncfs = {}\n",
    "rs = {}\n",
    "for key_subwork in key_subworks:\n",
    "    print(key_subwork+ '; '+str(key_subworks.index(key_subwork)+1)+'/'+str(len(key_subworks))+' subworks.')\n",
    "    ds = h5py.File(dir_ds+'ds_'+str(key_subwork)+'.h5', 'r')\n",
    "    ds_linear = plotlib.smooth_ds(ds['ds_linear'][0])\n",
    "    ds_remove = plotlib.smooth_ds(ds['ds_remove'][0])\n",
    "    ds_linear_all[key_subwork] = ds_linear\n",
    "    ds_remove_all[key_subwork] = ds_remove\n",
    "    index_ncfs[key_subwork] = list(ds['index_ncfs'])\n",
    "    rs[key_subwork] = np.array(ds['r'])\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_subwork in key_subworks:\n",
    "    print(key_subwork+ '; '+str(key_subworks.index(key_subwork)+1)+'/'+str(len(key_subworks))+' subworks.')\n",
    "    index = index_ncfs[key_subwork]\n",
    "    ncfs_sum_linear = np.array(ncfs)[index,:]\n",
    "    r = rs[key_subwork]\n",
    "    \n",
    "    # plot area\n",
    "    stalist = stations[key_subwork]\n",
    "    lat = lat[key_subwork].astype(float)\n",
    "    lon = lon[key_subwork].astype(float)\n",
    "    nsta = len(stalist)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    nPairs = int(len(StationPairs)/2)\n",
    "\n",
    "    ncfs_sum_remove = remove_stack(key_subwork,ncfs_sum_linear,r,StationPairs)\n",
    "\n",
    "    fig,ax = plt.subplots(3,3,figsize= (22,18))\n",
    "    ax[0][0]=plotlib.plot_area(ax[0][0],lon_all,lat_all,lon,lat)\n",
    "    for i in range(len(faults)):\n",
    "        ax[0][0].plot(faults['clark'+str(i+1)]['lon'], faults['clark'+str(i+1)]['lat'], 'k')\n",
    "    \n",
    "\n",
    "    # plot ncfs and ncfst\n",
    "    # linear stack\n",
    "    f0 = info_basic_bi['f']\n",
    "    t = info_basic_bi['t']\n",
    "    ncfst_linear = mathlib.freq_time(ncfs_sum_linear)\n",
    "    ncfst_remove = mathlib.freq_time(ncfs_sum_remove)\n",
    "    \n",
    "    title1 = \"Linear Stack subarea frequency for \"+key_subwork\n",
    "    #xlim_f = [0,15]\n",
    "    ax[0][1] = plotlib.plot_ncfs(ax[0][1],f0,ncfs_sum_linear,r,title1,xlim_f,0)\n",
    "    ax[0][2] = plotlib.plot_ncfs(ax[0][2],f0,ncfs_sum_remove,r,title1,xlim_f,0)\n",
    "    \n",
    "    # plot fj\n",
    "    ds = h5py.File(dir_ds+'ds_'+key_subwork+'.h5', 'r')\n",
    "    ds_linear = ds['ds_linear'][0]\n",
    "    ds_remove = ds['ds_remove'][0]\n",
    "    ds_linear = plotlib.smooth_ds(ds_linear)\n",
    "    ds_remove = plotlib.smooth_ds(ds_remove)\n",
    "    c = np.linspace(info_basic['c_min'],info_basic['c_max'],info_basic['c_num'])\n",
    "    #c = np.linspace(100,2000,1000)\n",
    "    title0 = \"Linear Stack subarea time for \"+key_subwork\n",
    "    ax[1][0] = plotlib.plot_ncfst(ax[1][0],t,ncfst_linear[start::interval],r[start::interval],title0,flag_time,xlim_T,0)\n",
    "    title0 = \"Remove Stack subarea time for \"+key_subwork\n",
    "    ax[1][1] = plotlib.plot_ncfst(ax[1][1],t,ncfst_remove[start::interval],r[start::interval],title0,flag_time,xlim_T,0)\n",
    "    for i in range(len(r)):\n",
    "        ax[1][1].plot()\n",
    "\n",
    "\n",
    "    \n",
    "    title0 = \"Linear stack dispersion curve \"+str(d_len)+' days'\n",
    "    ax[2][0] = plotlib.plot_fj(ax[2][0],ds_linear,title0,f0,c,0,v_min=v_min,v_max=v_max,c_map=c_map)\n",
    "    ax[2][0].set_xlim(xlim_f)\n",
    "\n",
    "    title0 = \"Remove stack dispersion curve \"+str(d_len)+' days'\n",
    "    ax[2][1] = plotlib.plot_fj(ax[2][1],ds_remove,title0,f,c,0,v_min=v_min,v_max=v_max,c_map=c_map)\n",
    "    ax[2][1].set_xlim(xlim_f)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dir_image+key_subwork+'_compare_remove.png',dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_project+'Basic_info.yml', 'w', encoding='utf-8') as f:\n",
    "   yaml.dump(data=info_basic, stream=f, allow_unicode=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e1b1cfcb63b8c4b20fd3d610677682a40199606624b55ac5cc8ef1326af990f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
