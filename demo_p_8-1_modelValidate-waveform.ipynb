{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, getopt, os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import math,h5py, pandas\n",
    "from scipy import integrate\n",
    "from scipy.fftpack import fft, hilbert\n",
    "from scipy.signal import butter, lfilter\n",
    "from geopy.distance import great_circle\n",
    "import matplotlib.ticker as ticker\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isrc = 40\n",
    "flag_maxd = 0.1\n",
    "flag_SNRmin = 0.8\n",
    "f_rick_c = 10\n",
    "t_rick_shift = 0.15\n",
    "bands = np.array([[1/18,1/12],[1/15,1/10],[1/12,1/7],[1/10,1/5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_project = 1\n",
    "\n",
    "if flag_project == 0:\n",
    "    file_project = 'a-project.yml'\n",
    "elif flag_project == 1:\n",
    "    file_project = 'a-project_repar.yml'\n",
    "elif flag_project == 2:\n",
    "    file_project = 'a-project_voro.yml'\n",
    "    \n",
    "with open(file_project, 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "name_project = 'project_repartition_v4.0/output_repar_v9.2_01-01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_CC_workspace:  ./\n",
      "dir_project_workspace:  ./\n",
      "dir_project:  ./project_repartition_v4.0/output_repar_v9.2_01-01/\n"
     ]
    }
   ],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_image = dir_project + info_basic['rdir_image']+'model_validate/'\n",
    "if not os.path.exists(dir_image):\n",
    "    os.makedirs(dir_image)\n",
    "#dir_CC = os.getcwd()+'/'+dir_CC_workspace[1:] + info_basic['rdir_CC']\n",
    "dir_CC = dir_CC_workspace + 'CC/CC_100_prewhiten/'\n",
    "#dir_CC = dir_CC_workspace + 'CC/CC_40_prewhiten/'\n",
    "key_subworks = info_basic['key_subworks']\n",
    "M = len(key_subworks)\n",
    "dir_file = os.getcwd()+'/ModelValidCode/ModelValidCode/parameter_prepare/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ricker(t,fc,t0):\n",
    " if (t<=0.0):\n",
    "    v=0.0\n",
    " f0 = np.sqrt(math.pi)/2.0\n",
    " u = (t-t0)*2.0*math.pi*fc\n",
    " v=(u**2.0/4.0-0.5)*np.exp(-u**2.0/4.0)*f0\n",
    " return v\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='bandpass')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSNR(cfsf,r,f,SNRmin):\n",
    "    NoiseWinLength = 5 # in seconds\n",
    "    SigWinC = np.array([0.35,0.55]) #signal window for velocity, in km/s\n",
    "    SigWinT = np.zeros((len(r),2))\n",
    "    SNR = np.zeros(np.shape(r))\n",
    "    for i in range(len(r)):\n",
    "        SigWinT[i,:] = r[i]/SigWinC\n",
    "\n",
    "    dt = 1/np.max(f)\n",
    "    t = (np.linspace(-len(f)/2,len(f)/2-1,len(f))-0.5)*dt\n",
    "    cfst = np.zeros(np.shape(cfsf))\n",
    "    for i in range(len(cfsf)):\n",
    "        cfst[i,:] = np.real(np.fft.fftshift(np.fft.ifft(cfsf[i,:])))\n",
    "        cfst[i,:] = cfst[i,:] /np.max(cfst[i,:])\n",
    "\n",
    "    id0 = int(len(t)/2)\n",
    "    cfst12 = cfst[:,id0::]\n",
    "    cfst21 = cfst[:,id0::-1]\n",
    "    for j in range(len(r)):\n",
    "        c12h= hilbert(cfst12[j,:])\n",
    "        c21h= hilbert(cfst21[j,:])\n",
    "        groupCF12 = np.sqrt(cfst12[j,:]**2 + c12h**2)\n",
    "        groupCF21 = np.sqrt(cfst21[j,:]**2 + c21h**2)\n",
    "        nnSigWinL = int(np.ceil(SigWinT[j,1]/dt))\n",
    "        nnSigWinR = int(np.floor(SigWinT[j,0]/dt))\n",
    "        if nnSigWinL >= nnSigWinR:\n",
    "            continue\n",
    "        nnNoiseWinL = nnSigWinR\n",
    "        nnNoiseWinR = nnSigWinR+int(round(NoiseWinLength/dt))\n",
    "\n",
    "        #print(\"nnSigWinL: \",nnSigWinL)\n",
    "        #print(\"nnSigWinR: \",nnSigWinR)\n",
    "        SigAmp12 = np.max(groupCF12[nnSigWinL:nnSigWinR])\n",
    "        SigAmpAve12 = np.mean(groupCF12[nnSigWinL:nnSigWinR])\n",
    "        NoiseAmpAve12 = np.mean(groupCF12[nnNoiseWinL:nnNoiseWinR])\n",
    "        if NoiseAmpAve12 == 0:\n",
    "            if SigAmp12 > 0:\n",
    "                SNR12 = 100\n",
    "            else:\n",
    "                SNR12 = 0\n",
    "        else:\n",
    "            SNR12 = SigAmp12/NoiseAmpAve12\n",
    "\n",
    "        SigAmp21 = np.max(groupCF21[nnSigWinL:nnSigWinR])\n",
    "        SigAmpAve21 = np.mean(groupCF21[nnSigWinL:nnSigWinR])\n",
    "        NoiseAmpAve21 = np.mean(groupCF21[nnNoiseWinL:nnNoiseWinR])\n",
    "        if NoiseAmpAve21 == 0:\n",
    "            if SigAmp21 > 0:\n",
    "                SNR21 = 100\n",
    "            else:\n",
    "                SNR21 = 0\n",
    "        else:\n",
    "            SNR21 = SigAmp21/NoiseAmpAve21\n",
    "\n",
    "        SNR[j] = np.nan_to_num(min(SNR12,SNR21))\n",
    "        \n",
    "    idx = []\n",
    "    for k in range(len(r)):\n",
    "        if SNR[k] < np.mean(SNR)*SNRmin:\n",
    "            idx.append(k)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isline = False\n",
    "LenFD = 3\n",
    "dir_src = dir_project + 'ModelValidate/src'+str(isrc)+'/'\n",
    "putinrou = [dir_CC + 'CFs_modelvalidate/'+ 'gather_all_modelvalidate.h5']\n",
    "syn_stalist = dir_file + 'stations_in.txt'\n",
    "sele_stalist = dir_file + 'stations_in.txt'\n",
    "srclist = dir_file + 'stations_virsrc.txt'\n",
    "inputpath = dir_src + 'input/'\n",
    "outputpath = dir_src + 'output/'\n",
    "fileFDconf = dir_src + 'SeisFD3D.conf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  srcsta:\t R2713\n"
     ]
    }
   ],
   "source": [
    "virsta = []\n",
    "sta_profile = pandas.read_table(srclist, header=None, sep='\\\\s+')\n",
    "net = list(sta_profile[0][:])\n",
    "sta = list(sta_profile[1][:])\n",
    "for i in range(len(sta)):\n",
    "    virsta.append(str(sta[i]))\n",
    "srcsta = virsta[isrc-1]\n",
    "print('  srcsta:\\t', srcsta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny = 2014\\nfor d in range(128,158):\\n    year = str(y)\\n    day = \"%03d\"%d\\n    outname = os.path.join(dir_CC,year+\\'-\\'+day+\\'.npz\\')\\n    try:\\n        data = np.load(outname)\\n        ncfs = data[\\'ncfs\\']\\n        nan = np.sum(np.isnan(ncfs))\\n        shape = ncfs.shape\\n        print(\\'day\\', d, \\'shape: \\', shape, \\' nan: \\', nan)\\n    except:\\n        print(\\'no file: \\', outname)\\n        continue\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "y = 2014\n",
    "for d in range(128,158):\n",
    "    year = str(y)\n",
    "    day = \"%03d\"%d\n",
    "    outname = os.path.join(dir_CC,year+'-'+day+'.npz')\n",
    "    try:\n",
    "        data = np.load(outname)\n",
    "        ncfs = data['ncfs']\n",
    "        nan = np.sum(np.isnan(ncfs))\n",
    "        shape = ncfs.shape\n",
    "        print('day', d, 'shape: ', shape, ' nan: ', nan)\n",
    "    except:\n",
    "        print('no file: ', outname)\n",
    "        continue\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================read observed Ccfs====================================\n",
    "CC_file = []\n",
    "CC_prof = []\n",
    "for i in range(len(putinrou)):\n",
    "  CC_prof.append(pandas.read_hdf(putinrou[i], 'cc_prof'))\n",
    "  with h5py.File(putinrou[i], mode = \"r\") as file_rou:\n",
    "      CC_file.append(np.array(file_rou[list(file_rou.keys())[0]]))\n",
    "CC_array = CC_file[0]\n",
    "CC_table = CC_prof[0]\n",
    "f_prof = pandas.read_hdf(putinrou[0], 'freq')\n",
    "freq = np.array(f_prof[:])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============selec Ccfs based on srcstat=====================================\n",
    "sele_netsta = []\n",
    "with open(sele_stalist, 'r') as f:\n",
    "    while True:\n",
    "        tmp = f.readline()\n",
    "        if tmp:\n",
    "            sele_netsta.append(tmp.split()[0] + '-' + tmp.split()[1])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "part_CC = []\n",
    "part_dis = []\n",
    "CC_sta_name = []\n",
    "cc_name = CC_table['0cc_name']\n",
    "indexes = []\n",
    "for i in range(len(cc_name)):\n",
    "    cc_pairs_sta2 = cc_name[i].split('_')\n",
    "    netsta1 = cc_pairs_sta2[0]\n",
    "    netsta2 = cc_pairs_sta2[1]\n",
    "    #print(cc_pairs_sta2)\n",
    "    if srcsta in cc_pairs_sta2:\n",
    "    #if (netsta1 in sele_netsta) and (netsta2 in sele_netsta) and (srcsta in cc_pairs_sta2):\n",
    "       indexes.append(i)\n",
    "       part_CC.append((CC_array[i,:]).copy())\n",
    "       part_dis.append(CC_table.iloc[i,3]) #km\n",
    "       if srcsta == netsta1:\n",
    "          CC_sta_name.append(netsta2)\n",
    "       else:\n",
    "          CC_sta_name.append(netsta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_rou_nonezerocc:  (85, 3000)\n",
      "dis_vin_nonezerocc:  (85,)\n"
     ]
    }
   ],
   "source": [
    "#print(\"CC_sta_name: \", CC_sta_name)\n",
    "part_CC = np.array(part_CC)\n",
    "part_dis = np.array(part_dis)\n",
    "dele_cc_rows = []\n",
    "for CC_num in range(part_CC.shape[0]):\n",
    "  #if part_CC[CC_num,:].all() == 0:\n",
    "      #print(CC_num)\n",
    "      #dele_cc_rows.append(CC_num)\n",
    "  if part_dis[CC_num] == 0 or part_dis[CC_num]>= flag_maxd:\n",
    "      dele_cc_rows.append(CC_num)\n",
    "dele_cc_rows = list(set(dele_cc_rows))\n",
    "dele_cc_rows.sort()\n",
    "raw_rou_nonezerocc = np.delete(part_CC, dele_cc_rows, axis = 0)\n",
    "dis_vin_nonezerocc = np.delete(part_dis, dele_cc_rows, axis = 0)\n",
    "for counter, index in enumerate(dele_cc_rows):\n",
    "    index = index-counter\n",
    "    CC_sta_name.pop(index)\n",
    "\n",
    "print(\"raw_rou_nonezerocc: \", raw_rou_nonezerocc.shape)\n",
    "print(\"dis_vin_nonezerocc: \", dis_vin_nonezerocc.shape)\n",
    "#print(\"time: \", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idel = getSNR(raw_rou_nonezerocc,dis_vin_nonezerocc,freq,SNRmin=flag_SNRmin)\n",
    "idel = list(set(idel))\n",
    "idel.sort()\n",
    "raw_rou_nonezerocc = np.delete(raw_rou_nonezerocc,idel,axis=0)\n",
    "dis_vin_nonezerocc = np.delete(dis_vin_nonezerocc,idel,axis=0)\n",
    "for counter, index in enumerate(idel):\n",
    "    index = index-counter\n",
    "    CC_sta_name.pop(index)\n",
    "\n",
    "#============obtain time-domain Green's function=================================================\n",
    "ncfs0 = raw_rou_nonezerocc\n",
    "robs = dis_vin_nonezerocc #km\n",
    "dtobs = 1/np.max(freq)\n",
    "tobs = (np.linspace(-len(freq)/2, len(freq)/2-1, len(freq))-0.5)*dtobs\n",
    "ncfst = np.zeros(np.shape(ncfs0))\n",
    "for i in range(len(ncfs0)):\n",
    "  ncfst[i,:] = np.real(np.fft.fftshift(np.fft.ifft(ncfs0[i,:])))\n",
    "\n",
    "cfs = (ncfst[:,int(len(freq)/2):1:-1] + ncfst[:,int(len(freq)/2+1)::]) / 2 \n",
    "cfs_grad = -np.gradient(cfs,axis=1,edge_order=1)/dtobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========convolve with the ricker wavelet=============================================================\n",
    "tt = tobs[int(len(freq)/2+1)::]\n",
    "wavelet = np.zeros(len(tt))\n",
    "waveobs = np.zeros((cfs_grad.shape[0],len(tt)))\n",
    "for i in range(len(tt)):\n",
    "   wavelet[i] = ricker(tt[i],f_rick_c,t_rick_shift)\n",
    "indx_obs = int(t_rick_shift/dtobs)\n",
    "for j in range(cfs_grad.shape[0]):\n",
    "   tmp = np.convolve(wavelet,cfs_grad[j,:])\n",
    "   waveobs[j,:] = tmp[indx_obs:len(tt)+indx_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========windowed waveform=================================================\n",
    "fs_obs = 1.0/(tt[1]-tt[0])\n",
    "lowcut = 1.0 / bands[:,1]\n",
    "highcut = 1.0 / bands[:,0]\n",
    "waveobs_T = {}\n",
    "for j in range(len(bands)):\n",
    "    waveobs_T[j] = np.zeros(waveobs.shape)\n",
    "    for i in range(waveobs.shape[0]):   \n",
    "        waveobs_T[j][i,:] = butter_bandpass_filter(waveobs[i,:], lowcut[j], highcut[j], fs_obs, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 9, 10008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945423/1685725718.py:80: DeprecationWarning: 'scipy.integrate.cumtrapz' is deprecated in favour of 'scipy.integrate.cumulative_trapezoid' and will be removed in SciPy 1.14.0\n",
      "  Dz0 = integrate.cumtrapz(Vz, t, axis=1, initial=0)\n"
     ]
    }
   ],
   "source": [
    "#===================Process synthetic waveforms==========================================================\n",
    "confFD = open(fileFDconf, 'r')\n",
    "linesFD = confFD.read().split('\\n')\n",
    "for j in range(len(linesFD)):\n",
    "  line = linesFD[j]\n",
    "  if line.find('#') >= 0: line = line[:line.find('#') - 1]\n",
    "  if line.split(' ')[0] == 'dims':\n",
    "    dims = [int(v) for v in line.split() if v.isdigit()][0:3]\n",
    "\n",
    "confFD.close()\n",
    "\n",
    "staloc = np.loadtxt(syn_stalist, usecols=[2,3])\n",
    "syn_netsta = []\n",
    "with open(syn_stalist, 'r') as f:\n",
    "    while True:\n",
    "        tmp = f.readline()\n",
    "        if tmp:\n",
    "           #syn_netsta.append(tmp.split()[0] + '-' + tmp.split()[1])\n",
    "           syn_netsta.append(tmp.split()[0])\n",
    "        else:\n",
    "            break\n",
    "Srloc = staloc[syn_netsta.index(srcsta)]\n",
    "#==============================================================================\n",
    "whitems = ['Vx', 'Vy', 'Vz', 'Txx', 'Tyy', 'Tzz', 'Txy', 'Txz', 'Tyz']\n",
    "\n",
    "isfirstget = True\n",
    "isgottime = False\n",
    "iline = 0\n",
    "for k in range(dims[2]):\n",
    "  for j in range(dims[1]):\n",
    "    for i in range(dims[0]):\n",
    "      filename = '{}seismo_mpi{:02d}{:02d}{:02d}.nc'.format(outputpath, i, j, k)\n",
    "      if not os.path.isfile(filename):\n",
    "        continue\n",
    "      ssm = nc.Dataset(filename, 'r')\n",
    "      filename = '{}station_mpi{:02d}{:02d}{:02d}.nc'.format(inputpath, i, j, k)\n",
    "      stn = nc.Dataset(filename, 'r')\n",
    "      pid = stn.variables['id'][:]#get the station index(two dimension)\n",
    "      if not isgottime:\n",
    "        t = ssm.variables['time'][:]\n",
    "        isgottime = True\n",
    "        nt = t.size # the acctural points stored in the Seis.nc\n",
    "      for ip in range(pid.shape[0]):\n",
    "        if pid[ip, 1] == iline:#equals to the L/P-index(P=0) ////get id from STA.nc ///to confirm line number\n",
    "          ttvar = np.zeros((1, 1, nt))\n",
    "          ttvar[0, 0, :] = np.reshape(ssm.variables[whitems[0]][:, ip], [nt]) #get the ip strip in Vx, and flaten into [nt] case\n",
    "          for iw in range(1,9):\n",
    "            tvar = np.reshape(ssm.variables[whitems[iw]][:, ip], [1, 1, nt])\n",
    "            ttvar = np.append(ttvar, tvar, axis = 1) #all stored in falten case and different in layerd direction\n",
    "          if isfirstget:\n",
    "            dvar = ttvar[:] #data  dvar[Var][Var][nt]\n",
    "            ipoint = pid[ip, 0] # relevent index(start from 1)\n",
    "            isfirstget = False\n",
    "          else:\n",
    "            dvar = np.append(dvar, ttvar, axis = 0)\n",
    "            ipoint = np.append(ipoint, pid[ip, 0])\n",
    "      stn.close()\n",
    "      ssm.close()\n",
    "#ipoint is absolute point location in point series(sequence in line).\n",
    "if 'ipoint' not in globals():\n",
    "  raise IOError('Maybe no seismogram data files in the outputpath: ' + outputpath)\n",
    "\n",
    "# nt point in time series\n",
    "# npt point in record index series\n",
    "\n",
    "npt = ipoint.size\n",
    "pvar = np.zeros((npt, 9, nt)) #RECiver Var Time\n",
    "for ip in range(npt):\n",
    "  pvar[ipoint[ip] - 1, :, :] = dvar[ip, :, :] \n",
    "for iw in range(9):\n",
    "  if iw < 3:\n",
    "    pvar[:, iw, :] = pvar[:, iw, :]/1.0e3\n",
    "  else:\n",
    "    pvar[:, iw, :] = pvar[:, iw, :]/1.0e9\n",
    "\n",
    "print(np.shape(pvar))\n",
    "\n",
    "# Integrate to obtain Displacement\n",
    "Vz = pvar[:, 2, :]\n",
    "Dz0 = integrate.cumtrapz(Vz, t, axis=1, initial=0)\n",
    "stpindx = int(t_rick_shift/(t[1]-t[0]))\n",
    "tc = t[:len(t)-stpindx]\n",
    "Dz = Dz0[:,stpindx:]\n",
    "\n",
    "\n",
    "# filter-----------------------------------------------------------\n",
    "fs_syn = 1.0/(t[1]-t[0])\n",
    "wavesyn_T = {}\n",
    "for i in range(len(bands)):\n",
    "    wavesyn_T[i] = np.zeros(Dz.shape)\n",
    "    for j in range(Dz.shape[0]):\n",
    "        wavesyn_T[i][j,:] = butter_bandpass_filter(Dz[j,:], lowcut[i], highcut[i], fs_syn, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============correct synthesized waveform with observed waveform based on station interval==========================================================\n",
    "#print(\"robs: \", robs)\n",
    "#print(\"rsyn: \", rsyn)\n",
    "indxcorr_syn = []\n",
    "indxcorr_obs = []\n",
    "r_plot = []\n",
    "#print(\"netsta: \", netsta)\n",
    "for i in range(len(robs)):\n",
    "  #print(\"CC_sta_name: \", CC_sta_name[i])\n",
    "  if CC_sta_name[i] in syn_netsta:\n",
    "      indxcorr_obs.append(i)\n",
    "      indxcorr_syn.append(syn_netsta.index(CC_sta_name[i]))\n",
    "      r_plot.append(robs[i])\n",
    "#print(\"indxcorr_obs: \", indxcorr_obs)\n",
    "#print(\"indxcorr_syn: \", indxcorr_syn)\n",
    "r_plot = np.array(r_plot)\n",
    "wavesync_T = {}\n",
    "waveobsc_T = {}\n",
    "for i in range(len(bands)):\n",
    "    wavesync_T[i] = wavesyn_T[i][indxcorr_syn]\n",
    "    waveobsc_T[i] = waveobs_T[i][indxcorr_obs]\n",
    "\n",
    "#print(\"wave0syn: \", wave0syn.shape)\n",
    "#print(\"wave0sync: \", wave0sync.shape)\n",
    "#print(\"wave0obsc: \", wave0obsc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aver \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.39\u001b[39m,\u001b[38;5;241m0.45\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.55\u001b[39m])\n\u001b[1;32m      2\u001b[0m t_left_shits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0.03\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m t_right_shits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.23\u001b[39m,\u001b[38;5;241m0.23\u001b[39m,\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.3\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "aver = np.array([0.39,0.45,0.5,0.55])\n",
    "t_left_shits = np.array([0,0.03,0,0])\n",
    "t_right_shits = np.array([0.23,0.23,0.2,0.3])\n",
    "flag_inter = 4\n",
    "waveobsc_T_copy = waveobsc_T.copy()\n",
    "wavesync_T_copy = wavesync_T.copy()\n",
    "\n",
    "#==============================================================================\n",
    "plt.style.use(dir_src+'/sc.p4.mplstyle')\n",
    "textx = -0.11\n",
    "texty =1.07\n",
    "xlimt = 3 #s\n",
    "ylimt = 1 #km\n",
    "scale1 = 0.005\n",
    "scale2 = 0.005\n",
    "linew = 2.0\n",
    "fonts = 10\n",
    "\n",
    "for i in range(len(bands)):\n",
    "  fig = plt.figure(figsize = (8, 6), dpi = 80)\n",
    "  ax0 = plt.gca()\n",
    "  \n",
    "  for j in range(0,len(r_plot),flag_inter):\n",
    "    t0 = r_plot[j]/aver[0]-t_left_shits[i]\n",
    "    t1 = r_plot[j]/aver[0]+t_right_shits[i]\n",
    "    indx0 = int(t0/dtobs)\n",
    "    indx1 = int(t1/dtobs)\n",
    "    waveobsc_T_copy[i][j,:indx0] = 0\n",
    "    waveobsc_T_copy[i][j,indx1:] = 0\n",
    "    pt,= plt.plot(tt, waveobsc_T_copy[i][j,:]/(np.max(abs(waveobsc_T_copy[i][j,:])))*scale2+r_plot[j],'b', antialiased='False',linewidth=linew)\n",
    "    label = \"Observation (\"+str(int(1/bands[i][1]))+\"-\"+str(int(1/bands[i][0]))+\"Hz)\"\n",
    "    pt0,= plt.plot(tc, wavesync_T_copy[i][j]/np.max(abs(wavesync_T_copy[i][j]))*scale1+r_plot[j], 'r', antialiased='False', linewidth=linew)\n",
    "    label0 = \"This study    (\"+str(int(1/bands[i][1]))+\"-\"+str(int(1/bands[i][0]))+\"Hz)\"\n",
    "  #plt.ylim([0, ylimt])\n",
    "  plt.ylim([0.01, 0.12])\n",
    "  plt.xlim([0, 1.2])\n",
    "  ax0.xaxis.set_major_locator(ticker.MaxNLocator(7))\n",
    "  ax0.xaxis.set_minor_locator(ticker.MaxNLocator(35))\n",
    "  ax0.yaxis.set_major_locator(ticker.MaxNLocator(9))\n",
    "  ax0.yaxis.set_minor_locator(ticker.MaxNLocator(45))\n",
    "  plt.xlabel('Time (s)')\n",
    "  plt.ylabel('Distance (km)')\n",
    "\n",
    "  plt.legend([pt, pt0],[label, label0],  loc=4)\n",
    "  #plt.title('Waveform comparison for 3-7s')\n",
    "  plt.savefig(dir_image+'comparison_'+str(int(1/bands[i][1]))+'-'+str(int(1/bands[i][0]))+'Hz.jpg', dpi=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
