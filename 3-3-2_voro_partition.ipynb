{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "#from scipy import interp, arange, exp\n",
    "from ccfj import GetStationPairs\n",
    "import ccfj\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import geopandas as gp\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import shutil\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tools_F-J')\n",
    "from toollib_voro import PointinPolygon\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import mathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('a-project_voro.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project_repartrition/output_repar_03-01/'               # Harmon server\n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_stack = dir_project+info_basic['rdir_stack']\n",
    "dir_CC = dir_CC_workspace+info_basic['rdir_CC']\n",
    "dir_ds =  dir_project + info_basic['rdir_ds']\n",
    "stalistname_all = info_basic['stalistname_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pairs(sta):\n",
    "    p = []\n",
    "    nsta = len(sta)\n",
    "    for ii in range(nsta):\n",
    "        for jj in range(ii+1,nsta):\n",
    "            p.append([sta[ii],sta[jj]])\n",
    "    return p\n",
    "def cal_indx(pair,nsta):\n",
    "    indx = int(pair[0]*(2*nsta-pair[0]-1)/2+pair[1]-pair[0]-1)\n",
    "    return indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_window_filter(t,ncfst0,r,v_min,t0,a):\n",
    "    ncfst = ncfst0.copy()\n",
    "    for i in range(len(ncfst)):\n",
    "        tag = r[i]/v_min\n",
    "        #print(t0,tag)\n",
    "        t1 = t[t>-tag-t0][t[t>-tag-t0]< tag+t0]\n",
    "        start = np.where(t == t1[0])[0][0]\n",
    "        end = np.where(t == t1[-1])[0][0]\n",
    "        ncfst[i][start:end+1]= ncfst[i][start:end+1]* np.exp(-a*np.abs((tag-np.abs(t1))))\n",
    "    return ncfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleVoro(indx0,outname,xvyv):\n",
    "    global ncfs\n",
    "    global f0\n",
    "    global c\n",
    "    global nf\n",
    "    global r\n",
    "    global count\n",
    "    global dir_ds\n",
    "    global nsta\n",
    "\n",
    "    global t0\n",
    "    global a\n",
    "    global v_tag\n",
    "\n",
    "    filename = os.path.join(dir_ds,outname+'.h5')\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    \n",
    "    subpairs = Pairs(indx0)\n",
    "    indx1 = [cal_indx(pair,nsta) for pair in subpairs]\n",
    "    ncfsi = ncfs[indx1,:]\n",
    "    counti = count[indx1]\n",
    "    ri = r[indx1]\n",
    "    indx = np.argsort(ri)\n",
    "    ri = ri[indx]\n",
    "    ncfsi = ncfsi[indx,:]\n",
    "    counti = counti[indx]\n",
    "    ncfsi = ncfsi[counti!=0]\n",
    "    ri = ri[counti!=0]\n",
    "    counti = counti[counti!=0]\n",
    "    for i in range(len(ri)):\n",
    "        ncfsi[i,:] = ncfsi[i,:]/counti[i]\n",
    "\n",
    "    dt = 1/np.max(f0)\n",
    "    t = (np.linspace(-len(f0)-1,len(f0)-1,2*(len(f0)-1))+0.5)*dt/2\n",
    "    ncfst_linear = mathlib.freq_time(ncfsi)\n",
    "    ncfst1 = time_window_filter(t,ncfst_linear,r,v_tag,t0,a)\n",
    "    ncfs_sum_remove = mathlib.time_freq(ncfst1)\n",
    "    \n",
    "    ds_11 = ccfj.fj_noise(np.real(ncfsi),ri,c,f0,itype=1,func=1)\n",
    "    ds_22 = ccfj.fj_noise(np.real(ncfs_sum_remove),ri,c,f0,itype=1,func=1)\n",
    "\n",
    "    ds_linear = np.array(ds_11).reshape(1,np.shape(ds_11)[0],np.shape(ds_11)[1])\n",
    "    ds_remove = np.array(ds_22).reshape(1,np.shape(ds_22)[0],np.shape(ds_22)[1])\n",
    "\n",
    "    h5file=h5py.File(filename,'w')\n",
    "    h5file.create_dataset('ds_linear',data=ds_linear)\n",
    "    h5file.create_dataset('ds_remove',data=ds_remove)\n",
    "    h5file.create_dataset('c',data=c)\n",
    "    h5file.create_dataset('f',data=f0)\n",
    "    h5file.create_dataset('indx',data=indx0)\n",
    "    h5file.create_dataset('xvyv',data=xvyv)\n",
    "    h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta = len(stainfo.iloc[:,0])\n",
    "staloc = np.asarray([stainfo['longitude'],stainfo['latitude']]).T\n",
    "# The KDE of the stations' locations\n",
    "kernel = stats.gaussian_kde(staloc.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncffile = h5py.File( dir_CC+ 'gather_all.h5','r')\n",
    "ncfs = ncffile['ncfs'][:]\n",
    "f0 = ncffile['f'][:]\n",
    "count = ncffile['count'][:]\n",
    "r = ncffile['r'][:]\n",
    "ncffile.close()\n",
    "nf = info_basic['nf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_min = 0.200\n",
    "c_max = 2\n",
    "c_num = 800\n",
    "info_basic['c_min'] = c_min\n",
    "info_basic['c_max'] = c_max\n",
    "info_basic['c_num'] = c_num\n",
    "c = np.linspace(c_min,c_max,c_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VoroTomo Partition times\n",
    "n_voro = 100\n",
    "# number of Voro cells  range\n",
    "kmin = 10\n",
    "kmax = 20\n",
    "\n",
    "# Set a larger range of the stations to facilitate the calculation of Voronoi cells\n",
    "# the points0 are not used in the inner Voronoi cells generating\n",
    "Radius = 10 \n",
    "x0 = np.mean(staloc[:,0])\n",
    "y0 = np.mean(staloc[:,1])\n",
    "minx = min(staloc[:,0]);maxx = max(staloc[:,0])\n",
    "miny = min(staloc[:,1]);maxy = max(staloc[:,1])\n",
    "points0 = []\n",
    "for i in range(36):\n",
    "    points0.append([x0+np.cos(i/18*np.pi),y0+np.sin(i/18*np.pi)])\n",
    "points0=np.asarray(points0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_basic['voro_n'] = n_voro\n",
    "info_basic['voro_kmin'] = kmin\n",
    "info_basic['voro_kmax'] = kmax\n",
    "info_basic['voro_Radius'] = Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tag = 2\n",
    "a = 100\n",
    "t0 = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting Voronoi Partitioning\n",
    "key_subworks = []\n",
    "for ii in range(n_voro):\n",
    "    print('start:' + str(ii))\n",
    "    # random the number of Voronoi cells\n",
    "    k = np.random.randint(kmin,kmax)\n",
    "    # Using the KDE PDF to generate Voronoi cells\n",
    "    points = kernel.resample(k).T \n",
    "    # Using the Uniform distribution to generate Voronoi cells\n",
    "    '''\n",
    "    points = np.random.rand(k,2)\n",
    "    points[:,0] = points[:,0]*(maxx-minx) + minx\n",
    "    points[:,1] = points[:,1]*(maxy-miny) + miny\n",
    "    '''\n",
    "    # Voronoi Partition\n",
    "    points = np.concatenate((points,points0))\n",
    "    vor = Voronoi(points)\n",
    "    areas = []\n",
    "    for j in range(k):\n",
    "        xv = vor.vertices[vor.regions[vor.point_region[j]],0]\n",
    "        yv = vor.vertices[vor.regions[vor.point_region[j]],1]\n",
    "        _in,_on = PointinPolygon.inpolygon(staloc[:,0],staloc[:,1],xv,yv)\n",
    "        indx = np.array([i for i,x in enumerate(_in) if x])\n",
    "        if len(indx)>10:\n",
    "            areas.append([indx,np.array([xv,yv])])\n",
    "    vor.close()\n",
    "    for j in range(len(areas)):\n",
    "        key_subwork = 'vor'+str(ii)+'_'+str(j)\n",
    "        key_subworks.append(key_subwork)\n",
    "        print(ii,j,len(areas[j][0]))\n",
    "        # calculate the F-J spectrum\n",
    "        singleVoro(areas[j][0],key_subwork,areas[j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_basic['key_subworks'] = key_subworks\n",
    "with open(dir_project+'Basic_info.yml', 'w', encoding='utf-8') as f:\n",
    "   yaml.dump(data=info_basic, stream=f, allow_unicode=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccfj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
