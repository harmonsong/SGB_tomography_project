{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "from ccfj import GetStationPairs\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import geopandas as gp\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.spatial import ConvexHull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import mathlib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_repartition_v3.0/output_repar_01-01/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('a-project_repar.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project_repartrition/output_repar_03-01/'               # Harmon server\n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_CC_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project:  /shdisk/rem2/Harmon/F-J/San/project_repartition_v3.0/output_repar_01-01/\n"
     ]
    }
   ],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_project_probes:  /shdisk/rem2/Harmon/F-J/San/project/output_FJSJ_17-01/\n",
      "dir_project_targets:  /shdisk/rem2/Harmon/F-J/San/project/output_FJSJ_17-02/\n"
     ]
    }
   ],
   "source": [
    "name_project_probes = info_basic['name_project_probes']\n",
    "name_project_targets = info_basic['name_project_targets']\n",
    "dir_project_probes = os.path.join(dir_project_workspace, name_project_probes)\n",
    "dir_project_targets = os.path.join(dir_project_workspace, name_project_targets)\n",
    "print('dir_project_probes: ', dir_project_probes)\n",
    "print('dir_project_targets: ', dir_project_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project_probes+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic_probes = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project_probes+'Basic_info.npy'\n",
    "info_basic_bi_probes = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary\n",
    "\n",
    "filename = dir_project_targets+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic_targets = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "\n",
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = info_basic_probes['key_subworks']\n",
    "targets = info_basic_targets['key_subworks']\n",
    "key_subworks = info_basic['key_subworks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist()\n",
    "lat_all = stainfo['latitude'].tolist() \n",
    "lon_all = stainfo['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname = dir_project_probes+ info_basic_probes['stalistname']\n",
    "stainfo_probes = pd.read_excel(stalistname,sheet_name=None)\n",
    "stalistname = dir_project_targets+ info_basic_targets['stalistname']\n",
    "stainfo_targets = pd.read_excel(stalistname,sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname = dir_project+ info_basic['stalistname']\n",
    "stainfo_all = pd.read_excel(stalistname,sheet_name=None)\n",
    "\n",
    "stalistname = dir_project_probes+ info_basic_probes['stalistname']\n",
    "stainfo_probes_all = pd.read_excel(stalistname,sheet_name=None)\n",
    "\n",
    "stalistname = dir_project_targets+ info_basic_targets['stalistname']\n",
    "stainfo_targets_all = pd.read_excel(stalistname,sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname = dir_project + 'subwork_location.xlsx'\n",
    "loc_key = pd.read_excel(stalistname,sheet_name='location')\n",
    "lat_key = loc_key['lat_centroid'].tolist()\n",
    "lon_key = loc_key['lon_centroid'].tolist()\n",
    "\n",
    "stalistname = dir_project_probes + 'subwork_location.xlsx'\n",
    "loc_key_probes = pd.read_excel(stalistname,sheet_name='location')\n",
    "key_probes = loc_key_probes['key_subwork'].tolist()\n",
    "lat_key_probes = loc_key_probes['lat_centroid'].tolist()\n",
    "lon_key_probes = loc_key_probes['lon_centroid'].tolist()\n",
    "\n",
    "stalistname = dir_project_targets + 'subwork_location.xlsx'\n",
    "loc_key_targets = pd.read_excel(stalistname,sheet_name='location')\n",
    "key_targets = loc_key_targets['key_subwork'].tolist()\n",
    "lat_key_targets = loc_key_targets['lat_centroid'].tolist()\n",
    "lon_key_targets = loc_key_targets['lon_centroid'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_probes = pd.read_excel(dir_project_probes + 'subwork_location.xlsx',sheet_name='location')\n",
    "loc_targets = pd.read_excel(dir_project_targets + 'subwork_location.xlsx',sheet_name='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = np.load('clark_faults.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_image:  /shdisk/rem2/Harmon/F-J/San/project_repartition_v3.0/output_repar_01-01/image_01-01/\n",
      "dir_disp:  /shdisk/rem2/Harmon/F-J/San/project/output_FJSJ_17-01/autopick17-01//\n"
     ]
    }
   ],
   "source": [
    "dir_image = dir_project+info_basic['dir_image']\n",
    "dir_disp_probes  = dir_project_probes + info_basic_probes['dir_disp'] \n",
    "print('dir_image: ', dir_image)\n",
    "print('dir_disp: ', dir_disp_probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_accept_all = info_basic_bi['probe_accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_mean = info_basic_bi['phase_mean']\n",
    "ks_f_range = info_basic['ks_f_range']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_err:  0.05\n",
      "flag_pass:  0.3\n"
     ]
    }
   ],
   "source": [
    "flag_err = info_basic['flag_err']\n",
    "flag_pass = info_basic['flag_pass']\n",
    "print('flag_err: ', flag_err)\n",
    "print('flag_pass: ', flag_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_repick = [29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_subworks = []\n",
    "for num in nums_repick:\n",
    "    tag = str(num)\n",
    "    key_subwork0 = [key_subwork for key_subwork in info_basic['key_subworks'] if tag == key_subwork[-len(str(tag)):]][0]\n",
    "    key_subworks.append(key_subwork0)\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read All ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_target_all = {}\n",
    "for target in targets:\n",
    "    file_ds = dir_project_targets + info_basic_targets['dir_ds'] + 'ds_'+target+'.h5'\n",
    "    ds = h5py.File(file_ds,'r')\n",
    "    ds_target_all[target] = ds['ds_remove'][0]\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renew information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_probes(key_subwork):\n",
    "    global dir_project\n",
    "    global dir_project_probes\n",
    "    global dir_project_targets\n",
    "    global probes\n",
    "    global stainfo_targets\n",
    "\n",
    "    stas = stainfo_targets[key_subwork]['Station'].tolist()\n",
    "    # 生成sta的包络\n",
    "    #hull_sta = ConvexHull(stainfo_targets[key_subwork][['Longitude','Latitude']])\n",
    "\n",
    "    stas2key = [sta[1:3]+'-'+sta[3:] for sta in stas]\n",
    "    probes_this = []\n",
    "    for sta in stas2key:\n",
    "        if sta in probes:\n",
    "            probes_this.append(sta)\n",
    "    return probes_this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_accept_origin = info_basic_bi['probe_accept']\n",
    "key_probe = info_basic_bi['probe']\n",
    "for key_subwork in key_subworks:\n",
    "    target = key_subwork.split('--')[0]\n",
    "    probes_this = extract_probes(target)\n",
    "    key_probe[key_subwork] = probes_this\n",
    "    probe_accept_origin[target] = probes_this\n",
    "info_basic_bi['probe_accept'] = probe_accept_origin\n",
    "info_basic_bi['probe'] = key_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-12--401\n"
     ]
    }
   ],
   "source": [
    "filename = dir_project+'stations_info.xlsx'\n",
    "books = load_workbook(filename)\n",
    "writers = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "\n",
    "for key in key_subworks:\n",
    "    print(key)\n",
    "    target = key.split('--')[0]\n",
    "    df=pd.DataFrame()\n",
    "    df['Station'] = stainfo_targets[target]['Station']\n",
    "    df['latitude'] = stainfo_targets[target]['latitude']\n",
    "    df['longitude'] = stainfo_targets[target]['longitude']\n",
    "    df.to_excel(writers, sheet_name=key,index=False)\n",
    "writers.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project + 'subwork_location.xlsx'\n",
    "loc_info = pd.read_excel(filename,sheet_name='location')\n",
    "lat_centroid_all_origin = loc_info['lat_centroid'].tolist()\n",
    "lon_centroid_all_origin = loc_info['lon_centroid'].tolist()\n",
    "stations = loc_info['key_subwork'].tolist()\n",
    "for key in key_subworks:\n",
    "    index = stations.index(key)\n",
    "    target = key.split('--')[0]\n",
    "    index_target = targets.index(target)\n",
    "    lat_centroid_all_origin[index] = lat_key_targets[index_target]\n",
    "    lon_centroid_all_origin[index] = lon_key_targets[index_target]\n",
    "loc_info['lat_centroid'] = lat_centroid_all_origin\n",
    "loc_info['lon_centroid'] = lon_centroid_all_origin\n",
    "loc_info.to_excel(writers, sheet_name='location',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_project+'Basic_info.yml', 'w', encoding='utf-8') as f:\n",
    "   yaml.dump(data=info_basic, stream=f, allow_unicode=True)\n",
    "np.save(dir_project + 'Basic_info.npy', info_basic_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete original stack and ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_stack = dir_project + info_basic['dir_stack']\n",
    "dir_ds = dir_project + info_basic['dir_ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stack = os.listdir(dir_stack)\n",
    "list_ds = os.listdir(dir_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in key_subworks:\n",
    "    stack_this = key + '_gather_linear.h5'\n",
    "    stack_timewindow = key + '_gather_timewindow.h5'\n",
    "    ds_this = 'ds_'+key +'.h5'\n",
    "    if stack_this in list_stack:\n",
    "        print('delete ', stack_this)\n",
    "        os.remove(dir_stack + stack_this)\n",
    "    if stack_timewindow in list_stack:\n",
    "        print('delete ', stack_timewindow)\n",
    "        os.remove(dir_stack + stack_timewindow)\n",
    "    if ds_this in list_ds:\n",
    "        print('delete ', ds_this)\n",
    "        os.remove(dir_ds + ds_this)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccfj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
