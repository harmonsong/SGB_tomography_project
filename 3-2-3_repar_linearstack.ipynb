{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "from ccfj import GetStationPairs\n",
    "from ccfj import GetStationPairs\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import geopandas as gp\n",
    "from geopy.distance import great_circle\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import mathlib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_repartition_v3.0/output_repar_v9.1_test/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('a-project_repar.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project_repartrition/repartrition_01-03/'               # Harmon server\n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_CC_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project:  /shdisk/rem2/Harmon/F-J/San/project_repartition_v3.0/output_repar_v9.1_test/\n"
     ]
    }
   ],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1--08-03',\n",
       " '2--09-03',\n",
       " '3--10-03',\n",
       " '4--11-03',\n",
       " '5--12-03',\n",
       " '6--13-03',\n",
       " '7--14-03',\n",
       " '8--15-03',\n",
       " '9--16-03',\n",
       " '10--18-03',\n",
       " '11--19-03',\n",
       " '12--20-03',\n",
       " '13--21-03',\n",
       " '14--22-03',\n",
       " '15--23-03',\n",
       " '16--24-03',\n",
       " '17--25-03',\n",
       " '18--26-03']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_subworks = info_basic['key_subworks']\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_stack = dir_project+info_basic['dir_stack']\n",
    "dir_CC = dir_CC_workspace+info_basic['name_CC']\n",
    "dir_partition = dir_project + info_basic['dir_partition']\n",
    "#dir_CC = dir_CC_workspace+'CC/CC_40_prewhiten/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist()\n",
    "lat_all = stainfo['latitude'].tolist() \n",
    "lon_all = stainfo['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncffile = h5py.File( dir_CC+ 'gather_all.h5','r')\n",
    "ncfs = ncffile['ncfs'][:]\n",
    "f = ncffile['f'][:]\n",
    "count_all = ncffile['count'][:]\n",
    "ncffile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_basic_bi['r_max'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_stack(key_subwork):\n",
    "    global key_subworks\n",
    "    global dir_stack\n",
    "    global info_basic\n",
    "    global stainfo_all\n",
    "    global dir_partition\n",
    "\n",
    "    print(\"Collecting \",key_subwork,' ...')\n",
    "    if os.path.exists(dir_stack+str(key_subwork)+'_gather_linear.h5'):\n",
    "        print(\"File exists.\")\n",
    "        return\n",
    "\n",
    "    time0 = time.time()\n",
    "\n",
    "    nf = info_basic['nf']\n",
    "    \n",
    "    filepath = dir_partition + str(key_subwork) + '.txt'\n",
    "    stalist, lat, lon = np.loadtxt(filepath, dtype='str', unpack=True)\n",
    "    nsta = len(stalist)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    nPairs = int(len(StationPairs)/2)\n",
    "\n",
    "    ncfs_sum_linear = np.zeros((nPairs,nf),dtype=np.complex64)\n",
    "    r = np.zeros(nPairs)\n",
    "    count= np.zeros(nPairs)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    for i in range(nPairs):\n",
    "        sta1 = StationPairs[2*i]\n",
    "        sta2 = StationPairs[2*i+1]\n",
    "        idx1 = np.min( [int(stalist_all.index(stalist[sta1])),int(stalist_all.index(stalist[sta2]))] )\n",
    "        idx2 = np.max( [int(stalist_all.index(stalist[sta1])),int(stalist_all.index(stalist[sta2]))] )\n",
    "        #idx1 = int(stalist_all.index(stalist[sta1]))\n",
    "        #idx2 = int(stalist_all.index(stalist[sta2]))\n",
    "        #idx1 = int(stainfo[stainfo[key_pd]==stalist[sta1]].index.values[0])\n",
    "        #idx2 = int(stainfo[stainfo[key_pd]==stalist[sta2]].index.values[0])\n",
    "        \n",
    "        m = 0\n",
    "        for j in range(nsta_all-idx1,nsta_all):\n",
    "            m += j\n",
    "        num = m +idx2 - idx1 -1\n",
    "        \n",
    "        ncfs_sum_linear[i,:] = np.nan_to_num(ncfs[num,:])\n",
    "        count[i] = count_all[num]\n",
    "        #r[i] = r0[num]\n",
    "        #if count_all[num] > 0:\n",
    "        #    ncfs_sum_linear[i,:] = ncfs[num,:]/count_all[num]\n",
    "        #    count[i] = count_all[num]\n",
    "\n",
    "        r[i] = great_circle((lat[sta1],lon[sta1]),(lat[sta2],lon[sta2])).km\n",
    "        #names.append([stalist_all[StationPairs_all[2*num]],stalist_all[StationPairs_all[2*num+1]]])\n",
    "\n",
    "    outname = str(key_subwork)+'_gather_linear.h5'\n",
    "    if os.path.exists(dir_stack+outname):\n",
    "        os.remove(dir_stack+outname)\n",
    "    ncffile = h5py.File(dir_stack+outname,'w')\n",
    "    \n",
    "    ncffile.create_dataset('ncfs',data=ncfs_sum_linear)\n",
    "    ncffile.create_dataset('r',data=r)\n",
    "    ncffile.create_dataset('count',data=count)\n",
    "    ncffile.create_dataset('f',data=f)\n",
    "    ncffile.create_dataset('StationPairs',data=StationPairs)\n",
    "    #print(ncffile.keys())\n",
    "    ncffile.close()\n",
    "    #np.savez(dir_stack+key_subwork+\"_summed-linear.npz\",ncfs= ncfs_sum_linear,r = r,stalist=stalist,StationPairs=StationPairs)\n",
    "    print(\"Done in \",time.time()-time0,\" s.\", str(key_subworks.index(key_subwork)+1),'/',len(key_subworks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nThreads = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting  1--08-03  ...\n",
      "Done in  0.234389066696167  s. 1 / 18\n",
      "Collecting  2--09-03  ...\n",
      "Done in  0.24254512786865234  s. 2 / 18\n",
      "Collecting  3--10-03  ...\n",
      "Done in  0.5593142509460449  s. 3 / 18\n",
      "Collecting  4--11-03  ...\n",
      "Done in  0.44658613204956055  s. 4 / 18\n",
      "Collecting  5--12-03  ...\n",
      "Done in  0.41878652572631836  s. 5 / 18\n",
      "Collecting  6--13-03  ...\n",
      "Done in  0.4696981906890869  s. 6 / 18\n",
      "Collecting  7--14-03  ...\n",
      "Done in  0.45261216163635254  s. 7 / 18\n",
      "Collecting  8--15-03  ...\n",
      "Done in  0.47664666175842285  s. 8 / 18\n",
      "Collecting  9--16-03  ...\n",
      "Done in  0.5137462615966797  s. 9 / 18\n",
      "Collecting  10--18-03  ...\n",
      "Done in  0.606677770614624  s. 10 / 18\n",
      "Collecting  11--19-03  ...\n",
      "Done in  0.738044261932373  s. 11 / 18\n",
      "Collecting  12--20-03  ...\n",
      "Done in  0.7895646095275879  s. 12 / 18\n",
      "Collecting  13--21-03  ...\n",
      "Done in  0.684561014175415  s. 13 / 18\n",
      "Collecting  14--22-03  ...\n",
      "Done in  0.432894229888916  s. 14 / 18\n",
      "Collecting  15--23-03  ...\n",
      "Done in  0.2493281364440918  s. 15 / 18\n",
      "Collecting  16--24-03  ...\n",
      "Done in  0.4061882495880127  s. 16 / 18\n",
      "Collecting  17--25-03  ...\n",
      "Done in  0.5876445770263672  s. 17 / 18\n",
      "Collecting  18--26-03  ...\n",
      "Done in  0.5517878532409668  s. 18 / 18\n"
     ]
    }
   ],
   "source": [
    "for key_subwork in key_subworks:\n",
    "    linear_stack(key_subwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(filename_bi,info_basic_bi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccfj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
