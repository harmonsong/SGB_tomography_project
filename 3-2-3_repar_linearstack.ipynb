{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "from ccfj import GetStationPairs\n",
    "from ccfj import GetStationPairs\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import geopandas as gp\n",
    "from geopy.distance import great_circle\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import mathlib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_repartition_v3.0/output_repar_v9.1_test/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('a-project_repar.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project_repartrition/repartrition_01-03/'               # Harmon server\n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_CC_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project:  /shdisk/rem2/Harmon/F-J/San/project_repartition_v3.0/output_repar_v9.1_test/\n"
     ]
    }
   ],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2--09-03',\n",
       " '3--10-03',\n",
       " '4--11-03',\n",
       " '5--12-03',\n",
       " '6--13-03',\n",
       " '7--14-03',\n",
       " '8--15-03',\n",
       " '9--16-03',\n",
       " '10--18-03',\n",
       " '11--19-03',\n",
       " '12--20-03',\n",
       " '13--21-03',\n",
       " '14--22-03',\n",
       " '15--23-03',\n",
       " '16--24-03',\n",
       " '17--25-03',\n",
       " '18--26-03']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_subworks = info_basic['key_subworks']\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3--10-03', '6--13-03', '5--12-03', '2--09-03', '4--11-03']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'key_subworks_repick' in info_basic.keys():\n",
    "    key_subworks_repick = info_basic['key_subworks_repick']\n",
    "else:\n",
    "    key_subworks_repick = []\n",
    "key_subworks_repick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_stack = dir_project+info_basic['dir_stack']\n",
    "dir_CC = dir_CC_workspace+info_basic['name_CC']\n",
    "dir_partition = dir_project + info_basic['dir_partition']\n",
    "\n",
    "#dir_CC = dir_CC_workspace+'CC/CC_40_prewhiten/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist()\n",
    "lat_all = stainfo['latitude'].tolist() \n",
    "lon_all = stainfo['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncffile = h5py.File( dir_CC+ 'gather_all.h5','r')\n",
    "ncfs = ncffile['ncfs'][:]\n",
    "f = ncffile['f'][:]\n",
    "count_all = ncffile['count'][:]\n",
    "ncffile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_basic_bi['r_max'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_stack(key_subwork):\n",
    "    global key_subworks\n",
    "    global dir_stack\n",
    "    global info_basic\n",
    "    global stainfo_all\n",
    "    global dir_partition\n",
    "    global key_subworks_repick\n",
    "\n",
    "    print(\"Collecting \",key_subwork,' ...')\n",
    "    outname = str(key_subwork)+'_gather_linear.h5'\n",
    "    if key_subwork in key_subworks_repick:\n",
    "        if os.path.exists(dir_stack+outname):\n",
    "            os.remove(dir_stack+outname)\n",
    "    if os.path.exists(dir_stack+str(key_subwork)+'_gather_linear.h5'):\n",
    "        print(\"File exists.\")\n",
    "        return\n",
    "\n",
    "    time0 = time.time()\n",
    "\n",
    "    nf = info_basic['nf']\n",
    "    \n",
    "    filepath = dir_partition + str(key_subwork) + '.txt'\n",
    "    stalist, lat, lon = np.loadtxt(filepath, dtype='str', unpack=True)\n",
    "    nsta = len(stalist)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    nPairs = int(len(StationPairs)/2)\n",
    "\n",
    "    ncfs_sum_linear = np.zeros((nPairs,nf),dtype=np.complex64)\n",
    "    r = np.zeros(nPairs)\n",
    "    count= np.zeros(nPairs)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    for i in range(nPairs):\n",
    "        sta1 = StationPairs[2*i]\n",
    "        sta2 = StationPairs[2*i+1]\n",
    "        idx1 = np.min( [int(stalist_all.index(stalist[sta1])),int(stalist_all.index(stalist[sta2]))] )\n",
    "        idx2 = np.max( [int(stalist_all.index(stalist[sta1])),int(stalist_all.index(stalist[sta2]))] )\n",
    "        #idx1 = int(stalist_all.index(stalist[sta1]))\n",
    "        #idx2 = int(stalist_all.index(stalist[sta2]))\n",
    "        #idx1 = int(stainfo[stainfo[key_pd]==stalist[sta1]].index.values[0])\n",
    "        #idx2 = int(stainfo[stainfo[key_pd]==stalist[sta2]].index.values[0])\n",
    "        \n",
    "        m = 0\n",
    "        for j in range(nsta_all-idx1,nsta_all):\n",
    "            m += j\n",
    "        num = m +idx2 - idx1 -1\n",
    "        \n",
    "        ncfs_sum_linear[i,:] = np.nan_to_num(ncfs[num,:])\n",
    "        count[i] = count_all[num]\n",
    "        #r[i] = r0[num]\n",
    "        #if count_all[num] > 0:\n",
    "        #    ncfs_sum_linear[i,:] = ncfs[num,:]/count_all[num]\n",
    "        #    count[i] = count_all[num]\n",
    "\n",
    "        r[i] = great_circle((lat[sta1],lon[sta1]),(lat[sta2],lon[sta2])).km\n",
    "        #names.append([stalist_all[StationPairs_all[2*num]],stalist_all[StationPairs_all[2*num+1]]])\n",
    "\n",
    "    \n",
    "    ncffile = h5py.File(dir_stack+outname,'w')\n",
    "    ncffile.create_dataset('ncfs',data=ncfs_sum_linear)\n",
    "    ncffile.create_dataset('r',data=r)\n",
    "    ncffile.create_dataset('count',data=count)\n",
    "    ncffile.create_dataset('f',data=f)\n",
    "    ncffile.create_dataset('StationPairs',data=StationPairs)\n",
    "    #print(ncffile.keys())\n",
    "    ncffile.close()\n",
    "    #np.savez(dir_stack+key_subwork+\"_summed-linear.npz\",ncfs= ncfs_sum_linear,r = r,stalist=stalist,StationPairs=StationPairs)\n",
    "    print(\"Done in \",time.time()-time0,\" s.\", str(key_subworks.index(key_subwork)+1),'/',len(key_subworks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nThreads = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting  2--09-03  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in  0.24718952178955078  s. 1 / 17\n",
      "Collecting  3--10-03  ...\n",
      "Done in  0.3785054683685303  s. 2 / 17\n",
      "Collecting  4--11-03  ...\n",
      "Done in  0.5221869945526123  s. 3 / 17\n",
      "Collecting  5--12-03  ...\n",
      "Done in  0.45369744300842285  s. 4 / 17\n",
      "Collecting  6--13-03  ...\n",
      "Done in  0.30153679847717285  s. 5 / 17\n",
      "Collecting  7--14-03  ...\n",
      "File exists.\n",
      "Collecting  8--15-03  ...\n",
      "File exists.\n",
      "Collecting  9--16-03  ...\n",
      "File exists.\n",
      "Collecting  10--18-03  ...\n",
      "File exists.\n",
      "Collecting  11--19-03  ...\n",
      "File exists.\n",
      "Collecting  12--20-03  ...\n",
      "File exists.\n",
      "Collecting  13--21-03  ...\n",
      "File exists.\n",
      "Collecting  14--22-03  ...\n",
      "File exists.\n",
      "Collecting  15--23-03  ...\n",
      "File exists.\n",
      "Collecting  16--24-03  ...\n",
      "File exists.\n",
      "Collecting  17--25-03  ...\n",
      "File exists.\n",
      "Collecting  18--26-03  ...\n",
      "File exists.\n"
     ]
    }
   ],
   "source": [
    "for key_subwork in key_subworks:\n",
    "    linear_stack(key_subwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(filename_bi,info_basic_bi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccfj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
