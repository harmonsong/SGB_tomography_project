{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import argparse\n",
    "from scipy.stats import gaussian_kde\n",
    "import os\n",
    "import yaml\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "sys.path.append(r'../tools_F-J/toollib_DisbaCode')\n",
    "from objective_function import (ObjectiveFunctionDerivativeUsed, Forward)\n",
    "from toollib_DisbaCode import forward\n",
    "from toollib_DisbaCode import objective_function\n",
    "from toollib_DisbaCode import empirical_relation\n",
    "from toollib_DisbaCode import plot_disp\n",
    "from toollib_DisbaCode import plot_model\n",
    "from toollib_DisbaCode import plot_lcurve\n",
    "from toollib_DisbaCode import plot_inversion    \n",
    "from toollib_DisbaCode import plot_kernel\n",
    "\n",
    "#from toollib_standard import maplib\n",
    "#from toollib_standard import mathlib\n",
    "#from toollib_standard import filelib\n",
    "#from toollib_standard import stacklib\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_project = 1 # 0--regular; 1--repartrition; 2--voronoi\n",
    "flag_mode = 2 # 0--fundamental; 1--Overtones; 2--Both\n",
    "flag_forward = 1 # 0--no forward calculation; 1--forward calculation\n",
    "file_init = 'initial/initial_model_4.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_project == 0:\n",
    "    file_project = 'a-project.yml'\n",
    "elif flag_project == 1:\n",
    "    file_project = 'a-project_repar.yml'\n",
    "elif flag_project == 2:\n",
    "    file_project = 'a-project_voro.yml'\n",
    "    \n",
    "with open(file_project, 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "\n",
    "#name_project = 'project/output_FJSJ_16-01/'               \n",
    "name_project = 'project_repartition_v4.0/output_repar_v9.5_01--10-16Hz/'         \n",
    "#name_project = 'project_voronoi/voronoi_01-03/'         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ds = dir_project + info_basic['rdir_ds']\n",
    "dir_partition = dir_project + info_basic['rdir_partition']\n",
    "dir_inv = dir_project + info_basic['rdir_inv_BFGS']\n",
    "f0 = info_basic_bi['f']\n",
    "c = np.linspace(info_basic['fj_c_min'], info_basic['fj_c_max'], info_basic['fj_c_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_near = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = dir_project+dir_inv_dispernet+ 'inv3.txt'\n",
    "#nums = np.loadtxt(filename,dtype=int)\n",
    "nums = [1] \n",
    "key_subworks_all = info_basic['key_subworks']\n",
    "key_subworks = []\n",
    "for num in nums:\n",
    "    for key_subwork in key_subworks_all:\n",
    "        if str(num) == key_subwork.split('--')[0]:\n",
    "            key_subworks.append(key_subwork)\n",
    "            break\n",
    "#key_subworks = info_basic['key_subworks']\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config_fund = 'config_inv_fund.yml'\n",
    "file_config = 'config_inv.yml'\n",
    "with open(dir_inv+file_config, 'r') as fp:\n",
    "    config = yaml.safe_load(fp)\n",
    "with open(dir_inv+file_config_fund, 'r') as fp:\n",
    "    config_fund = yaml.safe_load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_image = dir_project +  info_basic['rdir_image'] + 'inversion_compare_near/'\n",
    "if not os.path.exists(dir_image):\n",
    "    os.mkdir(dir_image)\n",
    "\n",
    "info_basic['rdir_BFGS_invfile'] = info_basic['rdir_inv_BFGS'] + 'inversion/'\n",
    "info_basic['rdir_disp_model'] = info_basic['rdir_inv_BFGS'] + 'disp_model/'\n",
    "info_basic['rdir_model'] = info_basic['rdir_inv_BFGS'] + 'model/'\n",
    "dir_invfile = dir_project + info_basic['rdir_BFGS_invfile']\n",
    "dir_disp_model = dir_project + info_basic['rdir_disp_model']\n",
    "dir_model = dir_project + info_basic['rdir_model']\n",
    "\n",
    "if not os.path.exists(dir_invfile):\n",
    "    os.mkdir(dir_invfile)\n",
    "if not os.path.exists(dir_disp_model):\n",
    "    os.mkdir(dir_disp_model)\n",
    "if not os.path.exists(dir_model):\n",
    "    os.mkdir(dir_model)\n",
    "info_basic['rdir_BFGS_invfile_fund'] = info_basic['rdir_inv_BFGS'] + 'inversion_fund/'\n",
    "info_basic['rdir_disp_model_fund'] = info_basic['rdir_inv_BFGS'] + 'disp_model_fund/'\n",
    "info_basic['rdir_model_fund'] = info_basic['rdir_inv_BFGS'] + 'model_fund/'\n",
    "dir_invfile_fund = dir_project + info_basic['rdir_BFGS_invfile_fund']\n",
    "dir_disp_model_fund = dir_project + info_basic['rdir_disp_model_fund']\n",
    "dir_model_fund = dir_project + info_basic['rdir_model_fund']\n",
    "if not os.path.exists(dir_invfile_fund):\n",
    "    os.mkdir(dir_invfile_fund)\n",
    "if not os.path.exists(dir_disp_model_fund):\n",
    "    os.mkdir(dir_disp_model_fund)\n",
    "if not os.path.exists(dir_model_fund):\n",
    "    os.mkdir(dir_model_fund)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "stalist_all = stainfo['Station'].tolist() \n",
    "lat_stations_all =  stainfo['latitude'].tolist() \n",
    "lon_stations_all =  stainfo['longitude'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fault surface trace\n",
    "faults = np.load('clark_faults.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_partition = {}\n",
    "lat_stations_partition = {}\n",
    "lon_stations_partition = {}\n",
    "lat_centroid_partition = []\n",
    "lon_centroid_partition = []\n",
    "for key in info_basic['key_subworks']:\n",
    "    filepath = dir_partition + str(key) + '.txt'\n",
    "    stations_this, lat_stations_this, lon_stations_this = np.loadtxt(filepath, dtype='str' , unpack=True)\n",
    "    stations_partition[key] = stations_this\n",
    "    lat_stations_partition[key] = lat_stations_this.astype(float)\n",
    "    lon_stations_partition[key] = lon_stations_this.astype(float)\n",
    "    lat_centroid_partition.append(np.mean(lat_stations_this.astype(float)))\n",
    "    lon_centroid_partition.append(np.mean(lon_stations_this.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_affine_transform(original_points, target_points):\n",
    "    A_matrix = np.array([[original_points[0][0], original_points[0][1], 1, 0, 0, 0],\n",
    "                         [0, 0, 0, original_points[0][0], original_points[0][1], 1],\n",
    "                         [original_points[1][0], original_points[1][1], 1, 0, 0, 0],\n",
    "                         [0, 0, 0, original_points[1][0], original_points[1][1], 1],\n",
    "                         [original_points[2][0], original_points[2][1], 1, 0, 0, 0],\n",
    "                         [0, 0, 0, original_points[2][0], original_points[2][1], 1]])\n",
    "\n",
    "    A1_B1_C1 = np.array([target_points[0][0], target_points[0][1], target_points[1][0], target_points[1][1], target_points[2][0], target_points[2][1]])\n",
    "\n",
    "    coefficients = np.linalg.solve(A_matrix, A1_B1_C1)\n",
    "\n",
    "    affine_matrix = np.array([[coefficients[0], coefficients[1], coefficients[2]],\n",
    "                               [coefficients[3], coefficients[4], coefficients[5]],\n",
    "                               [0, 0, 1]])\n",
    "\n",
    "    return affine_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transformation\n",
    "lon_stations_all_new = []\n",
    "lat_stations_all_new = []\n",
    "for sta in stalist_all:\n",
    "    if int(sta[1:3]) <= 60:\n",
    "        lon_stations_all_new.append(lon_stations_all[stalist_all.index(sta)])\n",
    "        lat_stations_all_new.append(lat_stations_all[stalist_all.index(sta)])\n",
    "refs = ['R0101','R6001','R6020']\n",
    "lon_refs = [lon_stations_all[stalist_all.index(ref)] for ref in refs]\n",
    "lat_refs = [lat_stations_all[stalist_all.index(ref)] for ref in refs]\n",
    "loc_refs = np.column_stack([lon_refs,lat_refs])\n",
    "loc_refs_new = np.array([[0,0],[600,0],[600,600]])\n",
    "\n",
    "affine_matrix = compute_affine_transform(loc_refs, loc_refs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all stations\n",
    "x_stations_all = []\n",
    "y_stations_all = []\n",
    "for i in range(len(lon_stations_all)):\n",
    "    loc_sta = np.array([lon_stations_all[i],lat_stations_all[i],1])\n",
    "    loc_sta_new = np.dot(affine_matrix,loc_sta)\n",
    "    x_stations_all.append(loc_sta_new[0])\n",
    "    y_stations_all.append(loc_sta_new[1])\n",
    "x_centroid_partition = []\n",
    "y_centroid_partition = []\n",
    "for i in range(len(lon_centroid_partition)):\n",
    "    loc_centroid = np.array([lon_centroid_partition[i],lat_centroid_partition[i],1])\n",
    "    loc_centroid_new = np.dot(affine_matrix,loc_centroid)\n",
    "    x_centroid_partition.append(loc_centroid_new[0])\n",
    "    y_centroid_partition.append(loc_centroid_new[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = {}\n",
    "for key in key_subworks:\n",
    "    print(key+ ' '+str(key_subworks.index(key)+1) + '/'+str(len(key_subworks)))\n",
    "    ds = h5py.File(dir_ds+'ds_'+key+'.h5', 'r')\n",
    "    ds_remove = ds['ds_remove'][0]\n",
    "    ds_all[key] = plotlib.smooth_ds(ds_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fj(ax,ds_linear,title0,f,c,index,v_min,v_max,c_map):\n",
    "    ax.imshow(np.flip(ds_linear,0),aspect='auto',extent=[min(f),max(f),min(c),max(c)],vmin=v_min,vmax = v_max, cmap = c_map)\n",
    "    #plt.imshow(np.flip(ds_linear,0),extent=[min(f),max(f),min(c),max(c)],aspect='auto',cmap='jet',vmin=0,vmax=1)\n",
    "    #ax.pcolormesh(f,c,ds_linear,cmap='jet',vmin=0,vmax=1)\n",
    "    if index == 0:\n",
    "        ax.set_title(title0)\n",
    "    else:\n",
    "        ax.set_title('('+chr(96+index)+')',loc='left')\n",
    "    ax.set_xlabel('Normalized Frequency/ Hz')\n",
    "    ax.set_ylabel('Velocity/ m/s')\n",
    "    #ax.set_xlim(xlim)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forard and plot estimated disp and Vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(key_subwork):\n",
    "    global key_subworks_all\n",
    "    global x_centroid_partition\n",
    "    global y_centroid_partition\n",
    "    global lon_centroid_partition\n",
    "    global lat_centroid_partition\n",
    "    global flag_near\n",
    "\n",
    "    y_centroid = y_centroid_partition[key_subworks_all.index(key_subwork)]\n",
    "    x_centroid = x_centroid_partition[key_subworks_all.index(key_subwork)]\n",
    "    dist = np.sqrt((np.array(y_centroid_partition)-y_centroid)**2 + (np.array(x_centroid_partition)-x_centroid)**2)\n",
    "    dist_sort = np.sort(dist)\n",
    "    key_nearest = []\n",
    "    lon_nearest = []\n",
    "    lat_nearest = []\n",
    "    dist_nearst = []\n",
    "    for i in range(len(dist_sort)):\n",
    "        if dist_sort[i] < flag_near and dist[i] != 0:\n",
    "            index = np.where(dist==dist_sort[i])[0][0]\n",
    "            key_this = key_subworks_all[index]\n",
    "            key_nearest.append(key_subworks_all[key_subworks_all.index(key_this)])\n",
    "            lon_nearest.append(lon_centroid_partition[key_subworks_all.index(key_this)])\n",
    "            lat_nearest.append(lat_centroid_partition[key_subworks_all.index(key_this)])\n",
    "            dist_nearst.append(dist_sort[i])\n",
    "\n",
    "\n",
    "    return key_nearest, lon_nearest, lat_nearest,dist_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_near(config,dir_model,key_subwork,key_nearest,dist_nearst,ax):\n",
    "    global flag_near\n",
    "    config_plot = config['plot']\n",
    "    zmax = config_plot['zmax']\n",
    "    vsmin, vsmax = config_plot['vs_lim']\n",
    "    model_init = np.loadtxt(dir_inv + config['model_init']+'.txt')\n",
    "    z = model_init[:, 1]\n",
    "    vs_init = model_init[:, 3]\n",
    "    unit = 'km'\n",
    "    km2m = 1\n",
    "    hw = config['init_half_width']\n",
    "    v1, v2 = vs_init - hw, vs_init + hw\n",
    "    vs1_plot = np.append(v1, v1[-1])\n",
    "    vs2_plot = np.append(v2, v2[-1])\n",
    "    z_plot = np.append(z, zmax) * km2m\n",
    "\n",
    "    ax.step(vs_init,z,c = 'k',label = 'initial',linewidth=0.8)\n",
    "    ax.set_xlim([vsmin, vsmax])\n",
    "    ax.set_ylim([0, zmax * km2m])\n",
    "    ax.set_xlabel('Vs (km/s)')\n",
    "    ax.set_ylabel('Depth ({:s})'.format(unit))\n",
    "    ax.invert_yaxis()\n",
    "    ax.step(vs1_plot,z_plot,'--',c='gray',alpha=0.8)\n",
    "    ax.step(vs2_plot, z_plot, '--', c='gray', alpha=0.8)\n",
    "\n",
    "    data = np.loadtxt(dir_model + 'model_' + key_subwork + '.txt')\n",
    "    z = data[:, 1]\n",
    "    z = np.append(z, [zmax,]) * km2m\n",
    "    vs = data[:, 3]\n",
    "    vs = np.append(vs, [vs[-1],])\n",
    "    p3, = ax.step(vs,z,'-',c='b',alpha=0.6,linewidth=4,label = key_subwork)\n",
    "\n",
    "    #cs = ['b','plum','y','g','cyan','lime']\n",
    "    #cmap = plt.cm.get_cmap('coolwarm')\n",
    "    cmap = matplotlib.colormaps['afmhot']\n",
    "    norm = plt.Normalize(10, flag_near)\n",
    "    colors = [cmap(norm(value)) for value in dist_nearst]\n",
    "    for i in range(len(key_nearest)):\n",
    "        key = key_nearest[i]\n",
    "        data = np.loadtxt(dir_model + 'model_' + key + '.txt')\n",
    "        z = data[:, 1]\n",
    "        z = np.append(z, [zmax,]) * km2m\n",
    "        vs = data[:, 3]\n",
    "        vs = np.append(vs, [vs[-1],])\n",
    "        p3, = ax.step(vs,z,'-',c=colors[i],alpha=0.6,linewidth=2,label = key)\n",
    "    ax.legend(loc='lower left')\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm,ax = ax)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_map = 'jet'\n",
    "v_max = None\n",
    "v_min = 0.1\n",
    "\n",
    "all_disp = 0\n",
    "show_std = 1\n",
    "show_init = 0\n",
    "plot_fund = 1\n",
    "xlim_f = [0.5,30]\n",
    "xlim_T = [-1,1]\n",
    "ylim_c = [0.25,1.8]\n",
    "clim = [0,1]\n",
    "fmin = 1\n",
    "fmax = 30\n",
    "cmin = 0.1\n",
    "cmax = 2.5\n",
    "vmax = 0.3\n",
    "\n",
    "max_mode = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_num = 0\n",
    "inter_forward = 5\n",
    "linestyle = ['*','o','^','+','v','<','>','p','h']\n",
    "show_init = 0\n",
    "for key_subwork in key_subworks:\n",
    "    flag_num += 1\n",
    "    print(key_subwork + ', '+str(key_subworks.index(key_subwork)+1) + '/' + str(len(key_subworks)) ) \n",
    "\n",
    "    # configuration\n",
    "    file_inv =  'ds_'+key_subwork+'curve'\n",
    "    file_disp_data = dir_project + info_basic['rdir_disp_pick']+'ds_'+key_subwork+'curve.txt'\n",
    "    file_model = 'model_'+key_subwork+'.txt'\n",
    "    file_disp_forward = dir_disp_model +  'disp_model_'+key_subwork+'.txt'\n",
    "    if not os.path.exists(dir_invfile+file_inv):\n",
    "        print(key_subwork+'Overtone inversion data file not exist')\n",
    "        plt.close()\n",
    "        continue\n",
    "    file_model_fund = 'model_'+key_subwork+'.txt'\n",
    "    file_disp_forward_fund = dir_disp_model_fund +  'disp_model_'+key_subwork+'.txt'\n",
    "    if not os.path.exists(dir_invfile_fund+file_inv):\n",
    "        print(key_subwork+' Fundamental inversion data file not exist')\n",
    "        plt.close()\n",
    "        continue    \n",
    "    \n",
    "    fig = plt.figure(figsize=(24, 16))\n",
    "    # plot partition\n",
    "    stalist = stations_partition[key_subwork]\n",
    "    lat_stations_this = lat_stations_partition[key_subwork]\n",
    "    lon_stations_this = lon_stations_partition[key_subwork]\n",
    "    ax_partition = fig.add_subplot(231)\n",
    "    ax_partition=plotlib.plot_area(ax_partition,lon_stations_all,lat_stations_all,lon_stations_this,lat_stations_this,markersize = 0.75 ,markersize2 = 3)\n",
    "    ax_partition.scatter(lon_centroid_partition,lat_centroid_partition,marker='^',color='y',s=4)\n",
    "    for i in range(len(faults)):\n",
    "        ax_partition.plot(faults['clark'+str(i+1)]['lon'], faults['clark'+str(i+1)]['lat'], 'k--',lw = 0.5)\n",
    "    ax_partition.set_title('Partition')\n",
    "    key_nearest, lon_nearest, lat_nearest, dist_nearst = find_nearest(key_subwork)\n",
    "    cmap = matplotlib.colormaps['winter']\n",
    "    norm = plt.Normalize(10, flag_near)\n",
    "    colors = [cmap(norm(value)) for value in dist_nearst]\n",
    "    for i in range(len(key_nearest)): \n",
    "        ax_partition.scatter(lon_nearest[i],lat_nearest[i],marker='o',color=colors[i],s=40,label = key_nearest[i])\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm,ax = ax_partition, fraction = 0.01,pad=0.01)\n",
    "    ax_partition.scatter(np.mean(lon_stations_this),np.mean(lat_stations_this),marker='^',color='b',s=100,label = key_subwork)\n",
    "    ax_partition.legend()\n",
    "    stations_nearst = set()\n",
    "    lon_stations_nearest = []\n",
    "    lat_stations_nearest = []\n",
    "    for key_subwork_this in key_nearest:\n",
    "        stations_nearst.update(stations_partition[key_subwork_this])\n",
    "    for sta in stations_nearst:\n",
    "        lon_stations_nearest.append(lon_stations_all[stalist_all.index(sta)])\n",
    "        lat_stations_nearest.append(lat_stations_all[stalist_all.index(sta)])\n",
    "    lon_stations_nearest = list(lon_stations_nearest)\n",
    "    lat_stations_nearest = list(lat_stations_nearest)\n",
    "    ax_partition.scatter(lon_stations_nearest,lat_stations_nearest,marker='o',color='b',s=10)\n",
    "    ax_partition.set_aspect('equal')\n",
    "\n",
    "\n",
    "    title0 = \"FJ with forward disp curve\"\n",
    "    ax_FJ = fig.add_subplot(2,3,2)\n",
    "    ax_FJ.set_xlim(xlim_f)\n",
    "    ax_FJ.set_ylim(ylim_c)\n",
    "    ds_remove = ds_all[key_subwork]\n",
    "    ax_FJ = plotlib.plot_fj(ax_FJ,ds_remove,title0,f0,c,0,v_min = v_min,v_max=v_max,c_map=c_map)\n",
    "    disp_data = np.loadtxt(file_disp_data)\n",
    "    num_m_data = len(set(disp_data[:,2]))\n",
    "    modes_data = set(disp_data[:,2].astype(int))\n",
    "        # data\n",
    "    for mode in modes_data:\n",
    "        data_mode = disp_data[disp_data[:, 2] == mode]\n",
    "        if mode==0:\n",
    "            ax_FJ.plot(data_mode[:, 0], data_mode[:, 1], 'k^',label='data',linewidth=4)\n",
    "        else:\n",
    "            ax_FJ.plot(data_mode[:, 0], data_mode[:, 1],  'k^',linewidth=4 )\n",
    "        # foward\n",
    "    file_disp_forward = dir_disp_model +  'disp_model_'+key_subwork+'.txt'\n",
    "    disp_forward = np.loadtxt(file_disp_forward)\n",
    "    num_m = len(set(disp_forward[:,2]))\n",
    "    modes = set(disp_forward[:,2].astype(int))\n",
    "    for mode in modes:\n",
    "        disp_forward_mode = disp_forward[disp_forward[:, 2] == mode]\n",
    "        if mode==0:\n",
    "            ax_FJ.scatter(disp_forward_mode[::inter_forward, 0], disp_forward_mode[::inter_forward, 1], color='greenyellow',marker = linestyle[mode],label='Overtone estemate',s=10)\n",
    "        else:\n",
    "            ax_FJ.scatter(disp_forward_mode[::inter_forward, 0], disp_forward_mode[::inter_forward, 1], color='greenyellow',marker = linestyle[mode],s=10)\n",
    "    file_disp_forward_fund = dir_disp_model_fund +  'disp_model_'+key_subwork+'.txt'\n",
    "    disp_forward_fund = np.loadtxt(file_disp_forward_fund)\n",
    "    num_m = len(set(disp_forward_fund[:,2]))\n",
    "    modes = set(disp_forward_fund[:,2].astype(int))\n",
    "    for mode in modes:\n",
    "        disp_forward_fund_mode = disp_forward_fund[disp_forward_fund[:, 2] == mode]\n",
    "        if mode==0:\n",
    "            ax_FJ.scatter(disp_forward_fund_mode[::inter_forward, 0], disp_forward_fund_mode[::inter_forward, 1], color='red',marker = linestyle[mode],label='Fundamental estemate',s=10)\n",
    "        else:\n",
    "            ax_FJ.scatter(disp_forward_fund_mode[::inter_forward, 0], disp_forward_fund_mode[::inter_forward, 1], color='red',marker= linestyle[mode],s=10)\n",
    "\n",
    "\n",
    "    # plot fund and over\n",
    "    ax_vs = fig.add_subplot(234)\n",
    "    ax_vs,model_fund,fmt = plot_inversion.plot_model(config, file_inv, show_init, file_model,file_init,ax_vs,file_model_fund =dir_model_fund + file_model_fund,plot_fund=1,dir_this = dir_inv)\n",
    "    std_fund = model_fund[:,5]\n",
    "    z_step = model_fund[:,1]\n",
    "    \n",
    "    # plot fund velocity\n",
    "    ax_fund = fig.add_subplot(235)\n",
    "    ax_fund = plot_model_near(config_fund,dir_model_fund,key_subwork,key_nearest,dist_nearst,ax_fund)\n",
    "    ax_over = fig.add_subplot(236)\n",
    "    ax_over = plot_model_near(config,dir_model,key_subwork,key_nearest,dist_nearst,ax_over)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dir_image+key_subwork+'_compare.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
