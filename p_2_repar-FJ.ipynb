{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "from ccfj import GetStationPairs\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import mathlib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import stacklib\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_repartition_v3.0/output_repar_v9.1_test/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('a-project_repar.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project_repartrition/output_repar_01-03/'               # Harmon server\n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_CC_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project:  /shdisk/rem2/Harmon/F-J/San/project_repartition_v3.0/output_repar_v9.1_test/\n"
     ]
    }
   ],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_stack = dir_project + info_basic['dir_stack']\n",
    "dir_ds = dir_project + info_basic['dir_ds']\n",
    "dir_partition = dir_project + info_basic['dir_partition']\n",
    "dir_image = dir_project + info_basic['dir_image'] + 'regular_FJ/'\n",
    "if os.path.exists(dir_image) == False:\n",
    "    os.makedirs(dir_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1--08-03',\n",
       " '2--09-03',\n",
       " '3--10-03',\n",
       " '4--11-03',\n",
       " '5--12-03',\n",
       " '6--13-03',\n",
       " '7--14-03',\n",
       " '8--15-03',\n",
       " '9--16-03',\n",
       " '10--18-03',\n",
       " '11--19-03',\n",
       " '12--20-03',\n",
       " '13--21-03',\n",
       " '14--22-03',\n",
       " '15--23-03',\n",
       " '16--24-03',\n",
       " '17--25-03',\n",
       " '18--26-03']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_subworks = info_basic['key_subworks']\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key_subworks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist()\n",
    "lat_all = stainfo['latitude'].tolist() \n",
    "lon_all = stainfo['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = {}\n",
    "lat = {}\n",
    "lon = {}\n",
    "for key in key_subworks:\n",
    "    filepath = dir_partition + str(key) + '.txt'\n",
    "    stations_this, lat_stations_this, lon_stations_this = np.loadtxt(filepath, dtype='str' , unpack=True)\n",
    "    stations[key] = stations_this\n",
    "    lat[key] = lat_stations_this.astype(float)\n",
    "    lon[key] = lon_stations_this.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = np.load('clark_faults.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1--08-03\n",
      "2--09-03\n",
      "3--10-03\n",
      "4--11-03\n",
      "5--12-03\n",
      "6--13-03\n",
      "7--14-03\n",
      "8--15-03\n",
      "9--16-03\n",
      "10--18-03\n",
      "11--19-03\n",
      "12--20-03\n",
      "13--21-03\n",
      "14--22-03\n",
      "15--23-03\n",
      "16--24-03\n",
      "17--25-03\n",
      "18--26-03\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "d_len = 31\n",
    "c_map = 'jet'\n",
    "v_min = 0.1\n",
    "v_max = None\n",
    "info_basic['v_min'] = v_min\n",
    "info_basic['v_max'] = v_max\n",
    "info_basic['c_map'] = c_map\n",
    "#t0 = info_basic['t0']\n",
    "#v_tag = info_basic['v_tag']\n",
    "for key_subwork in key_subworks:\n",
    "    print(key_subwork)\n",
    "    fig,ax = plt.subplots(3,3,figsize= (22,18))\n",
    "    # settings for subwork\n",
    "    \n",
    "    \n",
    "    #start = info_basic_bi['start'][key_subwork]\n",
    "    #interval = info_basic_bi['interval'][key_subwork]\n",
    "    #flag_time = info_basic_bi['flag_time'][key_subwork]\n",
    "    start = info_basic['start']\n",
    "    interval = info_basic['interval']\n",
    "    flag_time = info_basic['flag_time']\n",
    "\n",
    "    xlim_f = [1,15]\n",
    "    xlim_T = [-1,1]\n",
    "\n",
    "    # plot area\n",
    "    \n",
    "    stalist = stations[key_subwork]\n",
    "    lat_this = lat[key_subwork]\n",
    "    lon_this = lon[key_subwork]\n",
    "    nsta = len(stalist)\n",
    "    StationPairs = GetStationPairs(nsta)\n",
    "    nPairs = int(len(StationPairs)/2)\n",
    "\n",
    "    ax[0][0]=plotlib.plot_area(ax[0][0],lon_all,lat_all,lon_this,lat_this)\n",
    "    for i in range(len(faults)):\n",
    "        ax[0][0].plot(faults['clark'+str(i+1)]['lon'], faults['clark'+str(i+1)]['lat'], 'k')\n",
    "    \n",
    "\n",
    "    # plot ncfs and ncfst\n",
    "    # linear stack\n",
    "    \n",
    "    outname = str(key_subwork)+'_gather_linear.h5'\n",
    "    ncffile = h5py.File(dir_stack + outname,'r')\n",
    "    ncfs_sum_linear = ncffile['ncfs'][:]\n",
    "    r = ncffile['r'][:]\n",
    "    ncffile.close()\n",
    "    # timewindow-filtered stack\n",
    "    outname = str(key_subwork)+'_gather_timewindow.h5'\n",
    "    ncffile = h5py.File(dir_stack + outname,'r')\n",
    "    ncfs_sum_remove = ncffile['ncfs'][:]\n",
    "    ncffile.close()\n",
    "\n",
    "    f = info_basic_bi['f']\n",
    "    t = info_basic_bi['t']\n",
    "    ncfst_linear = mathlib.freq_time(ncfs_sum_linear)\n",
    "    ncfst_remove = mathlib.freq_time(ncfs_sum_remove)\n",
    "    \n",
    "    title1 = \"Linear Stack subarea frequency for \"+str(key_subwork)\n",
    "    #xlim_f = [0,15]\n",
    "    ax[0][1] = plotlib.plot_ncfs(ax[0][1],f,ncfs_sum_linear,r,title1,xlim_f,0)\n",
    "    ax[0][2] = plotlib.plot_ncfs(ax[0][2],f,ncfs_sum_remove,r,title1,xlim_f,0)\n",
    "    \n",
    "    # plot fj\n",
    "    ds = h5py.File(dir_ds+'ds_'+str(key_subwork)+'.h5', 'r')\n",
    "    ds_linear = ds['ds_linear'][0]\n",
    "    ds_remove = ds['ds_remove'][0]\n",
    "    ds_linear = plotlib.smooth_ds(ds_linear)\n",
    "    ds_remove = plotlib.smooth_ds(ds_remove)\n",
    "    ds.close()\n",
    "    \n",
    "    c = np.linspace(info_basic['c_min'],info_basic['c_max'],info_basic['c_num'])\n",
    "    #c = np.linspace(100,2000,1000)\n",
    "    \n",
    "    title0 = \"Linear Stack subarea time for \"+str(key_subwork)\n",
    "    ax[1][0] = plotlib.plot_ncfst(ax[1][0],t,ncfst_linear[start::interval],r[start::interval],title0,flag_time,xlim_T,0)\n",
    "    title0 = \"Remove Stack subarea time for \"+str(key_subwork)\n",
    "    ax[1][1] = plotlib.plot_ncfst(ax[1][1],t,ncfst_remove[start::interval],r[start::interval],title0,flag_time,xlim_T,0)\n",
    "    for i in range(len(r)):\n",
    "        ax[1][1].plot()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    title0 = \"Linear stack dispersion curve \"+str(d_len)+' days'\n",
    "    ax[2][0] = plotlib.plot_fj(ax[2][0],ds_linear,title0,f,c,0,v_min=v_min,v_max=v_max,c_map=c_map)\n",
    "    ax[2][0].set_xlim(xlim_f)\n",
    "\n",
    "    title0 = \"Remove stack dispersion curve \"+str(d_len)+' days'\n",
    "    ax[2][1] = plotlib.plot_fj(ax[2][1],ds_remove,title0,f,c,0,v_min=v_min,v_max=v_max,c_map=c_map)\n",
    "    ax[2][1].set_xlim(xlim_f)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dir_image+str(key_subwork)+'_compare_remove.png',dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_project+'Basic_info.yml', 'w', encoding='utf-8') as f:\n",
    "   yaml.dump(data=info_basic, stream=f, allow_unicode=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
