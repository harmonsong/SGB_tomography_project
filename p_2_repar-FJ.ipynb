{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import geopandas as gp\n",
    "import time\n",
    "import pandas as pd\n",
    "from geopy.distance import great_circle\n",
    "import folium\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../tools_F-J/')\n",
    "from toollib_standard import maplib\n",
    "from toollib_standard import mathlib\n",
    "from toollib_standard import filelib\n",
    "from toollib_standard import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_repartition_v4.0/output_repar_v9.5_02--10-16Hz/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('a-project_repar.yml', 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project_repartrition/output_repar_01-03/'               # Harmon server\n",
    "name_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_CC_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project_workspace:  /shdisk/rem2/Harmon/F-J/San/\n",
      "dir_project:  /shdisk/rem2/Harmon/F-J/San/project_repartition_v4.0/output_repar_v9.5_02--10-16Hz/\n"
     ]
    }
   ],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_CC = dir_CC_workspace + info_basic['rdir_CC']\n",
    "dir_ds = dir_project + info_basic['rdir_ds']\n",
    "dir_partition = dir_project + info_basic['rdir_partition']\n",
    "dir_image = dir_project + info_basic['rdir_image'] + 'regular_FJ/'\n",
    "if os.path.exists(dir_image) == False:\n",
    "    os.makedirs(dir_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['264--12-10', '536--49-16', '63--47-04', '493--38-15']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_subworks = info_basic['key_subworks'][0:4]\n",
    "key_subworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = mathlib.GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist()\n",
    "lat_stations_all = stainfo['latitude'].tolist() \n",
    "lon_stations_all = stainfo['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalistname_all = info_basic['stalistname_all']\n",
    "stainfo = pd.read_excel(stalistname_all)\n",
    "nsta_all = len(stainfo.iloc[:,0])\n",
    "StationPairs_all = mathlib.GetStationPairs(nsta_all)\n",
    "nPairs_all = int(len(StationPairs_all)/2)\n",
    "stalist_all = stainfo['Station'].tolist()\n",
    "lat_stations_all = stainfo['latitude'].tolist() \n",
    "lon_stations_all = stainfo['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = {}\n",
    "lat = {}\n",
    "lon = {}\n",
    "for key in key_subworks:\n",
    "    filepath = dir_partition + str(key) + '.txt'\n",
    "    stations_this, lat_stations_this, lon_stations_this = np.loadtxt(filepath, dtype='str' , unpack=True)\n",
    "    stations[key] = stations_this\n",
    "    lat[key] = lat_stations_this.astype(float)\n",
    "    lon[key] = lon_stations_this.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = np.load('clark_faults.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncffile = h5py.File(dir_CC + 'gather_all.h5','r')\n",
    "ncfs = ncffile['ncfs'][:]\n",
    "f = ncffile['f'][:]\n",
    "count_all = ncffile['count'][:]\n",
    "ncffile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pairs(sta):\n",
    "    p = []\n",
    "    nsta = len(sta)\n",
    "    for ii in range(nsta):\n",
    "        for jj in range(ii+1,nsta):\n",
    "            p.append([sta[ii],sta[jj]])\n",
    "    return p\n",
    "def cal_indx(pair,nsta):\n",
    "    indx = int(pair[0]*(2*nsta-pair[0]-1)/2+pair[1]-pair[0]-1)\n",
    "    return indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_window_filter(t,ncfst0,r,v_min,t0,a):\n",
    "    ncfst = ncfst0.copy()\n",
    "    for i in range(len(ncfst)):\n",
    "        tag = r[i]/v_min\n",
    "        #print(t0,tag)\n",
    "        t1 = t[t>-tag-t0][t[t>-tag-t0]< tag+t0]\n",
    "        start = np.where(t == t1[0])[0][0]\n",
    "        end = np.where(t == t1[-1])[0][0]\n",
    "        ncfst[i][start:end+1]= ncfst[i][start:end+1]* np.exp(-a*np.abs((tag-np.abs(t1))))\n",
    "    return ncfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stack(key_subwork,ncfs_sum_linear,r,StationPairs):\n",
    "    global dir_project\n",
    "    global key_subworks\n",
    "    global info_basic\n",
    "    global flag_save\n",
    "    global v_tag\n",
    "    global t0\n",
    "    global a\n",
    "\n",
    "    start0 = time.time()\n",
    "    f0 = info_basic_bi['f']\n",
    "    dt = 1/np.max(f0)\n",
    "    t = (np.linspace(-len(f0)-1,len(f0)-1,2*(len(f0)-1))+0.5)*dt/2\n",
    "    ncfst_linear = mathlib.freq_time(ncfs_sum_linear)\n",
    "    ncfst1 = time_window_filter(t,ncfst_linear,r,v_tag,t0,a)\n",
    "    ncfs_sum_remove = mathlib.time_freq(ncfst1)\n",
    "    if flag_save:\n",
    "        tag = name_project[ name_project.rfind('_')+1: -1]\n",
    "        dir_stack = dir_project + 'stack_'+tag+'/'\n",
    "        outname = key_subwork+'_gather_timewindow.h5'\n",
    "        if os.path.exists(dir_stack+outname):\n",
    "            os.remove(dir_stack+outname)\n",
    "        ncffile = h5py.File(dir_stack+outname,'w')\n",
    "        ncffile.create_dataset('ncfs', data=ncfs_sum_remove) \n",
    "        ncffile.create_dataset('r',data=r)\n",
    "        ncffile.create_dataset('StationPairs',data=StationPairs)\n",
    "        ncffile.close()\n",
    "    print('Finish remove stack, time:', time.time()-start0, ' seconds')\n",
    "    return ncfs_sum_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tag = info_basic['remove_v_tag']\n",
    "t0 = info_basic['remove_t0']\n",
    "a = info_basic['remove_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_save = 0\n",
    "\n",
    "start = 0 \n",
    "interval = 10\n",
    "flag_time = 0.02\n",
    "tao = 0\n",
    "\n",
    "c_map = 'jet'\n",
    "v_min = 0.1\n",
    "v_max = None\n",
    "d_len = 31\n",
    "\n",
    "xlim_f = [2,30]\n",
    "xlim_T = [-1,1]\n",
    "\n",
    "info_basic['v_min'] = v_min\n",
    "info_basic['v_max'] = v_max\n",
    "info_basic['c_map'] = c_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264--12-10; 1/4 subworks.\n",
      "536--49-16; 2/4 subworks.\n",
      "63--47-04; 3/4 subworks.\n",
      "493--38-15; 4/4 subworks.\n"
     ]
    }
   ],
   "source": [
    "ds_linear_all = {}\n",
    "ds_remove_all = {}\n",
    "index_ncfs = {}\n",
    "rs = {}\n",
    "for key_subwork in key_subworks:\n",
    "    print(key_subwork+ '; '+str(key_subworks.index(key_subwork)+1)+'/'+str(len(key_subworks))+' subworks.')\n",
    "    ds = h5py.File(dir_ds+'ds_'+str(key_subwork)+'.h5', 'r')\n",
    "    ds_linear = plotlib.smooth_ds(ds['ds_linear'][0])\n",
    "    ds_remove = plotlib.smooth_ds(ds['ds_remove'][0])\n",
    "    ds_linear_all[key_subwork] = ds_linear\n",
    "    ds_remove_all[key_subwork] = ds_remove\n",
    "    index_ncfs[key_subwork] = list(ds['index_ncfs'])\n",
    "    rs[key_subwork] = np.array(ds['r'])\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264--12-10; 1/4 subworks.\n",
      "Finish remove stack, time: 0.38622403144836426  seconds\n",
      "536--49-16; 2/4 subworks.\n",
      "Finish remove stack, time: 1.3679754734039307  seconds\n",
      "63--47-04; 3/4 subworks.\n",
      "Finish remove stack, time: 0.45684003829956055  seconds\n",
      "493--38-15; 4/4 subworks.\n",
      "Finish remove stack, time: 1.1092829704284668  seconds\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "for key_subwork in key_subworks:\n",
    "    print(key_subwork+ '; '+str(key_subworks.index(key_subwork)+1)+'/'+str(len(key_subworks))+' subworks.')\n",
    "    #ncfs_sum_linear, r, StationPairs = linear_stack(key_subwork)\n",
    "    \n",
    "    index = index_ncfs[key_subwork]\n",
    "    ncfs_sum_linear = np.array(ncfs)[index,:]\n",
    "    r = rs[key_subwork]\n",
    "\n",
    "    stalist = stations[key_subwork]\n",
    "    lat_this = lat[key_subwork]\n",
    "    lon_this = lon[key_subwork]\n",
    "    nsta = len(stalist)\n",
    "    StationPairs = mathlib.GetStationPairs(nsta)\n",
    "    nPairs = int(len(StationPairs)/2)\n",
    "\n",
    "    ncfs_sum_remove = remove_stack(key_subwork,ncfs_sum_linear,r,StationPairs)\n",
    "\n",
    "    fig,ax = plt.subplots(3,3,figsize= (22,18))\n",
    "    # plot area\n",
    "    ax[0][0]=plotlib.plot_area(ax[0][0],lon_stations_all,lat_stations_all,lon_this,lat_this)\n",
    "    for i in range(len(faults)):\n",
    "        ax[0][0].plot(faults['clark'+str(i+1)]['lon'], faults['clark'+str(i+1)]['lat'], 'k')\n",
    "\n",
    "    f0 = info_basic_bi['f']\n",
    "    t = info_basic_bi['t']\n",
    "    ncfst_linear = mathlib.freq_time(ncfs_sum_linear)\n",
    "    ncfst_remove = mathlib.freq_time(ncfs_sum_remove)\n",
    "    \n",
    "    title1 = \"Linear Stack subarea frequency for \"+str(key_subwork)\n",
    "    #xlim_f = [0,15]\n",
    "    ax[0][1] = plotlib.plot_ncfs(ax[0][1],f0,ncfs_sum_linear,r,title1,xlim_f,0)\n",
    "    ax[0][2] = plotlib.plot_ncfs(ax[0][2],f0,ncfs_sum_remove,r,title1,xlim_f,0)\n",
    "    \n",
    "    # plot fj\n",
    "    c = np.linspace(info_basic['fj_c_min'],info_basic['fj_c_max'],info_basic['fj_c_num'])\n",
    "    \n",
    "    title0 = \"Linear Stack subarea time for \"+str(key_subwork)\n",
    "    ax[1][0] = plotlib.plot_ncfst(ax[1][0],t,ncfst_linear[start::interval],r[start::interval],title0,flag_time,xlim_T,0)\n",
    "    title0 = \"Remove Stack subarea time for \"+str(key_subwork)\n",
    "    ax[1][1] = plotlib.plot_ncfst(ax[1][1],t,ncfst_remove[start::interval],r[start::interval],title0,flag_time,xlim_T,0)\n",
    "    for i in range(len(r)):\n",
    "        ax[1][1].plot()\n",
    "    \n",
    "    title0 = \"Linear stack dispersion curve \"+str(d_len)+' days'\n",
    "    ax[2][0] = plotlib.plot_fj(ax[2][0],ds_linear,title0,f0,c,0,v_min=v_min,v_max=v_max,c_map=c_map)\n",
    "    ax[2][0].set_xlim(xlim_f)\n",
    "\n",
    "    title0 = \"Remove stack dispersion curve \"+str(d_len)+' days'\n",
    "    ax[2][1] = plotlib.plot_fj(ax[2][1],ds_remove,title0,f0,c,0,v_min=v_min,v_max=v_max,c_map=c_map)\n",
    "    ax[2][1].set_xlim(xlim_f)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dir_image+str(key_subwork)+'_compare_remove.png',dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_project+'Basic_info.yml', 'w', encoding='utf-8') as f:\n",
    "   yaml.dump(data=info_basic, stream=f, allow_unicode=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
