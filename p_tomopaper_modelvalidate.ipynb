{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, getopt, os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import math,h5py, pandas\n",
    "from scipy import integrate\n",
    "from scipy.fftpack import fft, hilbert\n",
    "from scipy.signal import butter, lfilter\n",
    "from geopy.distance import great_circle\n",
    "import matplotlib.ticker as ticker\n",
    "import yaml\n",
    "import netCDF4 as nc\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_project = 1\n",
    "\n",
    "if flag_project == 0:\n",
    "    file_project = 'a-project.yml'\n",
    "elif flag_project == 1:\n",
    "    file_project = 'a-project_repar.yml'\n",
    "elif flag_project == 2:\n",
    "    file_project = 'a-project_voro.yml'\n",
    "    \n",
    "with open(file_project, 'r', encoding='utf-8') as f:\n",
    "    proj = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "name_project = proj['name']\n",
    "#name_project = 'project_repartition_v4.0/output_repar_v9.5_01--10-16Hz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_CC_workspace:  ./\n",
      "dir_project_workspace:  ./\n",
      "dir_project:  ./project_repartition_v4.0/output_repar_v9.5_02--10-16Hz/\n"
     ]
    }
   ],
   "source": [
    "with open('0_config.yml', 'r', encoding='utf-8') as f:\n",
    "    dir_config = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "dir_project_workspace = dir_config['dir_project_workspace']\n",
    "dir_CC_workspace = dir_config['dir_CC_workspace']\n",
    "print('dir_CC_workspace: ', dir_CC_workspace)\n",
    "print('dir_project_workspace: ', dir_project_workspace)\n",
    "dir_project = os.path.join(dir_project_workspace, name_project)\n",
    "print('dir_project: ', dir_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project+'Basic_info.yml'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    info_basic = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "filename_bi = dir_project+'Basic_info.npy'\n",
    "info_basic_bi = np.load(filename_bi, allow_pickle='TRUE').item()      # setting dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_image = dir_project + info_basic['rdir_image']+'paper_tomo/'\n",
    "dir_partition = dir_project + info_basic['rdir_partition']\n",
    "dir_disp = dir_project + info_basic['rdir_disp_model']\n",
    "if not os.path.exists(dir_image):\n",
    "    os.makedirs(dir_image)\n",
    "#dir_CC = os.getcwd()+'/'+dir_CC_workspace[1:] + info_basic['rdir_CC']\n",
    "dir_CC = dir_CC_workspace + 'CC/CC_150_prewhiten/'\n",
    "#dir_CC = dir_CC_workspace + 'CC/CC_40_prewhiten/'\n",
    "key_subworks = info_basic['key_subworks']\n",
    "M = len(key_subworks)\n",
    "dir_file = os.getcwd()+'/ModelValidCode/ModelValidCode/parameter_prepare/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs parameters\n",
    "isline = False\n",
    "LenFD = 3\n",
    "putinrou = [dir_CC + 'CFs_modelvalidate/'+ 'gather_all_modelvalidate.h5']\n",
    "syn_stalist = dir_file + 'stations_in.txt'\n",
    "sele_stalist = dir_file + 'stations_in.txt'\n",
    "srclist = dir_file + 'stations_virsrc.txt'\n",
    "#=============================read observed Ccfs====================================\n",
    "CC_file = []\n",
    "CC_prof = []\n",
    "for i in range(len(putinrou)):\n",
    "  CC_prof.append(pandas.read_hdf(putinrou[i], 'cc_prof'))\n",
    "  with h5py.File(putinrou[i], mode = \"r\") as file_rou:\n",
    "      CC_file.append(np.array(file_rou[list(file_rou.keys())[0]]))\n",
    "CC_array = CC_file[0]\n",
    "CC_table = CC_prof[0]\n",
    "f_prof = pandas.read_hdf(putinrou[0], 'freq')\n",
    "freq = np.array(f_prof[:])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_CC = dir_CC_workspace + 'CC/CC_150_prewhiten/'\n",
    "#dir_CC = dir_CC_workspace + 'CC/CC_40_prewhiten/'\n",
    "key_subworks = info_basic['key_subworks']\n",
    "M = len(key_subworks)\n",
    "dir_file = os.getcwd()+'/ModelValidCode/ModelValidCode/parameter_prepare/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ricker(t,fc,t0):\n",
    " if (t<=0.0):\n",
    "    v=0.0\n",
    " f0 = np.sqrt(math.pi)/2.0\n",
    " u = (t-t0)*2.0*math.pi*fc\n",
    " v=(u**2.0/4.0-0.5)*np.exp(-u**2.0/4.0)*f0\n",
    " return v\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='bandpass')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSNR(cfsf,r,f,SNRmin):\n",
    "    NoiseWinLength = 5 # in seconds\n",
    "    SigWinC = np.array([0.35,0.55]) #signal window for velocity, in km/s\n",
    "    SigWinT = np.zeros((len(r),2))\n",
    "    SNR = np.zeros(np.shape(r))\n",
    "    for i in range(len(r)):\n",
    "        SigWinT[i,:] = r[i]/SigWinC\n",
    "\n",
    "    dt = 1/np.max(f)\n",
    "    t = (np.linspace(-len(f)/2,len(f)/2-1,len(f))-0.5)*dt\n",
    "    cfst = np.zeros(np.shape(cfsf))\n",
    "    for i in range(len(cfsf)):\n",
    "        cfst[i,:] = np.real(np.fft.fftshift(np.fft.ifft(cfsf[i,:])))\n",
    "        cfst[i,:] = cfst[i,:] /np.max(cfst[i,:])\n",
    "\n",
    "    id0 = int(len(t)/2)\n",
    "    cfst12 = cfst[:,id0::]\n",
    "    cfst21 = cfst[:,id0::-1]\n",
    "    for j in range(len(r)):\n",
    "        c12h= hilbert(cfst12[j,:])\n",
    "        c21h= hilbert(cfst21[j,:])\n",
    "        groupCF12 = np.sqrt(cfst12[j,:]**2 + c12h**2)\n",
    "        groupCF21 = np.sqrt(cfst21[j,:]**2 + c21h**2)\n",
    "        nnSigWinL = int(np.ceil(SigWinT[j,1]/dt))\n",
    "        nnSigWinR = int(np.floor(SigWinT[j,0]/dt))\n",
    "        if nnSigWinL >= nnSigWinR:\n",
    "            continue\n",
    "        nnNoiseWinL = nnSigWinR\n",
    "        nnNoiseWinR = nnSigWinR+int(round(NoiseWinLength/dt))\n",
    "\n",
    "        #print(\"nnSigWinL: \",nnSigWinL)\n",
    "        #print(\"nnSigWinR: \",nnSigWinR)\n",
    "        SigAmp12 = np.max(groupCF12[nnSigWinL:nnSigWinR])\n",
    "        SigAmpAve12 = np.mean(groupCF12[nnSigWinL:nnSigWinR])\n",
    "        NoiseAmpAve12 = np.mean(groupCF12[nnNoiseWinL:nnNoiseWinR])\n",
    "        if NoiseAmpAve12 == 0:\n",
    "            if SigAmp12 > 0:\n",
    "                SNR12 = 100\n",
    "            else:\n",
    "                SNR12 = 0\n",
    "        else:\n",
    "            SNR12 = SigAmp12/NoiseAmpAve12\n",
    "\n",
    "        SigAmp21 = np.max(groupCF21[nnSigWinL:nnSigWinR])\n",
    "        SigAmpAve21 = np.mean(groupCF21[nnSigWinL:nnSigWinR])\n",
    "        NoiseAmpAve21 = np.mean(groupCF21[nnNoiseWinL:nnNoiseWinR])\n",
    "        if NoiseAmpAve21 == 0:\n",
    "            if SigAmp21 > 0:\n",
    "                SNR21 = 100\n",
    "            else:\n",
    "                SNR21 = 0\n",
    "        else:\n",
    "            SNR21 = SigAmp21/NoiseAmpAve21\n",
    "\n",
    "        SNR[j] = np.nan_to_num(min(SNR12,SNR21))\n",
    "        \n",
    "    idx = []\n",
    "    for k in range(len(r)):\n",
    "        if SNR[k] < np.mean(SNR)*SNRmin:\n",
    "            idx.append(k)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sync(isrc,dir_src,flag_maxd,flag_SNRmin,f_rick_c,t_rick_shift,bands,CC_array,CC_table,freq,srclist,sele_stalist,syn_stalist):\n",
    "  global dir_input\n",
    "  inputpath = dir_input\n",
    "  outputpath = dir_src + 'output/'\n",
    "  fileFDconf = dir_src + 'SeisFD3D.conf'\n",
    "  virsta = []\n",
    "  sta_profile = pandas.read_table(srclist, header=None, sep='\\\\s+')\n",
    "  net = list(sta_profile[0][:])\n",
    "  sta = list(sta_profile[1][:])\n",
    "  for i in range(len(sta)):\n",
    "      virsta.append(str(sta[i]))\n",
    "  srcsta = virsta[isrc-1]\n",
    "  print('srouce: ', str(isrc) ,'  srcsta:\\t', srcsta)\n",
    "  #==============selec Ccfs based on srcstat=====================================\n",
    "  sele_netsta = []\n",
    "  with open(sele_stalist, 'r') as f:\n",
    "      while True:\n",
    "          tmp = f.readline()\n",
    "          if tmp:\n",
    "              sele_netsta.append(tmp.split()[0] + '-' + tmp.split()[1])\n",
    "          else:\n",
    "              break\n",
    "\n",
    "  part_CC = []\n",
    "  part_dis = []\n",
    "  CC_sta_name = []\n",
    "  cc_name = CC_table['0cc_name']\n",
    "  indexes = []\n",
    "  for i in range(len(cc_name)):\n",
    "      cc_pairs_sta2 = cc_name[i].split('_')\n",
    "      netsta1 = cc_pairs_sta2[0]\n",
    "      netsta2 = cc_pairs_sta2[1]\n",
    "      #print(cc_pairs_sta2)\n",
    "      if srcsta in cc_pairs_sta2:\n",
    "      #if (netsta1 in sele_netsta) and (netsta2 in sele_netsta) and (srcsta in cc_pairs_sta2):\n",
    "        indexes.append(i)\n",
    "        part_CC.append((CC_array[i,:]).copy())\n",
    "        part_dis.append(CC_table.iloc[i,3]) #km\n",
    "        if srcsta == netsta1:\n",
    "            CC_sta_name.append(netsta2)\n",
    "        else:\n",
    "            CC_sta_name.append(netsta1)\n",
    "\n",
    "  #print(\"CC_sta_name: \", CC_sta_name)\n",
    "  part_CC = np.array(part_CC)\n",
    "  part_dis = np.array(part_dis)\n",
    "  dele_cc_rows = []\n",
    "  for CC_num in range(part_CC.shape[0]):\n",
    "    #if part_CC[CC_num,:].all() == 0:\n",
    "        #print(CC_num)\n",
    "        #dele_cc_rows.append(CC_num)\n",
    "    if part_dis[CC_num] == 0 or part_dis[CC_num]>= flag_maxd:\n",
    "        dele_cc_rows.append(CC_num)\n",
    "  dele_cc_rows = list(set(dele_cc_rows))\n",
    "  dele_cc_rows.sort()\n",
    "  raw_rou_nonezerocc = np.delete(part_CC, dele_cc_rows, axis = 0)\n",
    "  dis_vin_nonezerocc = np.delete(part_dis, dele_cc_rows, axis = 0)\n",
    "  for counter, index in enumerate(dele_cc_rows):\n",
    "      index = index-counter\n",
    "      CC_sta_name.pop(index)\n",
    "\n",
    "  #print(\"raw_rou_nonezerocc: \", raw_rou_nonezerocc.shape)\n",
    "  #print(\"dis_vin_nonezerocc: \", dis_vin_nonezerocc.shape)\n",
    "  #print(\"time: \", time)\n",
    "\n",
    "  idel = getSNR(raw_rou_nonezerocc,dis_vin_nonezerocc,freq,SNRmin=flag_SNRmin)\n",
    "  idel = list(set(idel))\n",
    "  idel.sort()\n",
    "  raw_rou_nonezerocc = np.delete(raw_rou_nonezerocc,idel,axis=0)\n",
    "  dis_vin_nonezerocc = np.delete(dis_vin_nonezerocc,idel,axis=0)\n",
    "  for counter, index in enumerate(idel):\n",
    "      index = index-counter\n",
    "      CC_sta_name.pop(index)\n",
    "\n",
    "  #============obtain time-domain Green's function=================================================\n",
    "  ncfs0 = raw_rou_nonezerocc\n",
    "  robs = dis_vin_nonezerocc #km\n",
    "  dtobs = 1/np.max(freq)\n",
    "  tobs = (np.linspace(-len(freq)/2, len(freq)/2-1, len(freq))-0.5)*dtobs\n",
    "  ncfst = np.zeros(np.shape(ncfs0))\n",
    "  for i in range(len(ncfs0)):\n",
    "    ncfst[i,:] = np.real(np.fft.fftshift(np.fft.ifft(ncfs0[i,:])))\n",
    "\n",
    "  cfs = (ncfst[:,int(len(freq)/2):1:-1] + ncfst[:,int(len(freq)/2+1)::]) / 2 \n",
    "  cfs_grad = -np.gradient(cfs,axis=1,edge_order=1)/dtobs\n",
    "\n",
    "  #===========convolve with the ricker wavelet=============================================================\n",
    "  tt = tobs[int(len(freq)/2+1)::]\n",
    "  wavelet = np.zeros(len(tt))\n",
    "  waveobs = np.zeros((cfs_grad.shape[0],len(tt)))\n",
    "  for i in range(len(tt)):\n",
    "    wavelet[i] = ricker(tt[i],f_rick_c,t_rick_shift)\n",
    "  indx_obs = int(t_rick_shift/dtobs)\n",
    "  for j in range(cfs_grad.shape[0]):\n",
    "    tmp = np.convolve(wavelet,cfs_grad[j,:])\n",
    "    waveobs[j,:] = tmp[indx_obs:len(tt)+indx_obs]\n",
    "\n",
    "  #===========windowed waveform=================================================\n",
    "  fs_obs = 1.0/(tt[1]-tt[0])\n",
    "  lowcut = 1.0 / bands[:,1]\n",
    "  highcut = 1.0 / bands[:,0]\n",
    "  waveobs_T = {}\n",
    "  for j in range(len(bands)):\n",
    "      waveobs_T[j] = np.zeros(waveobs.shape)\n",
    "      for i in range(waveobs.shape[0]):   \n",
    "          waveobs_T[j][i,:] = butter_bandpass_filter(waveobs[i,:], lowcut[j], highcut[j], fs_obs, order=2)\n",
    "\n",
    "  #===================Process synthetic waveforms==========================================================\n",
    "  confFD = open(fileFDconf, 'r')\n",
    "  linesFD = confFD.read().split('\\n')\n",
    "  for j in range(len(linesFD)):\n",
    "    line = linesFD[j]\n",
    "    if line.find('#') >= 0: line = line[:line.find('#') - 1]\n",
    "    if line.split(' ')[0] == 'dims':\n",
    "      dims = [int(v) for v in line.split() if v.isdigit()][0:3]\n",
    "\n",
    "  confFD.close()\n",
    "\n",
    "  staloc = np.loadtxt(syn_stalist, usecols=[2,3])\n",
    "  syn_netsta = []\n",
    "  with open(syn_stalist, 'r') as f:\n",
    "      while True:\n",
    "          tmp = f.readline()\n",
    "          if tmp:\n",
    "            #syn_netsta.append(tmp.split()[0] + '-' + tmp.split()[1])\n",
    "            syn_netsta.append(tmp.split()[0])\n",
    "          else:\n",
    "              break\n",
    "  Srloc = staloc[syn_netsta.index(srcsta)]\n",
    "  #==============================================================================\n",
    "  whitems = ['Vx', 'Vy', 'Vz', 'Txx', 'Tyy', 'Tzz', 'Txy', 'Txz', 'Tyz']\n",
    "\n",
    "  isfirstget = True\n",
    "  isgottime = False\n",
    "  iline = 0\n",
    "  for k in range(dims[2]):\n",
    "    for j in range(dims[1]):\n",
    "      for i in range(dims[0]):\n",
    "        filename = '{}seismo_mpi{:02d}{:02d}{:02d}.nc'.format(outputpath, i, j, k)\n",
    "        if not os.path.isfile(filename):\n",
    "          continue\n",
    "        ssm = nc.Dataset(filename, 'r')\n",
    "        filename = '{}station_mpi{:02d}{:02d}{:02d}.nc'.format(inputpath, i, j, k)\n",
    "        stn = nc.Dataset(filename, 'r')\n",
    "        pid = stn.variables['id'][:]#get the station index(two dimension)\n",
    "        if not isgottime:\n",
    "          t = ssm.variables['time'][:]\n",
    "          isgottime = True\n",
    "          nt = t.size # the acctural points stored in the Seis.nc\n",
    "        for ip in range(pid.shape[0]):\n",
    "          if pid[ip, 1] == iline:#equals to the L/P-index(P=0) ////get id from STA.nc ///to confirm line number\n",
    "            ttvar = np.zeros((1, 1, nt))\n",
    "            ttvar[0, 0, :] = np.reshape(ssm.variables[whitems[0]][:, ip], [nt]) #get the ip strip in Vx, and flaten into [nt] case\n",
    "            for iw in range(1,9):\n",
    "              tvar = np.reshape(ssm.variables[whitems[iw]][:, ip], [1, 1, nt])\n",
    "              ttvar = np.append(ttvar, tvar, axis = 1) #all stored in falten case and different in layerd direction\n",
    "            if isfirstget:\n",
    "              dvar = ttvar[:] #data  dvar[Var][Var][nt]\n",
    "              ipoint = pid[ip, 0] # relevent index(start from 1)\n",
    "              isfirstget = False\n",
    "            else:\n",
    "              dvar = np.append(dvar, ttvar, axis = 0)\n",
    "              ipoint = np.append(ipoint, pid[ip, 0])\n",
    "        stn.close()\n",
    "        ssm.close()\n",
    "  #ipoint is absolute point location in point series(sequence in line).\n",
    "  #if 'ipoint' not in globals():\n",
    "  #  raise IOError('Maybe no seismogram data files in the outputpath: ' + outputpath)\n",
    "\n",
    "  # nt point in time series\n",
    "  # npt point in record index series\n",
    "\n",
    "  npt = ipoint.size\n",
    "  pvar = np.zeros((npt, 9, nt)) #RECiver Var Time\n",
    "  for ip in range(npt):\n",
    "    pvar[ipoint[ip] - 1, :, :] = dvar[ip, :, :] \n",
    "  for iw in range(9):\n",
    "    if iw < 3:\n",
    "      pvar[:, iw, :] = pvar[:, iw, :]/1.0e3\n",
    "    else:\n",
    "      pvar[:, iw, :] = pvar[:, iw, :]/1.0e9\n",
    "\n",
    "  #print(np.shape(pvar))\n",
    "\n",
    "  # Integrate to obtain Displacement\n",
    "  Vz = pvar[:, 2, :]\n",
    "  #Dz0 = integrate.cumtrapz(Vz, t, axis=1, initial=0)\n",
    "  Dz0 = integrate.cumulative_trapezoid(Vz, t, axis=1, initial=0)\n",
    "  stpindx = int(t_rick_shift/(t[1]-t[0]))\n",
    "  tc = t[:len(t)-stpindx]\n",
    "  Dz = Dz0[:,stpindx:]\n",
    "  # filter-----------------------------------------------------------\n",
    "  fs_syn = 1.0/(t[1]-t[0])\n",
    "  wavesyn_T = {}\n",
    "  for i in range(len(bands)):\n",
    "      wavesyn_T[i] = np.zeros(Dz.shape)\n",
    "      for j in range(Dz.shape[0]):\n",
    "          wavesyn_T[i][j,:] = butter_bandpass_filter(Dz[j,:], lowcut[i], highcut[i], fs_syn, order=2)\n",
    "\n",
    "  indxcorr_syn = []\n",
    "  indxcorr_obs = []\n",
    "  r_plot = []\n",
    "  #print(\"netsta: \", netsta)\n",
    "  for i in range(len(robs)):\n",
    "    #print(\"CC_sta_name: \", CC_sta_name[i])\n",
    "    if CC_sta_name[i] in syn_netsta:\n",
    "        indxcorr_obs.append(i)\n",
    "        indxcorr_syn.append(syn_netsta.index(CC_sta_name[i]))\n",
    "        r_plot.append(robs[i])\n",
    "  #print(\"indxcorr_obs: \", indxcorr_obs)\n",
    "  #print(\"indxcorr_syn: \", indxcorr_syn)\n",
    "  r_plot = np.array(r_plot)\n",
    "  wavesync_T = {}\n",
    "  waveobsc_T = {}\n",
    "  for i in range(len(bands)):\n",
    "      wavesync_T[i] = wavesyn_T[i][indxcorr_syn]\n",
    "      waveobsc_T[i] = waveobs_T[i][indxcorr_obs]\n",
    "\n",
    "  return wavesync_T, waveobsc_T, r_plot,t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sync configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dir_project + 'modelValidate_src.txt'\n",
    "srcs = np.loadtxt(filename, dtype='str', unpack=True)\n",
    "filename = dir_project + 'modelValidate_src_papertomo.txt'\n",
    "srcs_nums = np.loadtxt(filename, dtype='int', unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 19, 28, 48, 60])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srcs_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_maxd = 0.07\n",
    "flag_SNRmin = 0.9\n",
    "f_rick_c = 10\n",
    "t_rick_shift = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(waveobsc_T,wavesync_T, r_plot, t, dir_image, bands,isrc,aver,t_left_shits,t_right_shits,flag_inter=1):\n",
    "    scale1 = 0.002\n",
    "    scale2 = 0.002\n",
    "    linew = 2.0\n",
    "    waveobsc_T_copy = copy.deepcopy(waveobsc_T)\n",
    "    wavesync_T_copy = copy.deepcopy(wavesync_T)\n",
    "    virsta = []\n",
    "    sta_profile = pandas.read_table(srclist, header=None, sep='\\\\s+')\n",
    "    net = list(sta_profile[0][:])\n",
    "    sta = list(sta_profile[1][:])\n",
    "    for i in range(len(sta)):\n",
    "        virsta.append(str(sta[i]))\n",
    "    srcsta = virsta[isrc-1]\n",
    "    \n",
    "    for i in range(len(bands)):\n",
    "        fig_model = plt.figure(figsize=(8, 6))\n",
    "        plt.style.use('tomo_paper.mplstyle')\n",
    "        ax_model = fig_model.add_subplot(111)\n",
    "        for j in range(0,len(r_plot),flag_inter):\n",
    "            #print(j)\n",
    "            t0 = r_plot[j]/aver[0]-t_left_shits[i]\n",
    "            t1 = r_plot[j]/aver[0]+t_right_shits[i]\n",
    "            dtobs = 1/np.max(freq)\n",
    "            indx0 = int(t0/dtobs)\n",
    "            indx1 = int(t1/dtobs)\n",
    "            waveobsc_T_copy[i][j,:indx0] = 0\n",
    "            waveobsc_T_copy[i][j,indx1:] = 0\n",
    "            stpindx = int(t_rick_shift/(t[1]-t[0]))\n",
    "            tc = t[:len(t)-stpindx]\n",
    "            tobs = (np.linspace(-len(freq)/2, len(freq)/2-1, len(freq))-0.5)*dtobs\n",
    "            tt = tobs[int(len(freq)/2+1)::]\n",
    "            pt,= ax_model.plot(tt, waveobsc_T_copy[i][j,:]/(np.max(abs(waveobsc_T_copy[i][j,:])))*scale2+r_plot[j]*1e3,'b', antialiased='False',linewidth=linew)\n",
    "            #label = \"Observation (\"+str(int(1/bands[i][1]))+\"-\"+str(int(1/bands[i][0]))+\"Hz)\"\n",
    "            label = \"Observation (\" + str(int(1/bands[i][1])) + '-' + str(int(1/bands[i][0])) + \"Hz)\"\n",
    "            pt0,= ax_model.plot(tc, wavesync_T_copy[i][j]/np.max(abs(wavesync_T_copy[i][j]))*scale1+r_plot[j]*1e3, 'r', antialiased='False', linewidth=linew)\n",
    "            ax_model.hlines(r_plot[j]*1e3+0.05, 0.75, 1, colors = \"r\",antialiased='False', linewidth=linew)\n",
    "            #label0 = \"This study    (\"+str(int(1/bands[i][1]))+\"-\"+str(int(1/bands[i][0]))+\"Hz)\"\n",
    "            label0 = \"This study (\"  + str(int(1/bands[i][1])) + '-' + str(int(1/bands[i][0])) + \"Hz)\"\n",
    "        #plt.ylim([0, ylimt])\n",
    "        #ax_model.set_ylim([0.005, flag_maxd+0.002])\n",
    "        #ax_model.set_ylim([0.005, 0.075+0.002])\n",
    "        ax_model.set_xlim([0, 0.8])\n",
    "        #ax0.xaxis.set_major_locator(ticker.MaxNLocator(7))\n",
    "        #ax0.xaxis.set_minor_locator(ticker.MaxNLocator(35))\n",
    "        #ax0.yaxis.set_major_locator(ticker.MaxNLocator(9))\n",
    "        #ax0.yaxis.set_minor_locator(ticker.MaxNLocator(45))\n",
    "        ax_model.set_xlabel('Time (s)')\n",
    "        ax_model.set_ylabel('Distance (m)')\n",
    "        ax_model.legend([pt, pt0],[label, label0],  loc=4)\n",
    "        #ax_model.set_title('Waveform comparison for '+str(int(1/bands[i][1]))+\"-\"+str(int(1/bands[i][0]))+\"Hz\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir_image+'modelValidation_'+'src'+str(isrc)+'_band-'+str(i)+'.eps')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = np.array([[1/10,1/5],[1/15,1/10], [1/20,1/15] ])\n",
    "dir_input = dir_project + 'ModelValidate_Overtones/template/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srouce:  66   srcsta:\t R3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srouce:  19   srcsta:\t R3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srouce:  28   srcsta:\t R3310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srouce:  48   srcsta:\t R3613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srouce:  60   srcsta:\t R3916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "for isrc in srcs_nums:\n",
    "#for isrc in [66]:\n",
    "    dir_src = dir_project + 'ModelValidate_Overtones/src'+str(isrc)+'/'\n",
    "    #data = np.load(dir_src+'waveform.npy',allow_pickle='TRUE').item()\n",
    "    #wavesync_T = data['wavesync_T']\n",
    "    #waveobsc_T = data['waveobsc_T']\n",
    "    wavesync_T, waveobsc_T, r_plot,t = extract_sync(isrc,dir_src,flag_maxd,flag_SNRmin,f_rick_c,t_rick_shift,bands,CC_array,CC_table,freq,srclist,sele_stalist,syn_stalist)\n",
    "    #t = data['t']\n",
    "    #r_plot = data['r_plot']\n",
    "    flag_inter = 1\n",
    "    aver = np.array([0.4,0.5,0.5])\n",
    "    t_left_shits = np.array([0.01,0,0.0])\n",
    "    t_right_shits = np.array([0.33,0.25,0.21])\n",
    "    plot_model(waveobsc_T,wavesync_T, r_plot, t, dir_image, bands,isrc,aver,t_left_shits,t_right_shits,flag_inter=flag_inter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccfj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
